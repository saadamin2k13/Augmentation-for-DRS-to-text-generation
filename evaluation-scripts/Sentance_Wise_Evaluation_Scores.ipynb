{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "867f2cc2ff0e40bca17886ff9b013266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e371d577cb042dd9ecb2de1cbb743bd",
              "IPY_MODEL_a626b63631a9422e91b0cba01b118209",
              "IPY_MODEL_bed9fdf469e8427caaf1e70ae7e3b574"
            ],
            "layout": "IPY_MODEL_a3e04008e23e41b8a3712e62b333ae34"
          }
        },
        "2e371d577cb042dd9ecb2de1cbb743bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0dec231f67a4f95bd20a28fc9d4458a",
            "placeholder": "​",
            "style": "IPY_MODEL_d5333a1b2cf6416ab59cddc6657c96e8",
            "value": "Fetching 5 files: 100%"
          }
        },
        "a626b63631a9422e91b0cba01b118209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57010e83bdfa43fb9788080834e5069c",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2426f951f10e48b69ab2b754d58f2f51",
            "value": 5
          }
        },
        "bed9fdf469e8427caaf1e70ae7e3b574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be5258c1e9704fc8b01e0bd6405ffeea",
            "placeholder": "​",
            "style": "IPY_MODEL_c872d6274944404f8a3614a0aa329000",
            "value": " 5/5 [00:00&lt;00:00, 199.04it/s]"
          }
        },
        "a3e04008e23e41b8a3712e62b333ae34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dec231f67a4f95bd20a28fc9d4458a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5333a1b2cf6416ab59cddc6657c96e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57010e83bdfa43fb9788080834e5069c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2426f951f10e48b69ab2b754d58f2f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be5258c1e9704fc8b01e0bd6405ffeea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c872d6274944404f8a3614a0aa329000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**code below will calculate METEOR score sentence by sentence**"
      ],
      "metadata": {
        "id": "H6GEtiDcEMIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.translate import meteor_score\n",
        "\n",
        "# Open the reference and candidate text files\n",
        "with open('test.txt', 'r') as ref_file, open('w_aug.txt', 'r') as cand_file:\n",
        "    # Read the contents of the files\n",
        "    ref_lines = ref_file.readlines()\n",
        "    cand_lines = cand_file.readlines()\n",
        "\n",
        "# Open the result file in write mode\n",
        "with open('meteor_w_aug.txt', 'w') as result_file:\n",
        "    # Calculate the METEOR score for each line\n",
        "    for ref_line, cand_line in zip(ref_lines, cand_lines):\n",
        "        # Tokenize the reference and candidate sentences\n",
        "        ref_sentences = nltk.sent_tokenize(ref_line)\n",
        "        cand_sentences = nltk.sent_tokenize(cand_line)\n",
        "\n",
        "        # Calculate the METEOR score for the entire line\n",
        "        ref_tokens = []\n",
        "        for ref_sentence in ref_sentences:\n",
        "            ref_tokens.extend(nltk.word_tokenize(ref_sentence.lower()))\n",
        "        cand_tokens = []\n",
        "        for cand_sentence in cand_sentences:\n",
        "            cand_tokens.extend(nltk.word_tokenize(cand_sentence.lower()))\n",
        "\n",
        "        meteor = meteor_score.meteor_score([ref_tokens], cand_tokens)\n",
        "\n",
        "        # Write the reference, candidate, and METEOR score to the result file\n",
        "        #result_file.write(\"Reference: \" + ref_line + \"\\n\")\n",
        "        #result_file.write(\"Candidate: \" + cand_line + \"\\n\")\n",
        "        result_file.write(\"\" + str(meteor) + \"\\n\")\n",
        "        #result_file.write(\"\\n\")\n"
      ],
      "metadata": {
        "id": "7AVeoxZ7ESkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f260395-43a0-4df3-f288-198ce04a4289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code below will calculate CIDEr score sentence by sentence**"
      ],
      "metadata": {
        "id": "QdpxpieL5SOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def read_sentences_from_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        sentences = file.readlines()\n",
        "    sentences = [sentence.strip() for sentence in sentences]\n",
        "    return sentences\n",
        "\n",
        "def compute_cider_score(generated_sentence, reference_sentences):\n",
        "    # Preprocess the sentences\n",
        "    generated_sentence = generated_sentence.lower()\n",
        "    reference_sentences = [sent.lower() for sent in reference_sentences]\n",
        "\n",
        "    # Create a TF-IDF vectorizer\n",
        "    vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Fit the vectorizer on the reference sentences\n",
        "    vectorizer.fit(reference_sentences)\n",
        "\n",
        "    # Transform the generated sentence and reference sentences into TF-IDF vectors\n",
        "    generated_vector = vectorizer.transform([generated_sentence])\n",
        "    reference_vectors = vectorizer.transform(reference_sentences)\n",
        "\n",
        "    # Calculate the cosine similarity between the generated vector and reference vectors\n",
        "    similarities = cosine_similarity(generated_vector, reference_vectors)[0]\n",
        "\n",
        "    # Compute the CIDEr score as the average cosine similarity\n",
        "    cider_score = sum(similarities) / len(similarities)\n",
        "    return cider_score\n",
        "\n",
        "# Example usage\n",
        "generated_sentences = read_sentences_from_file(\"train.txt\")\n",
        "reference_sentences = read_sentences_from_file(\"test.txt\")\n",
        "\n",
        "output_file = open(\"cider.txt\", \"w\")\n",
        "for generated_sentence in generated_sentences:\n",
        "    cider_score = compute_cider_score(generated_sentence, reference_sentences)\n",
        "    #output_file.write(\"Generated Sentence: {}\\n\".format(generated_sentence))\n",
        "    #output_file.write(\"CIDEr score: {}\\n\".format(cider_score))\n",
        "    output_file.write(\"{}\\n\".format(cider_score))\n",
        "    #output_file.write(\"\\n\")\n",
        "output_file.close()\n"
      ],
      "metadata": {
        "id": "6f7AgSh_5ZgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**code below will calculate ROUGE score sentence by sentence**"
      ],
      "metadata": {
        "id": "8fGYuWi6O4ON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "id": "_n0jaG25X3TI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74156fa1-d233-44b7-b5a8-f9a284d2fd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "import nltk\n",
        "\n",
        "def calculate_rouge_l_scores(reference_file, hypothesis_file, output_file):\n",
        "    rouge = Rouge()\n",
        "\n",
        "    with open(reference_file, 'r', encoding='utf-8') as ref_file, \\\n",
        "         open(hypothesis_file, 'r', encoding='utf-8') as hyp_file, \\\n",
        "         open(output_file, 'w', encoding='utf-8') as out_file:\n",
        "\n",
        "        ref_sentences = ref_file.readlines()\n",
        "        hyp_sentences = hyp_file.readlines()\n",
        "\n",
        "        # Calculate ROUGE-L scores for each sentence and save them in the output file\n",
        "        for ref_sent, hyp_sent in zip(ref_sentences, hyp_sentences):\n",
        "            ref_sent = ref_sent.strip()\n",
        "            hyp_sent = hyp_sent.strip()\n",
        "\n",
        "            score = rouge.get_scores(hyp_sent, ref_sent)[0]['rouge-l']['f']\n",
        "            #out_file.write(f\"ROUGE-L Score: {score}\\n\")\n",
        "            out_file.write(f\"{score}\\n\")\n",
        "\n",
        "    print(f\"ROUGE-L scores saved in {output_file}.\")\n",
        "\n",
        "# Example usage\n",
        "reference_file = 'test.txt'\n",
        "hypothesis_file = 'train_w_aug.txt'\n",
        "output_file = 'rouge1.txt'\n",
        "\n",
        "calculate_rouge_l_scores(reference_file, hypothesis_file, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9OZWgbMO_P5",
        "outputId": "b45e096e-39b0-419e-ff18-7e9a3c630c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-L scores saved in rouge1.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code below will calculate NIST score sentence by sentence.**"
      ],
      "metadata": {
        "id": "KZtgyeiJBYsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "def calculate_nist_score(ref_sentence, hyp_sentence, n=4):\n",
        "    ref_tokens = nltk.word_tokenize(ref_sentence)\n",
        "    hyp_tokens = nltk.word_tokenize(hyp_sentence)\n",
        "\n",
        "    ref_ngrams = nltk.ngrams(ref_tokens, n)\n",
        "    hyp_ngrams = nltk.ngrams(hyp_tokens, n)\n",
        "\n",
        "    ref_ngram_counts = nltk.FreqDist(ref_ngrams)\n",
        "    hyp_ngram_counts = nltk.FreqDist(hyp_ngrams)\n",
        "\n",
        "    clipped_counts = {\n",
        "        ngram: min(hyp_ngram_counts[ngram], ref_ngram_counts[ngram])\n",
        "        for ngram in hyp_ngram_counts\n",
        "    }\n",
        "\n",
        "    numerator = sum(clipped_counts.values())\n",
        "    denominator = sum(hyp_ngram_counts.values())\n",
        "\n",
        "    nist_score = numerator / denominator if denominator != 0 else 0.0\n",
        "\n",
        "    return nist_score\n",
        "\n",
        "def calculate_sentence_scores(ref_sentences, hyp_sentences):\n",
        "    sentence_scores = []\n",
        "    for ref_sentence, hyp_sentence in zip(ref_sentences, hyp_sentences):\n",
        "        score = calculate_nist_score(ref_sentence, hyp_sentence)\n",
        "        sentence_scores.append(score)\n",
        "    return sentence_scores\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Read reference sentences from a text file\n",
        "with open('test.txt', 'r', encoding='utf-8') as ref_file:\n",
        "    ref_sentences = ref_file.readlines()\n",
        "\n",
        "# Read hypothesis sentences from a text file\n",
        "with open('train.txt', 'r', encoding='utf-8') as hyp_file:\n",
        "    hyp_sentences = hyp_file.readlines()\n",
        "\n",
        "# Calculate sentence scores\n",
        "scores = calculate_sentence_scores(ref_sentences, hyp_sentences)\n",
        "\n",
        "# Save sentence scores in a text file\n",
        "with open('nist.txt', 'w', encoding='utf-8') as scores_file:\n",
        "    for score in scores:\n",
        "        scores_file.write(str(score) + '\\n')\n",
        "\n",
        "print(\"Sentence scores saved in scores.txt file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IGTpttoBL5d",
        "outputId": "ecb5babf-95d7-4951-bbbc-88ffdbeb01b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence scores saved in scores.txt file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code below will calculate the BLEU score sentence by sentence**"
      ],
      "metadata": {
        "id": "nFdC5sCABQkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "nRnt5yqlXaw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46af005f-e05f-433b-ebaf-d4146fa67a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "BJsIFIMPfzg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed24d460-ddd3-49d6-ade5-8a38090e3aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sentence by sentence BLEU score**"
      ],
      "metadata": {
        "id": "dRIQExUstoGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate import bleu_score\n",
        "\n",
        "def calculate_sentence_bleu(reference, candidate):\n",
        "    reference = [nltk.word_tokenize(sentence) for sentence in reference]\n",
        "    candidate = nltk.word_tokenize(candidate)\n",
        "    return bleu_score.sentence_bleu(reference, candidate)\n",
        "\n",
        "def calculate_and_save_bleu_scores(reference_file, candidate_file, output_file):\n",
        "    with open(reference_file, 'r', encoding='utf-8') as ref_file, \\\n",
        "         open(candidate_file, 'r', encoding='utf-8') as can_file, \\\n",
        "         open(output_file, 'w', encoding='utf-8') as out_file:\n",
        "\n",
        "        reference_sentences = [line.strip() for line in ref_file.readlines()]\n",
        "        candidate_sentences = [line.strip() for line in can_file.readlines()]\n",
        "\n",
        "        for ref_sentence, can_sentence in zip(reference_sentences, candidate_sentences):\n",
        "            bleu_score = calculate_sentence_bleu([ref_sentence], can_sentence)\n",
        "            out_file.write(f\"BLEU Score: {bleu_score:.4f} - Reference: {ref_sentence} - Candidate: {can_sentence}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    reference_file_path = \"test.txt\"\n",
        "    candidate_file_path = \"train_wo_aug.txt\"\n",
        "    output_file_path = \"bleu.txt\"\n",
        "\n",
        "    calculate_and_save_bleu_scores(reference_file_path, candidate_file_path, output_file_path)\n",
        "\n",
        "    print(\"BLEU scores saved to:\", output_file_path)\n"
      ],
      "metadata": {
        "id": "QQRkrCHbtrXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for Urdu Text, calculating sentece wise BLEU score.**"
      ],
      "metadata": {
        "id": "U0dtom-NuU2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "SmFLFAznvOu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU score based on custom tokenization."
      ],
      "metadata": {
        "id": "0aYApWycyBIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate import bleu_score\n",
        "\n",
        "def calculate_word_overlap_bleu(reference, candidate):\n",
        "    reference_tokens = reference.split()  # Tokenize based on spaces\n",
        "    candidate_tokens = candidate.split()\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    word_overlap_bleu = bleu_score.sentence_bleu([reference_tokens], candidate_tokens, weights=(1, 0, 0, 0))\n",
        "\n",
        "    return word_overlap_bleu\n",
        "\n",
        "def calculate_and_save_bleu_scores(reference_file, candidate_file, output_file):\n",
        "    with open(reference_file, 'r', encoding='utf-8') as ref_file, \\\n",
        "         open(candidate_file, 'r', encoding='utf-8') as can_file, \\\n",
        "         open(output_file, 'w', encoding='utf-8') as out_file:\n",
        "\n",
        "        reference_sentences = [line.strip() for line in ref_file.readlines()]\n",
        "        candidate_sentences = [line.strip() for line in can_file.readlines()]\n",
        "\n",
        "        for ref_sentence, can_sentence in zip(reference_sentences, candidate_sentences):\n",
        "            word_overlap_bleu = calculate_word_overlap_bleu(ref_sentence, can_sentence)\n",
        "            out_file.write(f\"{word_overlap_bleu:.4f}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    reference_file_path = \"test.txt\"\n",
        "    candidate_file_path = \"w_aug.txt\"\n",
        "    output_file_path = \"bleu_w_aug.txt\"\n",
        "\n",
        "    calculate_and_save_bleu_scores(reference_file_path, candidate_file_path, output_file_path)\n",
        "\n",
        "    print(\"Word Overlap BLEU scores saved to:\", output_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li9hx56byF9U",
        "outputId": "738ed951-a7b3-4717-fef0-f32f499a5884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Overlap BLEU scores saved to: bleu_w_aug.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make two txt files. One with reference and otherone as translation of neural model.**"
      ],
      "metadata": {
        "id": "zc2ZOVX2B0ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 compute-bleu-sentence-args.py test.txt train_w_aug.txt"
      ],
      "metadata": {
        "id": "rj3qHG06gZ6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm bleu*"
      ],
      "metadata": {
        "id": "lvwYEK6Tk5qN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d90b97-524a-4ee5-a481-ce7af962509c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'sample_data': Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create compute-bleu-sentence-args.py file and copy code given below in it.**"
      ],
      "metadata": {
        "id": "eVIHCPZgBkyc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4tupCACXOEH"
      },
      "outputs": [],
      "source": [
        "# BLEU for segment by segment with arguments\n",
        "# Run this file from CMD/Terminal\n",
        "# Example Command: python3 compute-bleu-sentence-args.py test_file_name.txt mt_file_name.txt\n",
        "\n",
        "import sys\n",
        "import sacrebleu\n",
        "from sacremoses import MosesDetokenizer\n",
        "md = MosesDetokenizer(lang='en')\n",
        "\n",
        "target_test = sys.argv[1]  # Test file argument\n",
        "target_pred = sys.argv[2]  # MTed file argument\n",
        "\n",
        "# Open the test dataset human translation file and detokenize the references\n",
        "refs = []\n",
        "\n",
        "with open(target_test) as test:\n",
        "    for line in test:\n",
        "        line = line.strip().split()\n",
        "        line = md.detokenize(line)\n",
        "        refs.append(line)\n",
        "\n",
        "print(\"Reference 1st sentence:\", refs[0])\n",
        "\n",
        "# Open the translation file by the NMT model and detokenize the predictions\n",
        "preds = []\n",
        "\n",
        "with open(target_pred) as pred:\n",
        "    for line in pred:\n",
        "        line = line.strip().split()\n",
        "        line = md.detokenize(line)\n",
        "        preds.append(line)\n",
        "\n",
        "# Calculate BLEU for sentence by sentence and save the result to a file\n",
        "with open(\"bleu-\" + target_pred + \".txt\", \"w+\") as output:\n",
        "    for line in zip(refs,preds):\n",
        "        test = line[0]\n",
        "        pred = line[1]\n",
        "        print(test, \"\\t--->\\t\", pred)\n",
        "        bleu = sacrebleu.sentence_bleu(pred, [test], smooth_method='exp')\n",
        "        print(bleu.score, \"\\n\")\n",
        "        output.write(str(bleu.score) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drawing histogram of BLEU scores**"
      ],
      "metadata": {
        "id": "9Aou_oxQzYjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "f= np.loadtxt('bleu-unlex-char.txt', unpack='False')\n",
        "\n",
        "# set bins' interval for your data\n",
        "# You have following intervals:\n",
        "# 1st col is number of data elements in [0,10000);\n",
        "# 2nd col is number of data elements in [10000, 20000);\n",
        "# ...\n",
        "# last col is number of data elements in [100000, 200000];\n",
        "bins = [0,10,20,30,40,50,60,70,80,90,100]\n",
        "\n",
        "plt.hist(f, histtype='bar', bins = bins, color = \"lightblue\", ec=\"red\")\n",
        "plt.xlabel('BLEU Score Range')\n",
        "plt.ylabel('Number of Translation Samples')\n",
        "plt.title('Char-Level Distribution of BLEU Scores')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "_nljStNOzedK",
        "outputId": "84d2c5d7-3242-4ade-ca4d-98808ea84088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for word-score**"
      ],
      "metadata": {
        "id": "prc825HW1_QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "f= np.loadtxt('bleu-unlex-word.txt', unpack='False')\n",
        "\n",
        "# set bins' interval for your data\n",
        "# You have following intervals:\n",
        "# 1st col is number of data elements in [0,10000);\n",
        "# 2nd col is number of data elements in [10000, 20000);\n",
        "# ...\n",
        "# last col is number of data elements in [100000, 200000];\n",
        "bins = [0,10,20,30,40,50,60,70,80,90,100]\n",
        "\n",
        "plt.hist(f, histtype='bar', bins = bins, color = \"lightblue\", ec=\"red\")\n",
        "plt.xlabel('BLEU Score Range')\n",
        "plt.ylabel('Number of Translation Samples')\n",
        "plt.title('Word-Level Distribution of BLEU Scores')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "RJ-yCvm81-fN",
        "outputId": "4fa4b986-1d40-496b-a568-460b0cf44a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**code to read text and save in excel file**"
      ],
      "metadata": {
        "id": "9ZKax4ov_l9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('unlexical-word.txt') as f1:\n",
        "    lines = [line.rstrip() for line in f1]\n",
        "\n",
        "with open('test.txt') as f2:\n",
        "    lines2 = [line.rstrip() for line in f2]\n",
        "\n",
        "with open('bleu-unlex-word.txt') as f3:\n",
        "    lines3 = [line.rstrip() for line in f3]\n",
        "\n",
        "\n",
        "print(type(lines))\n",
        "print(type(lines2))\n",
        "print(type(lines3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CtoC7ci_gLR",
        "outputId": "d0f9d694-259d-4dc0-94f5-71dc4c150db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "id": "LJMdF9c1AKBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xlsxwriter\n",
        "\n",
        "data = {'unlex-word-data': lines}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df['test-data'] = lines2\n",
        "df['BLEU-Scores'] = lines3\n",
        "\n",
        "print(df)\n",
        "writer = pd.ExcelWriter('test-word.xlsx', engine='xlsxwriter')\n",
        "df.to_excel(writer, sheet_name='Unlex-Word-Data', index=False)\n",
        "writer.save()"
      ],
      "metadata": {
        "id": "CM80kaOGABgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**now, reading excel file to display outputs for low BLEU scores**"
      ],
      "metadata": {
        "id": "Ke8r6peYL5Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "from pathlib import Path\n",
        "\n",
        "xlsx_file = Path('', 'test-word.xlsx')\n",
        "wb_obj = openpyxl.load_workbook(xlsx_file)\n",
        "sheet = wb_obj.active\n",
        "\n",
        "col_names = []\n",
        "for column in sheet.iter_cols(1, sheet.max_column):\n",
        "    col_names.append(column[0].value)\n",
        "\n",
        "\n",
        "print(col_names)"
      ],
      "metadata": {
        "id": "jtKaLlfCL_I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('test-word.xlsx', sheet_name=0) #reads the first sheet of your excel file\n",
        "print(df)\n",
        "print(type(df))"
      ],
      "metadata": {
        "id": "RllfK893OyjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 0 and `BLEU-Scores` <= 10\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 0 and `BLEU-Scores` <= 10\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiGaCg93VGZs",
        "outputId": "e4b91d68-65de-495b-a714-4e4151cfb753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "                                unlex-word-data  \\\n",
            "2                She really like shortest eggs.   \n",
            "11           Does everyone possibly get a book?   \n",
            "54                        Who the children are!   \n",
            "140                     She tore up the secret.   \n",
            "247                     I went there with feet.   \n",
            "268                        Has a drop dripping?   \n",
            "377        She washed him from her performance.   \n",
            "540            There was a soldier on the ship.   \n",
            "579  She is donating some money to cancer name.   \n",
            "589                                       http:   \n",
            "610                 The rope must be resumed...   \n",
            "752                      Tom won a lot of race.   \n",
            "\n",
            "                                     test-data  BLEU-Scores  \n",
            "2                      She likes short skirts.     9.652435  \n",
            "11             Nowadays anybody can get books.     6.567275  \n",
            "54              What a nuisance that child is!     7.160476  \n",
            "140        She has hit the jackpot once again.     7.654113  \n",
            "247                           We went on foot.     9.652435  \n",
            "268                             Drops dripped.     0.000000  \n",
            "377           She wiped him out of her memory.     8.051154  \n",
            "540        There were soldiers on these ships.     7.267884  \n",
            "579  She's donating money for cancer research.     6.742556  \n",
            "589  http://www.anl.siemens.de/news/press.html     0.055308  \n",
            "610                That rope has to be coiled.     7.267884  \n",
            "752                    Tom has won many races.     8.643020  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 11 and `BLEU-Scores` <= 20\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 11 and `BLEU-Scores` <= 20\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQVRGPItiCkS",
        "outputId": "3e447e4f-b434-4d6b-c6e7-2947105578f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "                                   unlex-word-data  \\\n",
            "4                  One cannot live on this island.   \n",
            "22                The casino is playing money now.   \n",
            "34                 The piano snapped the fire out.   \n",
            "51               I think he's eaten about 10 here.   \n",
            "92                                  The flies wet.   \n",
            "102                       The room wasn't out yet.   \n",
            "141                 You're here to speak Georgian.   \n",
            "150               There is a skeleton in the park.   \n",
            "155                  I'm wetting my handkerchiefs.   \n",
            "171                      I'll listen to this song.   \n",
            "175                        Your shift is open now.   \n",
            "250                                Tom ripped off.   \n",
            "262                We fishing in the River Thames.   \n",
            "263            The law was criticized by the wash.   \n",
            "277                   There is a bag in this room.   \n",
            "382                            Four times 5 is 20.   \n",
            "383             He studied some turtle in Harvard.   \n",
            "413                                      It's: 30.   \n",
            "438      What association is Hope Holcomb led now?   \n",
            "458                        The whistle roared out.   \n",
            "459                                I hated Monday.   \n",
            "465                                  I'm pregnant.   \n",
            "467      A crude oil has been overseas as a price.   \n",
            "470                  Hundreds of women were raped.   \n",
            "471  Which prize did Elizabeth Neufeld be awarded?   \n",
            "489                   Tom knows that Mary refused.   \n",
            "494                                   Tom's upset.   \n",
            "505     Napoleon received his army through Russia.   \n",
            "512                             It was incredible.   \n",
            "514                      Tom plays a lot of words.   \n",
            "520                  Tom got expelled from office.   \n",
            "543            500 British soldiers were captured.   \n",
            "561   The clock in the city was out at 10 o'clock.   \n",
            "572                 Tom scored a thirty name eggs.   \n",
            "613              Which city was Liverpool Beatles?   \n",
            "616    Tom still owes Mary three city _ 1 dollars.   \n",
            "628                     He sat down the telephone.   \n",
            "637                  There's somebody in the room.   \n",
            "649               Actinium melts by three degrees.   \n",
            "684                 We study since 8 until eleven.   \n",
            "704               Suddenly origins began to tango.   \n",
            "722                   I was swimming in the river.   \n",
            "727                  I was rejected by mosquitoes.   \n",
            "740                      She is shy of pine trees.   \n",
            "745                    assembled a sewing machine.   \n",
            "794                 I came here about six o'clock.   \n",
            "838                        I like this tie of you.   \n",
            "862                         We're not married yet.   \n",
            "873    The used to Boston must take about 90 name.   \n",
            "881                This hat cost about 50 dollars.   \n",
            "\n",
            "                                             test-data  BLEU-Scores  \n",
            "4                       You can't live on that island.    18.575058  \n",
            "22                        This casino is losing money.    15.619700  \n",
            "34                 The fire fighters put out the fire.    14.317201  \n",
            "51                    I think he ate about 10 oysters.    16.515822  \n",
            "92                                     The fly buzzes.    18.995892  \n",
            "102                    The room was anything but tidy.    15.207218  \n",
            "141                             Do you speak Georgian?    16.233396  \n",
            "150              There are tennis courts in this park.    13.134549  \n",
            "155                      I am wetting my handkerchief.    19.357693  \n",
            "171                   Let's listen to that song again.    16.341219  \n",
            "175                                  Your fly is open!    17.965206  \n",
            "250                                      Tom shivered.    18.995892  \n",
            "262                      I fished in the Thames River.    16.515822  \n",
            "263   The law was also criticized be the trade unions.    19.038682  \n",
            "277                   There are some bags in the room.    13.134549  \n",
            "382                         Four times five is twenty.    19.304870  \n",
            "383                         He studied law at Harvard.    18.575058  \n",
            "413                                It's half past one.    14.794016  \n",
            "438           What association does Hope Holcomb lead?    16.515822  \n",
            "458                                The thunder roared.    14.058533  \n",
            "459                                    I hate Mondays.    18.995892  \n",
            "465                                     Am I pregnant?    19.716119  \n",
            "467               Crude oil has been falling in price.    19.640733  \n",
            "470     Hundreds of thousands of women had been raped.    16.293990  \n",
            "471          What prize was Elizabeth Neufeld awarded?    16.515822  \n",
            "489                               Tom knows Mary lied.    19.304870  \n",
            "494                                Tom is unperturbed.    19.716119  \n",
            "505           Napoleon marched his armies into Russia.    15.619700  \n",
            "512                    That was incredible, wasn't it?    15.090768  \n",
            "514                      Tom mispronounces many words.    14.535768  \n",
            "520              Tom was expelled from private school.    16.341219  \n",
            "543   Five hundred British soldiers had been captured.    16.449759  \n",
            "561          The clocks in the city were striking ten.    15.851166  \n",
            "572                              Tom scored 30 points.    14.535768  \n",
            "613           What Liverpool club spawned the Beatles?    15.207218  \n",
            "616                         Tom owes Mary 300 dollars.    12.549311  \n",
            "628  As soon as he sat down, he picked up the telep...    11.830764  \n",
            "637                     There is someone in this room.    15.207218  \n",
            "649                         Actinium melts at 1,051°C.    17.965206  \n",
            "684                      I study from eight to eleven.    14.535768  \n",
            "704                       Suddenly rain began to fall.    19.304870  \n",
            "722                      I used to swim in this river.    13.540372  \n",
            "727                           I was bit by a mosquito.    16.341219  \n",
            "740                          She is partial to sweets.    14.535768  \n",
            "745                      You assemble sewing machines.    12.703319  \n",
            "794                               I came at about six.    19.640733  \n",
            "838                          I like that tie of yours.    19.640733  \n",
            "862                                 We aren't married.    12.703319  \n",
            "873  The flight to Boston should take about ninety ...    13.134549  \n",
            "881                That hat cost around fifty dollars.    18.575058  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 21 and `BLEU-Scores` <= 30\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 21 and `BLEU-Scores` <= 30\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfLkgX1fiFjl",
        "outputId": "8b050802-85ff-49e5-d10b-d008676c3c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73\n",
            "                                       unlex-word-data  \\\n",
            "10   She bought an vacuum cleaner from the supermar...   \n",
            "28                             How deep the potato is!   \n",
            "55                 It will cost about 10 thousand yen.   \n",
            "57           He drank some orange juice from a bottle.   \n",
            "71                            The children were bored.   \n",
            "..                                                 ...   \n",
            "849                             Japanese is my tongue.   \n",
            "871              Tom escorting Mary from the building.   \n",
            "876  Salted medical technology was one of the silve...   \n",
            "884                            The problem is discuss.   \n",
            "893                                It's a red herring.   \n",
            "\n",
            "                                             test-data  BLEU-Scores  \n",
            "10     She bought a vacuum cleaner at the supermarket.    26.084743  \n",
            "28                              How deep this lake is!    22.957488  \n",
            "55                      It will cost around 10000 yen.    25.848658  \n",
            "57              He drank orange juice out of a bottle.    26.084743  \n",
            "71                                The child was bored.    23.643540  \n",
            "..                                                 ...          ...  \n",
            "849                     Japanese is our mother tongue.    24.736930  \n",
            "871             Tom escorted Mary out of the building.    24.078566  \n",
            "876  Improved medical technology has been one of th...    28.863046  \n",
            "884                The problem is being discussed now.    28.641905  \n",
            "893                                       It's a trap!    21.364350  \n",
            "\n",
            "[73 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 31 and `BLEU-Scores` <= 40\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 31 and `BLEU-Scores` <= 40\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVtT1W5wiHrf",
        "outputId": "31db773f-132d-4a55-8869-17ee2c2da2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "                          unlex-word-data  \\\n",
            "9              That stinks of cigarettes.   \n",
            "20                 The dog snapped at me.   \n",
            "32   Tom washed the sheets on his finger.   \n",
            "37          She resigned through my poem.   \n",
            "39                    Taninna is purring.   \n",
            "..                                    ...   \n",
            "864                       Tom is escaped.   \n",
            "887                No one encouraged him.   \n",
            "889                            I'm tired.   \n",
            "894                  Tom sat on his desk.   \n",
            "897                         Stop sharing!   \n",
            "\n",
            "                                     test-data  BLEU-Scores  \n",
            "9                     You stink of cigarettes.    39.763536  \n",
            "20                       The dog nipped at me.    37.991784  \n",
            "32   Tom twirled the basketball on his finger.    38.260294  \n",
            "37                     She scoffed at my poem.    32.466792  \n",
            "39                          Taninna is paling.    35.355339  \n",
            "..                                         ...          ...  \n",
            "864                           Tom is escaping.    35.355339  \n",
            "887                     Nobody encouraged him.    39.763536  \n",
            "889                                I am tired.    39.432238  \n",
            "894                       Tom sat at his desk.    37.991784  \n",
            "897                            Stop kvetching!    34.668064  \n",
            "\n",
            "[99 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 41 and `BLEU-Scores` <= 50\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 41 and `BLEU-Scores` <= 50\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7ePbtTniZLT",
        "outputId": "ca5c3b1c-3f46-4b0e-ba3d-7b26e59ff408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84\n",
            "                                       unlex-word-data  \\\n",
            "29                    Ted loves his wife to Elizabeth.   \n",
            "36                                        I'm thirsty.   \n",
            "40                    The black bird is not blackbird.   \n",
            "88   Both Cristina and Luis always dreamed of study...   \n",
            "125                   I can't stand the noise anymore.   \n",
            "..                                                 ...   \n",
            "855                                      Tom is happy.   \n",
            "858                         Latin is a dead name dead.   \n",
            "863                                No one deserves it.   \n",
            "866                          He ate name of the apple.   \n",
            "886                     The bill amounts to 5,000 yen.   \n",
            "\n",
            "                                             test-data  BLEU-Scores  \n",
            "29                       Ted loves his wife Elizabeth.    48.892302  \n",
            "36                                  I'm still thirsty.    45.138644  \n",
            "40                 That black bird is not a blackbird.    42.383656  \n",
            "88   Both Cristina and Luis always dreamt of studyi...    46.713798  \n",
            "125                  I can't stand that noise anymore.    41.113362  \n",
            "..                                                 ...          ...  \n",
            "855                                  Tom is happy now.    49.760939  \n",
            "858                          Latin is a dead language.    43.472087  \n",
            "863                              No one deserves that.    42.728701  \n",
            "866                           He ate all of the apple.    48.892302  \n",
            "886             The bill amounts to five thousand yen.    42.383656  \n",
            "\n",
            "[84 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 51 and `BLEU-Scores` <= 60\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 51 and `BLEU-Scores` <= 60\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRIYN9Geidn2",
        "outputId": "260a29be-6b8c-449b-dc0a-d67a6517c4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n",
            "                           unlex-word-data                          test-data  \\\n",
            "24   Susan questioned your father's shoes.  Susan shined your father's shoes.   \n",
            "31                The piano value is zero.         The default value is zero.   \n",
            "33          She hired a private detective.  She hired a private investigator.   \n",
            "42              The train leaves at 2: 30.      The train leaves at 2:30 p.m.   \n",
            "48                  I am milking my goats.              I am milking my goat.   \n",
            "..                                     ...                                ...   \n",
            "783           Mayuko wore a flower smells.        Mayuko wore a flower crown.   \n",
            "828                           That stinks.                         It stinks.   \n",
            "856              The baby is crawling now.              The baby is crawling.   \n",
            "885       I was born on April 3rd in 1950.       I was born on April 3, 1950.   \n",
            "890              Tom rolled up his sleeve.         Tom rolled up his sleeves.   \n",
            "\n",
            "     BLEU-Scores  \n",
            "24     53.728497  \n",
            "31     53.728497  \n",
            "33     53.728497  \n",
            "42     59.755799  \n",
            "48     53.728497  \n",
            "..           ...  \n",
            "783    53.728497  \n",
            "828    55.032121  \n",
            "856    53.728497  \n",
            "885    51.334505  \n",
            "890    53.728497  \n",
            "\n",
            "[61 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 61 and `BLEU-Scores` <= 70\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 61 and `BLEU-Scores` <= 70\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFLiAlUAikJ1",
        "outputId": "42d332eb-385d-4467-c03f-dec9c285f497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n",
            "                                       unlex-word-data  \\\n",
            "23   The bathtub frightened when she was talking on...   \n",
            "91   The official dinner took place in the White Ho...   \n",
            "97                      I have never climbed Mt. Fuji.   \n",
            "104                   F. Uranus is similar to Neptune.   \n",
            "118                            Will you stop babbling?   \n",
            "123                            She is not a good cook.   \n",
            "177           Tom couldn't pronounce Mary's last name.   \n",
            "208                            aircraft is taking off.   \n",
            "210        They were seated the table in a restaurant.   \n",
            "212                             I saw nothing strange.   \n",
            "236                    Nick still owes me ten dollars.   \n",
            "242               Playing name is my favorite pastime.   \n",
            "249                        No one lives in this house.   \n",
            "256                 My little brother asked for money.   \n",
            "280                        Tom is coming to the party.   \n",
            "303                      Tom was born in the nineties.   \n",
            "308                       I grabbed Tom by the elbows.   \n",
            "320            He arrived at the station at 5 o'clock.   \n",
            "330                He spent his honeymoon in Maldives.   \n",
            "393               My uncle brought a new TV set on me.   \n",
            "405           This watch was your grandfather's watch.   \n",
            "411                  He isn't afraid of snakes at all.   \n",
            "419                                   I'm not a freak.   \n",
            "439                I know him, but he doesn't know me.   \n",
            "483                My uncle isn't young, he's healthy.   \n",
            "506                        I was wounded with a knife.   \n",
            "527             Tom and Mary are always flirting with.   \n",
            "549                 The brass band played three march.   \n",
            "550                                The rice is sticky.   \n",
            "609  Tom apologized to Mary to his son's impolite r...   \n",
            "618         It took me three hoours to do my homework.   \n",
            "638                           I'm looking for someone.   \n",
            "712               Melanie said that she likes subdued.   \n",
            "736                         I attempted suicide twice.   \n",
            "744                    Tom hasn't broken any laws yet.   \n",
            "766              Judith Miller is a member of the CIA.   \n",
            "777                              How does it cost him?   \n",
            "801             This is the biggest hotel in the city.   \n",
            "805                                This watch is slow.   \n",
            "806  Julio is neither in the hammock I hung under t...   \n",
            "819             J. J. Thomson was a English scientist.   \n",
            "824                                 It costs 30 euros.   \n",
            "848                              I got stung by a bee.   \n",
            "\n",
            "                                             test-data  BLEU-Scores  \n",
            "23   The bathtub overflowed while she was talking o...    63.155524  \n",
            "91   The official dinner took place at the White Ho...    65.803701  \n",
            "97                        I've never climbed Mt. Fuji.    68.037493  \n",
            "104                      Uranus is similar to Neptune.    68.037493  \n",
            "118                           Would you stop babbling?    66.874030  \n",
            "123                             She's not a good cook.    61.478815  \n",
            "177              Tom can't pronounce Mary's last name.    64.345888  \n",
            "208                          An aircraft is taking off    66.874030  \n",
            "210     They were seated at the table in a restaurant.    66.904844  \n",
            "212                            We saw nothing strange.    66.874030  \n",
            "236                          Nick owes me ten dollars.    64.345888  \n",
            "242                 Playing go is my favorite pastime.    64.345888  \n",
            "249                        Nobody lives in this house.    61.478815  \n",
            "256            My little brother asked for some money.    61.297524  \n",
            "280                   Tom is coming to the party, too.    63.191456  \n",
            "303                         Tom was born in the 1990s.    64.345888  \n",
            "308                        I grabbed Tom by the elbow.    64.345888  \n",
            "320                 He arrived at the station at five.    61.047358  \n",
            "330            He spent his honeymoon in the Maldives.    61.297524  \n",
            "393              My uncle brought a new TV set for us.    66.063286  \n",
            "405                 This watch was your grandfather's.    64.345888  \n",
            "411                  He's not afraid of snakes at all.    68.037493  \n",
            "419                                   I'm not a freak!    66.874030  \n",
            "439                 I know him but he doesn't know me.    65.803701  \n",
            "483            My uncle isn't young, but he's healthy.    61.019504  \n",
            "506                    I've been wounded with a knife.    61.478815  \n",
            "527  Tom and Mary are always flirting with each other.    67.712191  \n",
            "549               The brass band played three marches.    64.345888  \n",
            "550                               This rice is sticky.    66.874030  \n",
            "609  Tom apologized to Mary for his son's impolite ...    65.803701  \n",
            "618          It took me three hours to do my homework.    65.803701  \n",
            "638                         We're looking for someone.    66.874030  \n",
            "712              Melanie said that she likes swimming.    64.345888  \n",
            "736                      I've attempted suicide twice.    66.874030  \n",
            "744                        Tom hasn't broken any laws.    64.345888  \n",
            "766                  Judith Miller is a member of CIA.    66.063286  \n",
            "777                         How much does it cost him?    67.318214  \n",
            "801            This is the biggest hotel in this city.    66.063286  \n",
            "805                                 The watch is slow.    66.874030  \n",
            "806  Julio is swinging in the hammock that I hung u...    61.421509  \n",
            "819            J. J. Thomson was an English scientist.    65.803701  \n",
            "824                               That costs 30 euros.    66.874030  \n",
            "848                              I was stung by a bee.    64.345888  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 71 and `BLEU-Scores` <= 80\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 71 and `BLEU-Scores` <= 80\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI5dmRu_ipjI",
        "outputId": "893cf532-97aa-4d0b-b81b-89498f4739a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "                                       unlex-word-data  \\\n",
            "5    George W. Bush was born in the state Connectic...   \n",
            "25                             I arrived two days ago.   \n",
            "30                   Samba is a book by Scott McCloud.   \n",
            "41                          I painted the house green.   \n",
            "63                             We chopped a tree down.   \n",
            "73   The presentation is accompanied with a lot of ...   \n",
            "99             I took him, but he ignored the warning.   \n",
            "111                       This plastic chair is cheap.   \n",
            "178                    The damned computer won't work.   \n",
            "254                         I've lost my mobile phone.   \n",
            "258  A typical of prisoners took place on May 24, 1...   \n",
            "294                         My yogurt expires in 2014.   \n",
            "351               Mr. Johnson's room was a large room.   \n",
            "364                                 That CD costs $10.   \n",
            "476                             AI sat down beside me.   \n",
            "588                    Rats chewed a hole in the wall.   \n",
            "659                   This hamster has stuffed cheeks.   \n",
            "667                         Every building has a name.   \n",
            "674                        I like chocolate ice cream.   \n",
            "680         The bell rang and the train began to move.   \n",
            "683                               We climbed Mt. Fuji.   \n",
            "703          It was the first gold medal that she won.   \n",
            "753                   I'm from Rio de Janeiro, Brazil.   \n",
            "781                    Someone farted in the elevator.   \n",
            "789                    Mifune named his dog Maggy May.   \n",
            "\n",
            "                                             test-data  BLEU-Scores  \n",
            "5    George W. Bush was born in the state of Connec...    78.819297  \n",
            "25                            We arrived two days ago.    75.983569  \n",
            "30      Reinventing Comics is a book by Scott McCloud.    74.208848  \n",
            "41                         We painted the house green.    75.983569  \n",
            "63                              I chopped a tree down.    75.983569  \n",
            "73    The operation is accompanied with a lot of pain.    78.254229  \n",
            "99           I warned him, but he ignored the warning.    78.254229  \n",
            "111                        The plastic chair is cheap.    75.983569  \n",
            "178                   This damned computer won't work.    75.983569  \n",
            "254                            I lost my mobile phone.    75.983569  \n",
            "258  A typical reception of prisoners took place on...    79.789731  \n",
            "294                         My yogurt expires in 2014!    75.983569  \n",
            "351                Mr. Johnson's room was a large one.    75.062385  \n",
            "364                                 This CD costs $10.    75.983569  \n",
            "476                             Ai sat down beside me.    75.983569  \n",
            "588                   A rat chewed a hole in the wall.    74.208848  \n",
            "659                    The hamster has stuffed cheeks.    75.983569  \n",
            "667                          Each building has a name.    75.983569  \n",
            "674                        I like chocolate ice cream!    75.983569  \n",
            "680        The bell rang, and the train began to move.    71.086679  \n",
            "683                             I've climbed Mt. Fuji.    75.983569  \n",
            "703      It was the first gold medal that she had won.    75.165011  \n",
            "753                  I am from Rio de Janeiro, Brazil.    74.208848  \n",
            "781                   Somebody farted in the elevator.    75.983569  \n",
            "789                Mifune has named his dog Maggy May.    72.895452  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 81 and `BLEU-Scores` <= 90\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 81 and `BLEU-Scores` <= 90\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsW3aPhBiyRv",
        "outputId": "c55bf47e-a553-49e4-f982-10a5f5e73397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "                                       unlex-word-data  \\\n",
            "335  This dictionary contains about half a million ...   \n",
            "721                 We got up at seven in the morning.   \n",
            "851                      six people came to the party.   \n",
            "\n",
            "                                             test-data  BLEU-Scores  \n",
            "335  The dictionary contains about half a million w...    86.334002  \n",
            "721                  I got up at seven in the morning.    86.334002  \n",
            "851                 Only six people came to the party.    86.687790  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.query(\"`BLEU-Scores` >= 91 and `BLEU-Scores` <= 100\")))\n",
        "\n",
        "print(df.query(\"`BLEU-Scores` >= 91 and `BLEU-Scores` <= 100\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrYPqF8hi16K",
        "outputId": "2c7f5539-6d2d-45c9-fb9c-20c7571a30f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Empty DataFrame\n",
            "Columns: [unlex-word-data, test-data, BLEU-Scores]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**removing comments along with DRSs from test.txt file.**"
      ],
      "metadata": {
        "id": "hLAasXxMeE15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_comments(input_drs):\n",
        "    # Remove inline comments\n",
        "    cleaned_drs = re.sub(r'%[^\\n]*', '', input_drs)\n",
        "    # Remove comments at the beginning of the DRS block (if any)\n",
        "    cleaned_drs = cleaned_drs.strip()\n",
        "    return cleaned_drs\n",
        "\n",
        "def clean_drs_file(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        drs_data = f.read()\n",
        "\n",
        "    drs_list = drs_data.split('\\n\\n')  # Assuming DRSs are separated by empty lines in the input file\n",
        "\n",
        "    cleaned_drs_list = []\n",
        "    for drs in drs_list:\n",
        "        cleaned_drs_list.append(remove_comments(drs))\n",
        "\n",
        "    cleaned_drs_data = '\\n\\n'.join(cleaned_drs_list)\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(cleaned_drs_data)\n",
        "\n",
        "input_file_path = 'input.txt'\n",
        "output_file_path = 'output_drs.txt'\n",
        "\n",
        "clean_drs_file(input_file_path, output_file_path)\n"
      ],
      "metadata": {
        "id": "Zf9T_ufDh0du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calculating chrF score for urdu generation.**"
      ],
      "metadata": {
        "id": "KHFwBlvjlMUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "Bxs4ZwsJlQXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4841b1-0087-4198-813d-3492db97bb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.3.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional.text import chrf_score\n",
        "\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.readlines()\n",
        "    return [line.strip() for line in content]\n",
        "\n",
        "def calculate_chrf_score(preds_file, target_file):\n",
        "    # Read content from files\n",
        "    preds = read_file(preds_file)\n",
        "    target = read_file(target_file)\n",
        "\n",
        "    # Calculate chrf score for each line\n",
        "    chrf_results = [chrf_score([pred], [tar]).item() for pred, tar in zip(preds, target)]\n",
        "\n",
        "    # Calculate the average chrf score\n",
        "    average_chrf_score = sum(chrf_results) / len(chrf_results)\n",
        "\n",
        "    return average_chrf_score\n",
        "\n",
        "# Replace 'preds.txt' and 'target.txt' with your file names\n",
        "preds_file = 'gen_aug.txt'\n",
        "target_file = 'ref.txt'\n",
        "\n",
        "# Calculate and print the average chrf score\n",
        "average_chrf_score = calculate_chrf_score(preds_file, target_file)\n",
        "print(f\"Average chrf score: {average_chrf_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02SEdhOppdwQ",
        "outputId": "3f34855b-4145-408b-9843-d92764f9a79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average chrf score: 0.4587372371926904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculating sentence by sentence score"
      ],
      "metadata": {
        "id": "iLEXo9K42y7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional.text import chrf_score\n",
        "\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.readlines()\n",
        "    return [line.strip() for line in content]\n",
        "\n",
        "def calculate_and_save_chrf_scores(preds_file, target_file, output_file):\n",
        "    # Read content from files\n",
        "    preds = read_file(preds_file)\n",
        "    target = read_file(target_file)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as out_file:\n",
        "        for pred, tar in zip(preds, target):\n",
        "            # Calculate chrf score for each line\n",
        "            chrf_score_value = chrf_score([pred], [tar]).item()\n",
        "\n",
        "            # Save the chrf score to the output file\n",
        "            out_file.write(f\"{chrf_score_value:.4f}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace 'gen_aug.txt', 'ref.txt', and 'chrF_scores.txt' with your file names\n",
        "    preds_file = 'train_w_aug.txt'\n",
        "    target_file = 'test.txt'\n",
        "    output_file = 'chrF1.txt'\n",
        "\n",
        "    # Calculate and save the chrF scores sentence by sentence\n",
        "    calculate_and_save_chrf_scores(preds_file, target_file, output_file)\n",
        "\n",
        "    print(\"chrF scores saved to:\", output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t127ia092180",
        "outputId": "a28b253f-d50b-458a-fb4d-513025ad52fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chrF scores saved to: chrF1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating BERT-Score**"
      ],
      "metadata": {
        "id": "lBhLdOFvSDBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using automatic way, and sentence by sentence."
      ],
      "metadata": {
        "id": "ue1YqUEx6shd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install pytorch and huggingface transformers if you havn't done so\n",
        "!pip install torch\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "asRZzp_g6xgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if you have not installed bert_score, it is very easy\n",
        "# simply uncomment the line below to install through pip\n",
        "!pip install bert_score"
      ],
      "metadata": {
        "id": "2PDLkWTv6yJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import score"
      ],
      "metadata": {
        "id": "Lt_jPEIs60pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"train_wo_aug.txt\") as f:\n",
        "    cands = [line.strip() for line in f]\n",
        "\n",
        "with open(\"test.txt\") as f:\n",
        "    refs = [line.strip() for line in f]"
      ],
      "metadata": {
        "id": "mmHW3mOa625P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cands[0]"
      ],
      "metadata": {
        "id": "FSg-O_G_65Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When you are running this cell for the first time,\n",
        "# it will download the BERT model which will take relatively longer.\n",
        "# for Urdu, lang=\"others\" and for English, lang=\"en\"\n",
        "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)"
      ],
      "metadata": {
        "id": "e9q_Mlt467lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F1"
      ],
      "metadata": {
        "id": "kipFMwz17FnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def save_scores_to_file(scores, output_file):\n",
        "    with open(output_file, 'w', encoding='utf-8') as out_file:\n",
        "        for score in scores:\n",
        "            # Convert the tensor value to a float and save to the output file\n",
        "            out_file.write(f\"{score:.4f}\\n\")\n",
        "\n",
        "# Example usage\n",
        "# Replace 'bert_scores_tensor' and 'bert_scores.txt' with your tensor and desired output file\n",
        "bert_scores_tensor = F1\n",
        "# bert_scores_tensor = torch.tensor(copy torch F1 score here)\n",
        "\n",
        "output_file = 'bert_scores.txt'\n",
        "\n",
        "# Convert the tensor to a list and save BERT scores line by line to a file\n",
        "bert_scores_list = bert_scores_tensor.tolist()\n",
        "save_scores_to_file(bert_scores_list, output_file)\n"
      ],
      "metadata": {
        "id": "bRLB91f37tFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using github directory..."
      ],
      "metadata": {
        "id": "3lTUxSP-7vtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Tiiiger/bert_score\n"
      ],
      "metadata": {
        "id": "VtIG3Ewx1K30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e936898f-0576-4cac-c24b-139c40aef959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bert_score'...\n",
            "remote: Enumerating objects: 993, done.\u001b[K\n",
            "remote: Counting objects: 100% (355/355), done.\u001b[K\n",
            "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
            "remote: Total 993 (delta 219), reused 321 (delta 197), pack-reused 638\u001b[K\n",
            "Receiving objects: 100% (993/993), 1.34 MiB | 8.48 MiB/s, done.\n",
            "Resolving deltas: 100% (534/534), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd bert_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX7_ADtRSPwT",
        "outputId": "953e0290-96aa-47fd-ac48-2d0b2cfe39b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bert_score\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfERvqoESS9R",
        "outputId": "8562a4ba-31d9-4a11-dd5b-78ff5ee99f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/bert_score\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13) (2.1.0+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13) (1.5.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13) (4.35.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13) (4.66.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score==0.3.13) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score==0.3.13) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (0.20.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (0.4.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score==0.3.13) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score==0.3.13) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score==0.3.13) (1.3.0)\n",
            "Building wheels for collected packages: bert-score\n",
            "  Building wheel for bert-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-score: filename=bert_score-0.3.13-py3-none-any.whl size=61125 sha256=cc33e1170c9396dca06f28f9239be8ffedc419343510a2c99cf7d6537aa11d7b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4y_6v7wl/wheels/45/60/ae/f2f7d3e86a5863e0c2bfadd900eb5e6678a6cc956a71983310\n",
            "Successfully built bert-score\n",
            "Installing collected packages: bert-score\n",
            "Successfully installed bert-score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m unittest discover\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Yxi-cO6SaAG",
        "outputId": "d91dcccd-d0ff-45f9-fd49-541a24dc3b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 482/482 [00:00<00:00, 1.64MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 18.4MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 7.08MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 56.8MB/s]\n",
            "model.safetensors: 100% 1.42G/1.42G [00:15<00:00, 93.7MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".sSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 14 tests in 109.080s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for 'Urdu' specifically, we mention multi-lingual BERT model 'bert-base-multilingual-cased'."
      ],
      "metadata": {
        "id": "ilsiVxPuTzVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bert-score -r ../test.txt -c ../train_wo_aug.txt --model bert-base-multilingual-cased"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV4F1vSPSjVr",
        "outputId": "550b3b1c-6fbf-4412-b664-f7dd13766db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rtokenizer_config.json:   0% 0.00/29.0 [00:00<?, ?B/s]\rtokenizer_config.json: 100% 29.0/29.0 [00:00<00:00, 134kB/s]\n",
            "config.json: 100% 625/625 [00:00<00:00, 3.09MB/s]\n",
            "vocab.txt: 100% 996k/996k [00:00<00:00, 15.7MB/s]\n",
            "tokenizer.json: 100% 1.96M/1.96M [00:00<00:00, 26.0MB/s]\n",
            "model.safetensors: 100% 714M/714M [00:06<00:00, 106MB/s]\n",
            "bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.35.2)_fast-tokenizer P: 0.854723 R: 0.853493 F1: 0.853797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calculating COMET score for urdu generation.**"
      ],
      "metadata": {
        "id": "yTKMR_S7qojw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "id": "w-UZVQ7UwEmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unbabel-comet"
      ],
      "metadata": {
        "id": "YpwmA6kKqv0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "Hn7yukK0u5Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "\n",
        "import comet  # From: unbabel-comet\n",
        "import datasets\n",
        "import torch\n",
        "\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "Ik523fqauoOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "#comet_metric = load('metrics/comet/comet.py')\n",
        "comet_metric = load('comet')\n",
        "comet_metric = load('comet', 'wmt-large-hter-estimator')\n",
        "source = [\"Dem Feuer konnte Einhalt geboten werden\", \"Schulen und Kindergärten wurden eröffnet.\"]\n",
        "hypothesis = [\"The fire could be stopped\", \"Schools and kindergartens were open\"]\n",
        "reference = [\"They were able to control the fire.\", \"Schools and kindergartens opened\"]\n",
        "predictions = comet_metric.compute(predictions=hypothesis, references=reference, sources=source)\n",
        "predictions['scores']"
      ],
      "metadata": {
        "id": "C1om-qKUudcg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "867f2cc2ff0e40bca17886ff9b013266",
            "2e371d577cb042dd9ecb2de1cbb743bd",
            "a626b63631a9422e91b0cba01b118209",
            "bed9fdf469e8427caaf1e70ae7e3b574",
            "a3e04008e23e41b8a3712e62b333ae34",
            "d0dec231f67a4f95bd20a28fc9d4458a",
            "d5333a1b2cf6416ab59cddc6657c96e8",
            "57010e83bdfa43fb9788080834e5069c",
            "2426f951f10e48b69ab2b754d58f2f51",
            "be5258c1e9704fc8b01e0bd6405ffeea",
            "c872d6274944404f8a3614a0aa329000"
          ]
        },
        "outputId": "209bf29e-601a-488b-8b4b-f816f36bbcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "867f2cc2ff0e40bca17886ff9b013266"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.1.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/371e9839ca4e213dde891b066cf3080f75ec7e72/checkpoints/model.ckpt`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from comet import comet_score\n",
        "from evaluate import load\n",
        "#comet_metric = load('metrics/comet/comet.py')\n",
        "comet_metric = load('comet')\n",
        "\n",
        "# Load reference and generated text from files\n",
        "with open('ref.txt', 'r', encoding='utf-8') as file:\n",
        "    reference_text = file.read()\n",
        "\n",
        "with open('ref.txt', 'r', encoding='utf-8') as file:\n",
        "    generated_text = file.read()\n",
        "\n",
        "# Calculate COMET score\n",
        "#score = comet_score(reference_text, generated_text, language='urdu')\n",
        "\n",
        "#predictions = comet_metric.compute(predictions=hypothesis, references=reference, sources=source)\n",
        "predictions = comet_metric.compute(predictions=reference_text, references=reference_text, sources=reference_text)\n",
        "predictions['scores']\n",
        "\n",
        "#print(f\"COMET Score: {score}\")\n"
      ],
      "metadata": {
        "id": "pLz9xManqt7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filtering SMATCH data"
      ],
      "metadata": {
        "id": "vOtndj5J_zIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_line_numbers(input_file, output_file):\n",
        "    with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
        "         open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "        for line in infile:\n",
        "            # Split each line at ':' and keep only the part after the colon\n",
        "            parts = line.split(':')\n",
        "            if len(parts) == 2:\n",
        "                try:\n",
        "                    # Attempt to convert the part after the colon to a float\n",
        "                    float_value = float(parts[1].strip())\n",
        "                    outfile.write(f\"{float_value:.15f}\\n\")\n",
        "                except ValueError:\n",
        "                    # Handle cases where the conversion to float fails\n",
        "                    print(f\"Warning: Skipping line due to invalid format: {line}\")\n",
        "\n",
        "# Example usage\n",
        "input_file_path = 'par_w_aug.txt'\n",
        "output_file_path = 'smatch1.txt'\n",
        "\n",
        "remove_line_numbers(input_file_path, output_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5nEI6N-_140",
        "outputId": "8dae0850-de66-417c-a8f1-85869014a43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping line due to invalid format: generated sbn 4 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 7 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 38 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 47 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 71 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 108 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 153 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 175 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 189 error: Exporting a cyclic SBN graph to Penman is not possible.\n",
            "\n",
            "Warning: Skipping line due to invalid format: original sbn 306 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 317 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 366 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 367 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 425 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 429 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 519 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 559 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: original sbn 571 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 579 error: Exporting a cyclic SBN graph to Penman is not possible.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 597 error: Exporting a cyclic SBN graph to Penman is not possible.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 616 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 622 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 624 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 634 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 639 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 677 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 685 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 686 error: Exporting a cyclic SBN graph to Penman is not possible.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 711 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 719 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 727 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 761 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 792 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 793 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 802 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 835 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 859 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 873 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n",
            "Warning: Skipping line due to invalid format: generated sbn 885 error: Strict evaluation mode, possibly ill-formed graph not exported.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}