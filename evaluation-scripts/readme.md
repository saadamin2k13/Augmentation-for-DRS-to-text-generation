### This folder contains scripts to evaluate model-generated text using automatic evaluation metrics.

**A. sentence-wise evaluation score will evaluate text for:**

1. *BLEU*

2. *METEOR*
  
3. *ROUGE*
 
4. *NIST*
 
5. *CIDEr*
 
6. *BERT-Score*
 

**B. test significance script will calculate the statistical significance of the evaluation scores.**

to run 'testSignificance.py' python ==2.7
