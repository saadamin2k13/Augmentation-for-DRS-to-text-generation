{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**In this python code, PMB-Gold training file is used to perform quantity change augmentation.**"
      ],
      "metadata": {
        "id": "L5wH6HdeNZ9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hKuvXjm3anHX",
        "outputId": "60e88c1d-b930-4e73-e8b1-f71171db1ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yleMiIE2rW_B"
      },
      "outputs": [],
      "source": [
        "!wget \"https://pmb.let.rug.nl/releases/exp_data_3.0.0.zip\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip exp_data_3.0.0.zip\n"
      ],
      "metadata": {
        "id": "UnVnGy_1reA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv pmb_exp_data_3.0.0 en-data\n"
      ],
      "metadata": {
        "id": "WZ6JzBxCrrE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm exp_data_3.0.0.zip\n"
      ],
      "metadata": {
        "id": "JcaSeEf-r6CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd en-data\n"
      ],
      "metadata": {
        "id": "TofKKB_4r8Sg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8483781e-8b79-4e67-e021-09f80b127c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/en-data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir gold-silver-raw\n"
      ],
      "metadata": {
        "id": "2pweT7D_r-K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf de/ it/ nl/"
      ],
      "metadata": {
        "id": "amRzqCV5sAbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf gold-silver-raw"
      ],
      "metadata": {
        "id": "QePbG-QksDFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd en"
      ],
      "metadata": {
        "id": "438_8-kIsFIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b84901-8068-4b8f-d9ec-31af97062ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/en-data/en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf silver/ bronze/"
      ],
      "metadata": {
        "id": "OIubm-VPsHSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd gold/"
      ],
      "metadata": {
        "id": "XuTjivX9sJYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573b6cbd-3c14-43a3-e9ea-6d84e985b37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/en-data/en/gold\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rm dev.txt dev.txt.raw test.txt test.txt.raw"
      ],
      "metadata": {
        "id": "vaeP2qN3sLnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../../../"
      ],
      "metadata": {
        "id": "TlOX_4TUt-il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3fac0a-848a-44c8-d36c-5308ae6a790e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv ./en-data/en/gold/train.txt ."
      ],
      "metadata": {
        "id": "AGoA_j-bmq7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv ./en-data/en/gold/train.txt.raw ."
      ],
      "metadata": {
        "id": "RNZj8-P1m0OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf en-data/"
      ],
      "metadata": {
        "id": "lD884jhUm4GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7En9tmx1jKzE",
        "outputId": "f483e81a-55e4-48f9-9808-e1281afd5de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  train.txt  train.txt.raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code below use name-parser as a tool to get person-names from file. It uses NLTK pipeline to extract person-names. In our case it does not work well. So i used SpaCy for name-extraction."
      ],
      "metadata": {
        "id": "YqX1pGeNNQXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install nameparser"
      ],
      "metadata": {
        "id": "mk9PpTGxCdSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install nltk"
      ],
      "metadata": {
        "id": "iNOlVz6rDJa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the code to get human names from text.raw files. So we can have a list of all the names to be replaced with."
      ],
      "metadata": {
        "id": "yALmwBPyD5u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from itertools import count\n",
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "# nltk.download('maxent_ne_chunker')\n",
        "# nltk.download('words')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "# from nameparser.parser import HumanName\n",
        "# from nltk.corpus import wordnet\n",
        "\n",
        "\n",
        "# person_list = []\n",
        "# person_names=person_list\n",
        "# def get_human_names(text):\n",
        "#     tokens = nltk.tokenize.word_tokenize(text)\n",
        "#     pos = nltk.pos_tag(tokens)\n",
        "#     sentt = nltk.ne_chunk(pos, binary = False)\n",
        "\n",
        "#     person = []\n",
        "#     name = \"\"\n",
        "#     for subtree in sentt.subtrees(filter=lambda t: t.label() == 'PERSON'):\n",
        "#         for leaf in subtree.leaves():\n",
        "#             person.append(leaf[0])\n",
        "#         if len(person) > 1: #avoid grabbing lone surnames\n",
        "#             for part in person:\n",
        "#                 name += part + ' '\n",
        "#             if name[:-1] not in person_list:\n",
        "#                 person_list.append(name[:-1])\n",
        "#             name = ''\n",
        "#         person = []\n",
        "# #     print (person_list)\n",
        "\n",
        "# with open('train.txt.raw') as r, open('list-of-names.txt.raw', 'w') as w:\n",
        "#   text = r.read()\n",
        "#     #done.write(re.sub(r'\\b\\w+\\b', lambda x: word_list.get(x.group(), x.group()), text))\n",
        "\n",
        "# #with open(\"train.txt.raw\") as r:\n",
        "# #  text = r.read()\n",
        "\n",
        "#   names = get_human_names(text)\n",
        "#   for person in person_list:\n",
        "#       person_split = person.split(\" \")\n",
        "#       for name in person_split:\n",
        "#           if wordnet.synsets(name):\n",
        "#               if(name in person):\n",
        "#                   person_names.remove(person)\n",
        "#                   break\n",
        "#   w.write(\"\\n\".join(person_names))\n",
        "# print(person_names)\n",
        "# print(len(person_names))\n"
      ],
      "metadata": {
        "id": "9-wKJaPBCX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lower case and upper case changing of names"
      ],
      "metadata": {
        "id": "QPZste1KnIND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !dd if=list-of-names.txt.raw of=lower-case-names.txt.raw conv=lcase\n"
      ],
      "metadata": {
        "id": "XiUpxJAWnNFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code to get list of country names from dataset"
      ],
      "metadata": {
        "id": "KkjIVY8OIAvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pycountry"
      ],
      "metadata": {
        "id": "l3b5Y7uFIX3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import pycountry\n",
        "\n",
        "#with open('train.txt.raw') as r, open('list-of-cities.txt.raw', 'w') as w:\n",
        "#  text = r.read()\n",
        "\n",
        "\n",
        "#with open(\"train.txt.raw\") as r:\n",
        "#  text = r.read()\n",
        "\n",
        "#text = \"United States (New York), United Kingdom (London)\"\n",
        "#  for country in pycountry.countries:\n",
        "#      if country.name in text:\n",
        "#          print(country.name)\n",
        "#  w.write(\"\\n\".join(name))\n",
        "#print(len(country.name))\n",
        "\n"
      ],
      "metadata": {
        "id": "Rst1EFVdIYkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**==> Here we extract location-names from dataset.**"
      ],
      "metadata": {
        "id": "IImzjwfBRUGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "location based names extraction"
      ],
      "metadata": {
        "id": "wyvWv7z7M2fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install locationtagger"
      ],
      "metadata": {
        "id": "uddcbsWYM7ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting names of countries"
      ],
      "metadata": {
        "id": "vA4sB1nUt5_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locationtagger\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "#from nameparser.parser import HumanName\n",
        "#from nltk.corpus import wordnet\n",
        "\n",
        "with open(\"train.txt.raw\") as r, open('list-of-country.txt.raw', 'w') as co:\n",
        "  sample_text = r.read()\n",
        "\n",
        "# extracting entities.\n",
        "  place_entity = locationtagger.find_locations(text = sample_text)\n",
        "\n",
        "# getting all countries\n",
        "  print(\"The countries in text : \")\n",
        "  print(place_entity.countries)\n",
        "  co.write(\"\\n\".join(place_entity.countries))\n",
        "  print(len(place_entity.countries))\n"
      ],
      "metadata": {
        "id": "v8bZ5LT8t5jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=list-of-country.txt.raw of=lower-case-country.txt.raw conv=lcase\n"
      ],
      "metadata": {
        "id": "Rdk3IKEtv22W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting names of states/regions"
      ],
      "metadata": {
        "id": "is3DvAHDuky2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locationtagger\n",
        "\n",
        "with open(\"train.txt.raw\") as r, open('list-of-states.txt.raw', 'w') as s:\n",
        "  sample_text = r.read()\n",
        "\n",
        "# extracting entities.\n",
        "  place_entity = locationtagger.find_locations(text = sample_text)\n",
        "  # getting all states\n",
        "  print(\"The states in text : \")\n",
        "  print(place_entity.regions)\n",
        "  s.write(\"\\n\".join(place_entity.regions))\n",
        "  print(len(place_entity.regions))\n",
        "\n"
      ],
      "metadata": {
        "id": "0hu-koQauv66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0f0a98-2a33-4049-d036-03f8cfc6cf66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The states in text : \n",
            "['Seoul', 'Taiwan', 'Nara', 'Gifu', 'North', 'England', 'Leeds', 'Coventry', 'Liverpool', 'Milan', 'Florence', 'Rome', 'Pisa', 'Venice', 'Tel Aviv', 'Lisbon', 'Moscow', 'Barcelona', 'Madrid', 'Bavaria', 'Connecticut', 'Massachusetts', 'Illinois', 'New York', 'Rhode Island', 'California', 'Ohio', 'Texas', 'Washington', 'Missouri', 'North Carolina', 'Louisiana', 'Utah', 'Michigan', 'Nebraska', 'South', 'Istanbul', 'Paris', 'Vienna', 'Alaska', 'Saskatchewan', 'Kashmir', 'Okinawa', 'Hiroshima', 'Niigata', 'Rio de Janeiro', 'Alexandria', 'Edo', 'Paola', 'Northwest', 'Fukui', 'Nagasaki', 'Portland']\n",
            "53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=list-of-states.txt.raw of=lower-case-state.txt.raw conv=lcase\n"
      ],
      "metadata": {
        "id": "ClKOta5BwOUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting names of cities"
      ],
      "metadata": {
        "id": "wgCdNnbhwGvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locationtagger\n",
        "\n",
        "with open(\"train.txt.raw\") as r, open('list-of-cities.txt.raw', 'w') as ci:\n",
        "  sample_text = r.read()\n",
        "\n",
        "# extracting entities.\n",
        "  place_entity = locationtagger.find_locations(text = sample_text)\n",
        "# getting all cities\n",
        "  print(\"The cities in text : \")\n",
        "  print(place_entity.cities)\n",
        "  ci.write(\"\\n\".join(place_entity.cities))\n",
        "  print(len(place_entity.cities))"
      ],
      "metadata": {
        "id": "f7SWYb6OM5m-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9225b2-834b-4adf-e86a-629e0bb44c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cities in text : \n",
            "['Tokyo', 'Beijing', 'Seoul', 'Delhi', 'Kawasaki', 'Yokohama', 'Melbourne', 'Nagoya', 'Kyoto', 'Matsuyama', 'Nara', 'Kobe', 'Darwin', 'Nantes', 'London', 'York', 'Leeds', 'Coventry', 'March', 'Lincoln', 'Liverpool', 'Milan', 'Florence', 'Rome', 'Pisa', 'Venice', 'Formigine', 'Tel Aviv', 'Jerusalem', 'Marco', 'Lisbon', 'Paul', 'Athens', 'Moscow', 'Boston', 'Ferrari', 'Anna', 'Washington', 'Barcelona', 'Madrid', 'Oslo', 'Leipzig', 'Farsi', 'Berlin', 'Vinci', 'Chicago', 'New York', 'Portland', 'San Francisco', 'Alexandria', 'Buffalo', 'Clinton', 'Jackson', 'Fort Worth', 'Dallas', 'Los Angeles', 'New Orleans', 'Edison', 'Seattle', 'San Jose', 'Las Vegas', 'Frederick', 'Salt Lake City', 'Detroit', 'Elizabeth', 'Baghdad', 'Istanbul', 'Budapest', 'Paris', 'Nancy', 'Mecca', 'Vienna', 'Aachen', 'Tbilisi', 'Pskov', 'Canadian', 'California', 'Egypt', 'Vicksburg', 'Pacific', 'Lebanon', 'Vance', 'Mexico', 'Holland', 'Newton', 'Bell', 'Grant', 'Paola', 'Cameron', 'Hebron', 'Tracy', 'Liberty', 'Patterson', 'Hope', 'Alice', 'Farmville', 'Harvard', 'Thomas', 'Scott', 'Yale', 'Chelsea', 'Everest', 'Baker', 'Cuba', 'Singapore', 'Bali', 'Shanghai', 'Scotland', 'Bountiful', 'Peru', 'Apollo', 'Hooper', 'Roy', 'St. Helena', 'Amelia', 'Hadley', 'Napoleon', 'Jack', 'Charlemagne', 'Alexander', 'Oscar', 'Babylon', 'Othello', 'Rex', 'Brazil', 'Mars', 'Cairo', 'Achille', 'Laura', 'Munich', 'Spanish', 'White', 'Malta', 'Roosevelt', 'Belgium', 'Hughes', 'Reform', 'Arthur', 'Buenos Aires', 'Bruce', 'Osaka', 'Sendai', 'Sapporo', 'Fuji', 'Kanazawa', 'Niigata', 'God', 'Ford', 'Marc', 'Maastricht', 'Madonna', 'Basra', 'Rio de Janeiro', 'Hong Kong', 'Jones', 'Pretoria', 'Kinshasa', 'Marrakesh', 'George', 'Tama', 'America', 'Gibraltar', 'Hiroshima', 'Bach', 'Aschersleben', 'Okinawa', 'Usa', 'Ohio', 'Dawson', 'Helen', 'Lewis', 'Poland', 'War', 'Gifu', 'Ikeda', 'Sakura', 'Hashimoto', 'Narita', 'Nagasaki', 'Marie', 'Klagenfurt', 'Maria', 'Mary', 'Lech', 'Champagne', 'Maximilian', 'Ireland', 'Hasselt', 'Venus', 'Ruth', 'Magdalena', 'Van Horn', 'Merlin', 'Elba', 'Queen Anne', 'Bush', 'Rio', 'Smith', 'Atlantic', 'Christmas', 'Elaine', 'Norway', 'Becker', 'Margaret', 'Lake', 'Louisiana', 'Kennedy', 'Leonardo', 'Tony', 'Mayflower', 'Nixon', 'Lopez', 'Max', 'Turkey', 'Corsica', 'Strong', 'North', 'China', 'Italy', 'Bolivia', 'Coleridge', 'Abrams', 'Russia', 'England', 'Milo', 'Palm', 'May', 'Emily', 'Sarah', 'Man', 'Swiss', 'Shiro', 'Us', 'Moncalvo', 'Requena', 'Andorra', 'Jesus', 'Four', 'Castro', 'Robert', 'Spain', 'Pedro', 'Rosa', 'Elena', 'Heather', 'Wang', 'Suzanne', 'Long', 'Charles', 'Kuzey', 'Jeff', 'Lipton', 'Kashmir', 'Kashgar', 'Thames', 'Trang', 'Kanda', 'University', 'Tanaka', 'Krypton', 'Schneider', 'Mark', 'Tower', 'Bill', 'Suzano', 'Sao Paulo', 'German', 'Lenz', 'Frank', 'Obama', 'Fukui', 'Nine', 'Gamble', 'Kraft', 'Speed', 'Andes', 'Green', 'Yamada', 'Midnight', 'Normandy', 'Argentina', 'English', 'Canada', 'Dawn', 'Marks', 'Pope', 'Syria', 'Morocco', 'Finland', 'Michigan', 'Wood', 'Strawberry', 'Luna', 'Daniel', 'Patricia']\n",
            "295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=list-of-cities.txt.raw of=lower-case-city.txt.raw conv=lcase\n"
      ],
      "metadata": {
        "id": "n1M9hJgnwUri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4419bcb6-58b6-45ff-f706-6f3bc3190c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1+1 records in\n",
            "1+1 records out\n",
            "853 bytes copied, 0.000319608 s, 2.7 MB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK was not working perfectly with name extraction. so i changed it with SpaCy pipeline to extract names from original dataset file.**"
      ],
      "metadata": {
        "id": "76dhMXGS7YRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "id": "bwW4JXFV8P_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg\n"
      ],
      "metadata": {
        "id": "5KhmyX-y9ZeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy is used to extract names from original text files. Same names will also be used in DRS for name-change purposes. **"
      ],
      "metadata": {
        "id": "nHn19JRK7tBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "text=open('train.txt.raw').read()\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "sents = nlp(open('train.txt.raw').read()).to_json()\n",
        "\n",
        "people=[ee for ee in sents['ents'] if ee['label'] == 'PERSON']\n",
        "#print(people)\n",
        "\n",
        "f = open(\"names.txt.raw\", \"w\")\n",
        "#f.write(\"Woops! I have deleted the content!\")\n",
        "\n",
        "for pps in people:\n",
        "    #print(text[pps['start']:pps['end']])\n",
        "    f.write(text[pps['start']:pps['end']] + '\\n')\n",
        "#print(len(text))\n",
        "f.close()\n"
      ],
      "metadata": {
        "id": "9wkejsy67-o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using SpaCy, we get all the names in the linear text. but this also include duplication in names. Code below will remove the duplicate names collected from above file and save it into a new file with unique names.**"
      ],
      "metadata": {
        "id": "dThCuiHbLeaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('names.txt.raw') as result:\n",
        "        uniqlines = set(result.readlines())\n",
        "        with open('unique_names.txt.raw', 'w') as rmdup:\n",
        "            rmdup.writelines(set(uniqlines))"
      ],
      "metadata": {
        "id": "vqPmmrubJSuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odyUuByk_SVf",
        "outputId": "00d39b5c-8fd7-4169-f95c-7e68745e9251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names.txt.raw  \u001b[0m\u001b[01;34msample_data\u001b[0m/  train.txt.raw  unique_names.txt.raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**while creating dictionary for our name-change strategy, we can not change first and last names simantinously. Therefore, i split them w.r.t space and newline.**"
      ],
      "metadata": {
        "id": "AC97SaqM8aqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('unique_names.txt.raw', 'r') as infile, open('single_names.txt.raw', 'w') as outfile:\n",
        "    data = infile.readlines()\n",
        "    for i in data:\n",
        "        outfile.write('\\n'.join(i.split())+'\\n')\n",
        "        #print(i.split())\n"
      ],
      "metadata": {
        "id": "CJwFHT3Dz72D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to check manually for all the correct **unique single** names."
      ],
      "metadata": {
        "id": "hp5Wg0UD_iTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('unique_names.txt.raw') as result:\n",
        "        uniqlines = set(result.readlines())\n",
        "        with open('unique_single_names.txt.raw', 'w') as rmdup:\n",
        "            rmdup.writelines(set(uniqlines))"
      ],
      "metadata": {
        "id": "p3P7k0v5BcMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**code below will prepare multiple names as they are mentioned in DRS.**"
      ],
      "metadata": {
        "id": "OP7wDYMmh-Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input file\n",
        "fin = open(\"lower-case-city.txt.raw\", \"rt\")\n",
        "#output file to write the result to\n",
        "fout = open(\"connected-cities.txt.raw\", \"wt\")\n",
        "#for each line in the input file\n",
        "for line in fin:\n",
        "#read replace the string and write to output file\n",
        "  fout.write(line.replace(' ', '~'))\n",
        "#close input and output files\n",
        "fin.close()\n",
        "fout.close()"
      ],
      "metadata": {
        "id": "UIsXP8nMhl9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**converting unique single person-names into lower-case. Because in DRS, all names are in lower case.**"
      ],
      "metadata": {
        "id": "Gb65tr2xQb_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=unique_names.txt.raw of=lower-case-unique_names.txt.raw conv=lcase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8XBD6wsOs_a",
        "outputId": "03a73719-aa32-41d9-c59c-198d446adc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10+1 records in\n",
            "10+1 records out\n",
            "5362 bytes (5.4 kB, 5.2 KiB) copied, 0.000605925 s, 8.8 MB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**converting unique single person-names into captalized case. Because in DRS label and in linear text, all the names are in Captalized case.**"
      ],
      "metadata": {
        "id": "7qVsMCwfQi8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python program to read a file and capitalize\n",
        "# the first letter of every word in the file.\n",
        "\n",
        "# A file named \"gfg\", will be opened with the\n",
        "# reading mode.\n",
        "file_gfg = open('unique_names.txt.raw', 'r')\n",
        "cap_name = open('cap-case-unique_names.txt.raw','w')\n",
        "\n",
        "# This will traverse through every line one by one\n",
        "# in the file\n",
        "for line in file_gfg:\n",
        "\n",
        "    # This will convert the content\n",
        "    # of that line with capitalized\n",
        "    # first letter of every word\n",
        "    output = line.title()\n",
        "    cap_name.write(output)\n",
        "\n",
        "    # This will print the output\n",
        "    #print(output)"
      ],
      "metadata": {
        "id": "rWaQWPn3Qnl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code to get original names from one-file, swap them with another-file and replace the contents in new file by comparing them with dataset txt.raw file.**"
      ],
      "metadata": {
        "id": "wPSDjErGmGGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Here i am reading original names of dataset.\n",
        "# lines_1 = []\n",
        "# with open(\"1.txt\") as file:\n",
        "#     for line in file:\n",
        "#         line = line.strip() #or some other preprocessing\n",
        "#         lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# # Here i am reading replaceable names in the dataset.\n",
        "# lines_2 = []\n",
        "# with open(\"2.txt\") as file:\n",
        "#     for line in file:\n",
        "#         line = line.strip() #or some other preprocessing\n",
        "#         lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "# # here i am opening out_file to write contents.\n",
        "# fout = open(\"out.txt\",\"wt\")\n",
        "\n",
        "\n",
        "# # here i am trying to find list_1 word in txt.raw file\n",
        "# with open('train.txt.raw', \"r+\") as fin:\n",
        "#     fin_lines = fin.readlines()\n",
        "#     for x,y in zip(lines_1,lines_2): # <--- Loop through the list to check\n",
        "#         for line in fin_lines: # <--- Loop through each line\n",
        "#             if x in line:\n",
        "#               print(x)\n",
        "#               fout.write(line.replace(x,y))\n",
        "#                  #print(x)\n",
        "\n",
        "# fout.close()"
      ],
      "metadata": {
        "id": "qGhzyDeJEZyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***For name-augmentation in dataset text file, we need all names in Captalized_Case format. Therefor, we read our unique_single-Cap-Case name file.***"
      ],
      "metadata": {
        "id": "lfmSV-0_C1xu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--> Generating dictionary of cities.**"
      ],
      "metadata": {
        "id": "AfsgKN0GvRa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "City list can be downloaded from the following link.\n",
        "https://gist.github.com/norcal82/4accc0d968444859b408\n",
        "https://simplemaps.com/data/it-cities"
      ],
      "metadata": {
        "id": "AiJs7SaRvVXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "lines_1 = []\n",
        "with open(\"connected-cities.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_2 = []\n",
        "with open(\"replaceable-cities.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "for x,y in zip(lines_1,lines_2): # <--- Loop through the list to check\n",
        "  print(\"'\"+x+\"'\",\":\",\"'\"+y+\"'\",\",\")"
      ],
      "metadata": {
        "id": "301SwE_qwA35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating lower-case city-names**"
      ],
      "metadata": {
        "id": "niwbkc24xXwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=cap-case-city.txt.raw of=lower-case-city.txt.raw conv=lcase"
      ],
      "metadata": {
        "id": "JlBDHedmxb2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecf429b-da07-491c-ec4f-adc12940c49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18+1 records in\n",
            "18+1 records out\n",
            "9489 bytes (9.5 kB, 9.3 KiB) copied, 0.000587248 s, 16.2 MB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=replaceable-cities.txt.raw of=lower-case-replaceable_cities.txt.raw conv=lcase"
      ],
      "metadata": {
        "id": "ziCu-UnPxhk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "lines_1 = []\n",
        "with open(\"cap-case-city.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_2 = []\n",
        "with open(\"cap-case-replace-city.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "lines_3 = []\n",
        "with open(\"lower-case-city.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_3.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_4 = []\n",
        "with open(\"lower-case-replace-city.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_4.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "for x,y,z,w in zip(lines_1,lines_2,lines_3,lines_4): # <--- Loop through the list to check\n",
        "  print(\"'\"+x+\"'\",\":\",\"'\"+y+\"'\",\",\",\"'\"+z+\"'\",\":\",\"'\"+w+\"'\",\",\")"
      ],
      "metadata": {
        "id": "7EkJT1KlxtwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--> Generating dictionary of states.**"
      ],
      "metadata": {
        "id": "n9bNXXHwprBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "State list can be downloaded from the following link...\n",
        "https://gist.github.com/norcal82/c219ecf9b932d7db4ee6\n",
        "https://gist.github.com/JayHoltslander/c1c4e7f72e803a30a5466a69c5fe4927"
      ],
      "metadata": {
        "id": "Ehy6XrSppwMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "lines_1 = []\n",
        "with open(\"connected-states.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_2 = []\n",
        "with open(\"replaceable-states.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "for x,y in zip(lines_1,lines_2): # <--- Loop through the list to check\n",
        "  print(\"'\"+x+\"'\",\":\",\"'\"+y+\"'\",\",\")"
      ],
      "metadata": {
        "id": "O6r-Ys_Er0xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**generating lower-case states names**"
      ],
      "metadata": {
        "id": "SW2RpLT3sRTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=list-of-states.txt.raw of=lower-case-state_names.txt.raw conv=lcase"
      ],
      "metadata": {
        "id": "241PwxeBsVBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=cap-case-replace-state.txt.raw of=lower-case-replace-state.txt.raw conv=lcase"
      ],
      "metadata": {
        "id": "6U98xPbXsZEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7af1c3f-0e1c-4339-a4de-8d0b802f5e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2+1 records in\n",
            "2+1 records out\n",
            "1471 bytes (1.5 kB, 1.4 KiB) copied, 0.000270741 s, 5.4 MB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "lines_1 = []\n",
        "with open(\"cap-case-state.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_2 = []\n",
        "with open(\"cap-case-replace-state.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "lines_3 = []\n",
        "with open(\"lower-case-state.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_3.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_4 = []\n",
        "with open(\"lower-case-replace-state.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_4.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "for x,y,z,w in zip(lines_1,lines_2,lines_3,lines_4): # <--- Loop through the list to check\n",
        "  print(\"'\"+x+\"'\",\":\",\"'\"+y+\"'\",\",\",\"'\"+z+\"'\",\":\",\"'\"+w+\"'\",\",\")"
      ],
      "metadata": {
        "id": "kgg4LHrKtbtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--> Generating dictionary of countries.**"
      ],
      "metadata": {
        "id": "B2ECWgHnmPw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Country list can be obtained from the following link...\n",
        "https://www.countries-ofthe-world.com/all-countries.html"
      ],
      "metadata": {
        "id": "nFZ_r1KSpKYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "lines_1 = []\n",
        "with open(\"connected-countries.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_2 = []\n",
        "with open(\"replaceable-countries.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "for x,y in zip(lines_1,lines_2): # <--- Loop through the list to check\n",
        "  print(\"'\"+x+\"'\",\":\",\"'\"+y+\"'\",\",\")"
      ],
      "metadata": {
        "id": "ladMiTPxmKva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**converting country-names into lower-case**"
      ],
      "metadata": {
        "id": "X6dYT7CmnLEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=cap-case-country.txt.raw of=lower-case-country.txt.raw conv=lcase"
      ],
      "metadata": {
        "id": "r70g9BAOnU7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=cap-case-replace-country.txt.raw of=lower-case-replace-country.txt.raw conv=lcase"
      ],
      "metadata": {
        "id": "Xu-GIclNno1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generting country dictionary for DRS.**"
      ],
      "metadata": {
        "id": "CHmb6534nybX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "lines_1 = []\n",
        "with open(\"cap-case-country.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_2 = []\n",
        "with open(\"cap-case-replace-country.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "lines_3 = []\n",
        "with open(\"lower-case-country.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_3.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_4 = []\n",
        "with open(\"lower-case-replace-country.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_4.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "for x,y,z,w in zip(lines_1,lines_2,lines_3,lines_4): # <--- Loop through the list to check\n",
        "  print(\"'\"+x+\"'\",\":\",\"'\"+y+\"'\",\",\",\"'\"+z+\"'\",\":\",\"'\"+w+\"'\",\",\")"
      ],
      "metadata": {
        "id": "UWRotBwzoESa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "replace-names are downloaded from the following link.\n",
        "https://www.usna.edu/Users/cs/roche/courses/s15si335/proj1/files.php%3Ff=names.txt&downloadcode=yes"
      ],
      "metadata": {
        "id": "DigzNKjlR7o1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the code below will generate a dictionary of original names and the names replace with for *train.txt.raw* file**"
      ],
      "metadata": {
        "id": "MBoIyPzF5iID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "lines_1 = []\n",
        "with open(\"connected-names.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_2 = []\n",
        "with open(\"replaced-names.txt.raw\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "for x,y in zip(lines_1,lines_2): # <--- Loop through the list to check\n",
        "  print(\"'\"+x+\"'\",\":\",\"'\"+y+\"'\",\",\")"
      ],
      "metadata": {
        "id": "EEJD6DDYqWmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the code below, i will copy the dictionary generated in above code and paste it inside the {}. This will replace the original dataset files with the name-change dataset files.**"
      ],
      "metadata": {
        "id": "jHhmu8W06Tup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--> All text name-change code is mentioned below.**"
      ],
      "metadata": {
        "id": "lrMY2BHSQw__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this dictionary will change names with the names outside of training data.**"
      ],
      "metadata": {
        "id": "arcIAHwtSlvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "word_list = {'David' : 'Michael' ,\n",
        "'Lori' : 'Christopher' ,\n",
        "'Bradtke' : 'Jessica' ,\n",
        "'Brady' : 'Matthew' ,\n",
        "'Monica' : 'Ashley' ,\n",
        "'Keys' : 'Jennifer' ,\n",
        "'Koch' : 'Joshua' ,\n",
        "'Kofi' : 'Amanda' ,\n",
        "'Ayako' : 'Daniel' ,\n",
        "'Sekkura' : 'David' ,\n",
        "'Fatima' : 'James' ,\n",
        "'Cabot' : 'Robert' ,\n",
        "'Damon' : 'John' ,\n",
        "'Reno' : 'Joseph' ,\n",
        "'Castro' : 'Andrew' ,\n",
        "'Aurelius' : 'Ryan' ,\n",
        "'Khalifa' : 'Brandon' ,\n",
        "'Annie' : 'Jason' ,\n",
        "'Noble' : 'Justin' ,\n",
        "'Testing' : 'Sarah' ,\n",
        "'Marika' : 'William' ,\n",
        "'Warhol' : 'Jonathan' ,\n",
        "'Britney' : 'Stephanie' ,\n",
        "'Ronald' : 'Brian' ,\n",
        "'Ibrahim' : 'Nicole' ,\n",
        "'Watanabe' : 'Nicholas' ,\n",
        "'Edith' : 'Anthony' ,\n",
        "'Clinton' : 'Heather' ,\n",
        "'Guus' : 'Eric' ,\n",
        "'Hood' : 'Elizabeth' ,\n",
        "'Yumi' : 'Adam' ,\n",
        "'Stephen' : 'Megan' ,\n",
        "'Sadako' : 'Melissa' ,\n",
        "'Sylvia' : 'Kevin' ,\n",
        "'Berlioz' : 'Steven' ,\n",
        "'Pohl' : 'Thomas' ,\n",
        "'Sasaki' : 'Timothy' ,\n",
        "'Gene' : 'Christina' ,\n",
        "'Melanie' : 'Kyle' ,\n",
        "'Raymond' : 'Rachel' ,\n",
        "'Elke' : 'Laura' ,\n",
        "'Michelangelo' : 'Lauren' ,\n",
        "'Jack' : 'Amber' ,\n",
        "'Yuriko' : 'Brittany' ,\n",
        "'Bieber' : 'Danielle' ,\n",
        "'Qin' : 'Richard' ,\n",
        "'Mei' : 'Kimberly' ,\n",
        "'Irving' : 'Jeffrey' ,\n",
        "'Chisini' : 'Amy' ,\n",
        "'Sandra' : 'Crystal' ,\n",
        "'Judy' : 'Michelle' ,\n",
        "'Zola' : 'Tiffany' ,\n",
        "'Reinsdorf' : 'Jeremy' ,\n",
        "'Cline' : 'Benjamin' ,\n",
        "'Kelly' : 'Mark' ,\n",
        "'Deng' : 'Emily' ,\n",
        "'Mitchell' : 'Aaron' ,\n",
        "'Marie' : 'Charles' ,\n",
        "'Marilyn' : 'Rebecca' ,\n",
        "'Babe' : 'Jacob' ,\n",
        "'Montero' : 'Stephen' ,\n",
        "'William' : 'Patrick' ,\n",
        "'Senna' : 'Sean' ,\n",
        "'Harrison' : 'Erin' ,\n",
        "'Kamal' : 'Zachary' ,\n",
        "'Bin' : 'Jamie' ,\n",
        "'Ali' : 'Kelly' ,\n",
        "'Elvis' : 'Samantha' ,\n",
        "'Osamu' : 'Nathan' ,\n",
        "'John' : 'Sara' ,\n",
        "'Salvador' : 'Dustin' ,\n",
        "'King' : 'Paul' ,\n",
        "'Bérégovoy' : 'Angela' ,\n",
        "'Anderson' : 'Tyler' ,\n",
        "'Goethe' : 'Scott' ,\n",
        "'Maria' : 'Katherine' ,\n",
        "'Amadeus' : 'Andrea' ,\n",
        "'Jackson' : 'Gregory' ,\n",
        "'Robin' : 'Erica' ,\n",
        "'Guillermo' : 'Mary' ,\n",
        "'Snoop' : 'Travis' ,\n",
        "'Mike' : 'Lisa' ,\n",
        "'Browne' : 'Kenneth' ,\n",
        "'Sue' : 'Bryan' ,\n",
        "'Mandela' : 'Lindsey' ,\n",
        "'Christoph' : 'Kristen' ,\n",
        "'Inachis' : 'Jose' ,\n",
        "'Ortiz' : 'Alexander' ,\n",
        "'Carla' : 'Jesse' ,\n",
        "'Green' : 'Katie' ,\n",
        "'Gregory' : 'Lindsay' ,\n",
        "'Jane' : 'Shannon' ,\n",
        "'Chris' : 'Vanessa' ,\n",
        "'Norman' : 'Courtney' ,\n",
        "'Mohammad' : 'Christine' ,\n",
        "'Graham' : 'Alicia' ,\n",
        "'Andy' : 'Cody' ,\n",
        "'Fischer' : 'Allison' ,\n",
        "'Kalinske' : 'Bradley' ,\n",
        "'Hariri' : 'Samuel' ,\n",
        "'Klein' : 'Shawn' ,\n",
        "'Jim' : 'April' ,\n",
        "'Jordan' : 'Derek' ,\n",
        "'Spears' : 'Kathryn' ,\n",
        "'Reagan' : 'Kristin' ,\n",
        "'Vinci' : 'Chad' ,\n",
        "'Kim' : 'Jenna' ,\n",
        "'Ogura' : 'Tara' ,\n",
        "'Hawking' : 'Maria' ,\n",
        "'Lupita' : 'Krystal' ,\n",
        "'Elson' : 'Jared' ,\n",
        "'Sarah' : 'Anna' ,\n",
        "'Gabriel' : 'Edward' ,\n",
        "'Iverson' : 'Julie' ,\n",
        "'Tang' : 'Peter' ,\n",
        "'Charles' : 'Holly' ,\n",
        "'Dick' : 'Marcus' ,\n",
        "'Kieslowski' : 'Kristina' ,\n",
        "'Mitt' : 'Natalie' ,\n",
        "'Yamamoto' : 'Jordan' ,\n",
        "'Leloir' : 'Victoria' ,\n",
        "'Keats' : 'Jacqueline' ,\n",
        "'Chaplin' : 'Corey' ,\n",
        "'Turners' : 'Keith' ,\n",
        "'Bush' : 'Monica' ,\n",
        "'Robinson' : 'Juan' ,\n",
        "'Seiji' : 'Donald' ,\n",
        "'Dib' : 'Cassandra' ,\n",
        "'Lady' : 'Meghan' ,\n",
        "'Wilson' : 'Joel' ,\n",
        "'Zhao' : 'Shane' ,\n",
        "'Maurice' : 'Phillip' ,\n",
        "'Van' : 'Patricia' ,\n",
        "'Eugenio' : 'Brett' ,\n",
        "'Greene' : 'Ronald' ,\n",
        "'Gerulaitis' : 'Catherine' ,\n",
        "'Brett' : 'George' ,\n",
        "'Linux' : 'Antonio' ,\n",
        "'Alice' : 'Cynthia' ,\n",
        "'Tina' : 'Stacy' ,\n",
        "'Debierne' : 'Kathleen' ,\n",
        "'Spencer' : 'Raymond' ,\n",
        "'Presley' : 'Carlos' ,\n",
        "'Shiro' : 'Brandi' ,\n",
        "'Normand' : 'Douglas' ,\n",
        "'Ikeda' : 'Nathaniel' ,\n",
        "'Picasso' : 'Ian' ,\n",
        "'Frank' : 'Craig' ,\n",
        "'Lewis' : 'Brandy' ,\n",
        "'Kennedy' : 'Alex' ,\n",
        "'Trygve' : 'Valerie' ,\n",
        "'John' : 'Veronica' ,\n",
        "'Ianiero' : 'Cory' ,\n",
        "'Jimi' : 'Whitney' ,\n",
        "'Kate' : 'Gary' ,\n",
        "'Gilbert' : 'Derrick' ,\n",
        "'Dean' : 'Philip' ,\n",
        "'Agog' : 'Luis' ,\n",
        "'Dylan' : 'Diana' ,\n",
        "'Hideki' : 'Chelsea' ,\n",
        "'Salam' : 'Leslie' ,\n",
        "'Quentin' : 'Caitlin' ,\n",
        "'Presley' : 'Leah' ,\n",
        "'Dan' : 'Natasha' ,\n",
        "'Jospin' : 'Erika' ,\n",
        "'Milius' : 'Casey' ,\n",
        "'André' : 'Latoya' ,\n",
        "'Von' : 'Erik' ,\n",
        "'Machado' : 'Dana' ,\n",
        "'Ann' : 'Victor' ,\n",
        "'Johnson' : 'Brent' ,\n",
        "'Kazuko' : 'Dominique' ,\n",
        "'Gaulle' : 'Frank' ,\n",
        "'Blunt' : 'Brittney' ,\n",
        "'Tracy' : 'Evan' ,\n",
        "'Jekyll' : 'Gabriel' ,\n",
        "'Steve' : 'Julia' ,\n",
        "'Heidenreich' : 'Candice' ,\n",
        "'Harry' : 'Karen' ,\n",
        "'Marlowe' : 'Melanie' ,\n",
        "'Rosset' : 'Adrian' ,\n",
        "'Argentinean' : 'Stacey' ,\n",
        "'Lennon' : 'Margaret' ,\n",
        "'Louis' : 'Sheena' ,\n",
        "'Yukio' : 'Wesley' ,\n",
        "'Rosario' : 'Vincent' ,\n",
        "'Vitas' : 'Alexandra' ,\n",
        "'Vladislav' : 'Katrina' ,\n",
        "'Politkovskaya' : 'Bethany' ,\n",
        "'Yamaha' : 'Nichole' ,\n",
        "'Piaf' : 'Larry' ,\n",
        "'Hitler' : 'Jeffery' ,\n",
        "'Laden' : 'Curtis' ,\n",
        "'Marquez' : 'Carrie' ,\n",
        "'Woodrow' : 'Todd' ,\n",
        "'Nick' : 'Blake' ,\n",
        "'Papon' : 'Christian' ,\n",
        "'Favre' : 'Randy' ,\n",
        "'Robbins' : 'Dennis' ,\n",
        "'Garcia' : 'Alison' ,\n",
        "'Woolf' : 'Trevor' ,\n",
        "'Lucy' : 'Seth' ,\n",
        "'Henry' : 'Kara' ,\n",
        "'Marge' : 'Joanna' ,\n",
        "'Wallace' : 'Rachael' ,\n",
        "'Yukichi' : 'Luke' ,\n",
        "'Listyev' : 'Felicia' ,\n",
        "'Bill' : 'Brooke' ,\n",
        "'Linda' : 'Austin' ,\n",
        "'Anna' : 'Candace' ,\n",
        "'Vance' : 'Jasmine' ,\n",
        "'Conway' : 'Jesus' ,\n",
        "'Keast' : 'Alan' ,\n",
        "'Raghav' : 'Susan' ,\n",
        "'Andris' : 'Sandra' ,\n",
        "'Cup' : 'Tracy' ,\n",
        "'Sidney' : 'Kayla' ,\n",
        "'Joe' : 'Nancy' ,\n",
        "'Catherine' : 'Tina' ,\n",
        "'Tyler' : 'Krystle' ,\n",
        "'Versace' : 'Russell' ,\n",
        "'Tomba' : 'Jeremiah' ,\n",
        "'Putin' : 'Carl' ,\n",
        "'Majoli' : 'Miguel' ,\n",
        "'Hasselt' : 'Tony' ,\n",
        "'Jones' : 'Alexis' ,\n",
        "'Mccartney' : 'Gina' ,\n",
        "'Fisher' : 'Jillian' ,\n",
        "'Saburo' : 'Pamela' ,\n",
        "'Maischberger' : 'Mitchell' ,\n",
        "'Sharpton' : 'Hannah' ,\n",
        "'Koko' : 'Renee' ,\n",
        "'Gates' : 'Denise' ,\n",
        "'Simon' : 'Molly' ,\n",
        "'Schneider' : 'Jerry' ,\n",
        "'Peron' : 'Misty' ,\n",
        "'Ellen' : 'Mario' ,\n",
        "'Alfredo' : 'Johnathan' ,\n",
        "'Einstein' : 'Jaclyn' ,\n",
        "'Mika' : 'Brenda' ,\n",
        "'Hours' : 'Terry' ,\n",
        "'Yasser' : 'Lacey' ,\n",
        "'Washington' : 'Shaun' ,\n",
        "'Hayes' : 'Devin' ,\n",
        "'James' : 'Heidi' ,\n",
        "'Abraham' : 'Troy' ,\n",
        "'Oakley' : 'Lucas' ,\n",
        "'Chapman' : 'Desiree' ,\n",
        "'George' : 'Jorge' ,\n",
        "'Luna' : 'Andre' ,\n",
        "'Piet' : 'Morgan' ,\n",
        "'Simone' : 'Drew' ,\n",
        "'Rembrandt' : 'Sabrina' ,\n",
        "'Gore' : 'Miranda' ,\n",
        "'Mohamed' : 'Alyssa' ,\n",
        "'Jean' : 'Alisha' ,\n",
        "'Paolo' : 'Teresa' ,\n",
        "'Bob' : 'Johnny' ,\n",
        "'Fukuzawa' : 'Meagan' ,\n",
        "'Pearl' : 'Allen' ,\n",
        "'Bower' : 'Krista' ,\n",
        "'Miller' : 'Marc' ,\n",
        "'André' : 'Tabitha' ,\n",
        "'Louis' : 'Lance' ,\n",
        "'Anwar' : 'Ricardo' ,\n",
        "'Obama' : 'Martin' ,\n",
        "'Susan' : 'Chase' ,\n",
        "'Samuel' : 'Theresa' ,\n",
        "'Liisa' : 'Melinda' ,\n",
        "'Pettibon' : 'Monique' ,\n",
        "'Natasha' : 'Tanya' ,\n",
        "'Hussein' : 'Linda' ,\n",
        "'Milosevic' : 'Kristopher' ,\n",
        "'Snow' : 'Bobby' ,\n",
        "'Anthony' : 'Caleb' ,\n",
        "'Koko' : 'Ashlee' ,\n",
        "'Hart' : 'Kelli' ,\n",
        "'Roosevelt' : 'Henry' ,\n",
        "'Noriega' : 'Garrett' ,\n",
        "'Arafat' : 'Mallory' ,\n",
        "'Frederick' : 'Jill' ,\n",
        "'Madonna' : 'Jonathon' ,\n",
        "'Sappho' : 'Kristy' ,\n",
        "'Monroe' : 'Anne' ,\n",
        "'Oscar' : 'Francisco' ,\n",
        "'Hug' : 'Danny' ,\n",
        "'Sofu' : 'Robin' ,\n",
        "'Jorge' : 'Lee' ,\n",
        "'Babbage' : 'Tamara' ,\n",
        "'Pablo' : 'Manuel' ,\n",
        "'Micky' : 'Meredith' ,\n",
        "'Hale' : 'Colleen' ,\n",
        "'Nelson' : 'Lawrence' ,\n",
        "'Abbas' : 'Christy' ,\n",
        "'Edwin' : 'Ricky' ,\n",
        "'Rawlings' : 'Randall' ,\n",
        "'Rachel' : 'Marissa' ,\n",
        "'Noguchi' : 'Ross' ,\n",
        "'Steffi' : 'Mathew' ,\n",
        "'Lech' : 'Jimmy' ,\n",
        "'Betty' : 'Abigail' ,\n",
        "'Luther' : 'Kendra' ,\n",
        "'Costas' : 'Carolyn' ,\n",
        "'Mishima' : 'Billy' ,\n",
        "'Harper' : 'Deanna' ,\n",
        "'Himekusa' : 'Jenny' ,\n",
        "'Mary' : 'Jon' ,\n",
        "'Ford' : 'Albert' ,\n",
        "'Bob' : 'Taylor' ,\n",
        "'Kinnan' : 'Lori' ,\n",
        "'Bach' : 'Rebekah' ,\n",
        "'Hashimoto' : 'Cameron' ,\n",
        "'Edberg' : 'Ebony' ,\n",
        "'Chopin' : 'Wendy' ,\n",
        "'Metin' : 'Angel' ,\n",
        "'Joseph' : 'Micheal' ,\n",
        "'Becker' : 'Kristi' ,\n",
        "'Scrooge' : 'Caroline' ,\n",
        "'Dalton' : 'Colin' ,\n",
        "'Saad' : 'Dawn' ,\n",
        "'Aurore' : 'Kari' ,\n",
        "'Julie' : 'Clayton' ,\n",
        "'Alberto' : 'Arthur' ,\n",
        "'Sadat' : 'Roger' ,\n",
        "'Patterson' : 'Roberto' ,\n",
        "'Nikos' : 'Priscilla' ,\n",
        "'Ken' : 'Darren' ,\n",
        "'Tanaka' : 'Kelsey' ,\n",
        "'Robert' : 'Clinton' ,\n",
        "'Hunter' : 'Walter' ,\n",
        "'Brad' : 'Louis' ,\n",
        "'Punched' : 'Barbara' ,\n",
        "'Marty' : 'Isaac' ,\n",
        "'Bonaparte' : 'Cassie' ,\n",
        "'Tamaro' : 'Grant' ,\n",
        "'Kaplan' : 'Cristina' ,\n",
        "'Charlemagne' : 'Tonya' ,\n",
        "'Rex' : 'Rodney' ,\n",
        "'Kaurismäki' : 'Bridget' ,\n",
        "'Annan' : 'Joe' ,\n",
        "'Muhammad' : 'Cindy' ,\n",
        "'Riel' : 'Oscar' ,\n",
        "'Antoinette' : 'Willie' ,\n",
        "'Tiên' : 'Maurice' ,\n",
        "'Jackie' : 'Jaime' ,\n",
        "'Mike' : 'Angelica' ,\n",
        "'Weinberg' : 'Sharon' ,\n",
        "'Goudie' : 'Julian' ,\n",
        "'Pacino' : 'Jack' ,\n",
        "'Matthaeus' : 'Jay' ,\n",
        "'Meyer' : 'Calvin' ,\n",
        "'Heather' : 'Marie' ,\n",
        "'Lisa' : 'Hector' ,\n",
        "'Reinhardt' : 'Kate' ,\n",
        "'Anne' : 'Adrienne' ,\n",
        "'Dixon' : 'Tasha' ,\n",
        "'Rudolf' : 'Michele' ,\n",
        "'Klaus' : 'Ana' ,\n",
        "'Patsy' : 'Stefanie' ,\n",
        "'Bauer' : 'Cara' ,\n",
        "'Evans' : 'Alejandro' ,\n",
        "'Kourkoulos' : 'Ruben' ,\n",
        "'Burt' : 'Gerald' ,\n",
        "'Nobel' : 'Audrey' ,\n",
        "'Dalí' : 'Kristine' ,\n",
        "'Scott' : 'Ann' ,\n",
        "'Caesar' : 'Shana' ,\n",
        "'Marjorie' : 'Javier' ,\n",
        "'Hawk' : 'Katelyn' ,\n",
        "'Leonardo' : 'Brianna' ,\n",
        "'Andres' : 'Bruce' ,\n",
        "'Aldrin' : 'Deborah' ,\n",
        "'Maggie' : 'Claudia' ,\n",
        "'Luke' : 'Carla' ,\n",
        "'Cameron' : 'Wayne' ,\n",
        "'Carson' : 'Roy' ,\n",
        "'Nicholson' : 'Virginia' ,\n",
        "'Adams' : 'Haley' ,\n",
        "'Mel' : 'Brendan' ,\n",
        "'Max' : 'Janelle' ,\n",
        "'Spike' : 'Jacquelyn' ,\n",
        "'Brandon' : 'Beth' ,\n",
        "'Ogawa' : 'Edwin' ,\n",
        "'Raman' : 'Dylan' ,\n",
        "'Jerry' : 'Dominic' ,\n",
        "'Chizhov' : 'Latasha' ,\n",
        "'Emi' : 'Darrell' ,\n",
        "'Walt' : 'Geoffrey' ,\n",
        "'Dazai' : 'Savannah' ,\n",
        "'Ayrton' : 'Reginald' ,\n",
        "'Akira' : 'Carly' ,\n",
        "'Quincy' : 'Fernando' ,\n",
        "'Band' : 'Ashleigh' ,\n",
        "'Antonioni' : 'Aimee' ,\n",
        "'Laden' : 'Regina' ,\n",
        "'Lennon' : 'Mandy' ,\n",
        "'Tom' : 'Sergio' ,\n",
        "'Huber' : 'Rafael' ,\n",
        "'Laura' : 'Pedro' ,\n",
        "'Lancaster' : 'Janet' ,\n",
        "'Markku' : 'Kaitlin' ,\n",
        "'Lopez' : 'Frederick' ,\n",
        "'Lionel' : 'Cheryl' ,\n",
        "'Crichton' : 'Autumn' ,\n",
        "'Meir' : 'Tyrone' ,\n",
        "'Williams' : 'Martha' ,\n",
        "'Blackhawks' : 'Omar' ,\n",
        "'Shi' : 'Lydia' ,\n",
        "'Abrams' : 'Jerome' ,\n",
        "'Gianni' : 'Theodore' ,\n",
        "'Barack' : 'Abby' ,\n",
        "'Michael' : 'Neil' ,\n",
        "'Golda' : 'Shawna' ,\n",
        "'Akagawa' : 'Sierra' ,\n",
        "'Beethoven' : 'Nina' ,\n",
        "'Sipowicz' : 'Tammy' ,\n",
        "'Donald' : 'Nikki' ,\n",
        "'Peter' : 'Terrance' ,\n",
        "'Camdessus' : 'Claire' ,\n",
        "'Chomsky' : 'Cole' ,\n",
        "'Sheldon' : 'Trisha' ,\n",
        "'Roy' : 'Bonnie' ,\n",
        "'Ghiorso' : 'Diane' ,\n",
        "'Burped' : 'Summer' ,\n",
        "'Sara' : 'Carmen' ,\n",
        "'Twenty' : 'Mayra' ,\n",
        "'Gospel' : 'Jermaine' ,\n",
        "'Coello' : 'Eddie' ,\n",
        "'Vincent' : 'Micah' ,\n",
        "'Constant' : 'Marvin' ,\n",
        "'Spears' : 'Levi' ,\n",
        "'Yoko' : 'Emmanuel' ,\n",
        "'Paquiss' : 'Brad' ,\n",
        "'Nana' : 'Taryn' ,\n",
        "'Ted' : 'Toni' ,\n",
        "'Finkelstein' : 'Jessie' ,\n",
        "'Jessie' : 'Evelyn' ,\n",
        "'Moncalvo' : 'Darryl' ,\n",
        "'Mohn' : 'Ronnie' ,\n",
        "'Zappa' : 'Joy' ,\n",
        "'Mambro' : 'Adriana' ,\n",
        "'Austen' : 'Ruth' ,\n",
        "'Schubert' : 'Mindy' ,\n",
        "'Barbie' : 'Spencer' ,\n",
        "'Cruise' : 'Noah' ,\n",
        "'Gertrude' : 'Raul' ,\n",
        "'Leeson' : 'Suzanne' ,\n",
        "'Pedro' : 'Sophia' ,\n",
        "'Sid' : 'Dale' ,\n",
        "'Mari' : 'Jodi' ,\n",
        "'Nyong' : 'Christie' ,\n",
        "'Michel' : 'Raquel' ,\n",
        "'Trump' : 'Naomi' ,\n",
        "'Mondrian' : 'Kellie' ,\n",
        "'Liz' : 'Ernest' ,\n",
        "'Edison' : 'Jake' ,\n",
        "'Hanako' : 'Grace' ,\n",
        "'Osama' : 'Tristan' ,\n",
        "'Ibarra' : 'Shanna' ,\n",
        "'Henri' : 'Hilary' ,\n",
        "'Stich' : 'Eduardo' ,\n",
        "'Cathy' : 'Ivan' ,\n",
        "'Daping' : 'Hillary' ,\n",
        "'Hans' : 'Yolanda' ,\n",
        "'Akiko' : 'Alberto' ,\n",
        "'Martin' : 'Andres' ,\n",
        "'Pitt' : 'Olivia' ,\n",
        "'Patricia' : 'Armando' ,\n",
        "'Seuss' : 'Paula' ,\n",
        "'Antonia' : 'Amelia' ,\n",
        "'Squirrel' : 'Sheila' ,\n",
        "'Thomas' : 'Rosa' ,\n",
        "'Cleopatra' : 'Robyn' ,\n",
        "'Andre' : 'Kurt' ,\n",
        "'Signoret' : 'Dane' ,\n",
        "'Anke' : 'Glenn' ,\n",
        "'Erkin' : 'Nicolas' ,\n",
        "'Karmazin' : 'Gloria' ,\n",
        "'Ball' : 'Eugene' ,\n",
        "'Lie' : 'Logan' ,\n",
        "'Colbeck' : 'Steve' ,\n",
        "'Mantle' : 'Ramon' ,\n",
        "'Warren' : 'Bryce' ,\n",
        "'Molly' : 'Tommy' ,\n",
        "'Ingalls' : 'Preston' ,\n",
        "'Rutherford' : 'Keri' ,\n",
        "'Lincoln' : 'Devon' ,\n",
        "'Tomlinson' : 'Alana' ,\n",
        "'Antonio' : 'Marisa' ,\n",
        "'Noriko' : 'Melody' ,\n",
        "'Johann' : 'Rose' ,\n",
        "'Lenz' : 'Barry' ,\n",
        "'Dale' : 'Marco' ,\n",
        "'Geiger' : 'Karl' ,\n",
        "'Barbara' : 'Daisy' ,\n",
        "'Swift' : 'Leonard' ,\n",
        "'Tony' : 'Randi' ,\n",
        "'Elaine' : 'Maggie' ,\n",
        "'Doggy' : 'Charlotte' ,\n",
        "'Eva' : 'Emma' ,\n",
        "'Allan' : 'Terrence' ,\n",
        "'Vladimir' : 'Justine' ,\n",
        "'Lillien' : 'Britney' ,\n",
        "'Shannon' : 'Lacy' ,\n",
        "'Hideyo' : 'Jeanette' ,\n",
        "'Samir' : 'Francis' ,\n",
        "'Ruth' : 'Tyson' ,\n",
        "'Sakura' : 'Elise' ,\n",
        "'West' : 'Sylvia' ,\n",
        "'Agnès' : 'Rachelle' ,\n",
        "'Tyson' : 'Stanley' ,\n",
        "'Justin' : 'Debra' ,\n",
        "'Andrew' : 'Brady' ,\n",
        "'Quinn' : 'Charity' ,\n",
        "'Carl' : 'Hope' ,\n",
        "'Clinton' : 'Melvin' ,\n",
        "'Buzz' : 'Johanna' ,\n",
        "'Zhou' : 'Karla' ,\n",
        "'Marian' : 'Jarrod' ,\n",
        "'Jill' : 'Charlene' ,\n",
        "'Purnell' : 'Gabrielle' ,\n",
        "'Jan' : 'Cesar' ,\n",
        "'Emily' : 'Clifford' ,\n",
        "'Whitfield' : 'Byron' ,\n",
        "'Novello' : 'Terrell' ,\n",
        "'Nirvana' : 'Sonia' ,\n",
        "'Lynn' : 'Julio' ,\n",
        "'Carrie' : 'Stacie' ,\n",
        "'Kumi' : 'Shelby' ,\n",
        "'Wolfgang' : 'Shelly' ,\n",
        "'Harding' : 'Edgar' ,\n",
        "'Virginia' : 'Roxanne' ,\n",
        "'Irving' : 'Dwayne' ,\n",
        "'Rosa' : 'Kaitlyn' ,\n",
        "'Lin' : 'Kasey' ,\n",
        "'Mahatma' : 'Jocelyn' ,\n",
        "'Smith' : 'Alexandria' ,\n",
        "'Glashow' : 'Harold' ,\n",
        "'Odette' : 'Esther' ,\n",
        "'Dickens' : 'Kerri' ,\n",
        "'Mark' : 'Ellen' ,\n",
        "'Brown' : 'Abraham' ,\n",
        "'Leo' : 'Cedric' ,\n",
        "'Iva' : 'Carol' ,\n",
        "'Lida' : 'Katharine' ,\n",
        "'Alfred' : 'Shauna' ,\n",
        "'Bukowski' : 'Frances' ,\n",
        "'Brontë' : 'Antoine' ,\n",
        "'Tarantino' : 'Tabatha' ,\n",
        "'Lidya' : 'Annie' ,\n",
        "'Saddam' : 'Erick' ,\n",
        "'Goodell' : 'Alissa' ,\n",
        "'Charlotte' : 'Sherry' ,\n",
        "'Romney' : 'Chelsey' ,\n",
        "'Garfunkel' : 'Franklin' ,\n",
        "'Atahualpa' : 'Branden' ,\n",
        "'Gottfried' : 'Helen' ,\n",
        "'Karim' : 'Traci' ,\n",
        "'Marley' : 'Lorenzo' ,\n",
        "'Christian' : 'Dean' ,\n",
        "'Piao' : 'Sonya' ,\n",
        "'Primus' : 'Briana' ,\n",
        "'Armstrong' : 'Angelina' ,\n",
        "'Mozart' : 'Trista' ,\n",
        "'Yamauchi' : 'Bianca' ,\n",
        "'Hillary' : 'Leticia' ,\n",
        "'Mona' : 'Tia' ,\n",
        "'Roger' : 'Kristie' ,\n",
        "'Vanessa' : 'Stuart' ,\n",
        "'Aaron' : 'Laurie' ,\n",
        "'Pierrot' : 'Harry' ,\n",
        "'Huang' : 'Leigh' ,\n",
        "'Hooper' : 'Elisabeth' ,\n",
        "'Pikes' : 'Alfredo' ,\n",
        "'Agassi' : 'Aubrey' ,\n",
        "'Pierre' : 'Ray' ,\n",
        "'Seles' : 'Arturo' ,\n",
        "'Croatian' : 'Joey' ,\n",
        "'Beavers' : 'Kelley' ,\n",
        "'Diana' : 'Max' ,\n",
        "'Claxton' : 'Andy' ,\n",
        "'Escobar' : 'Latisha' ,\n",
        "'Graf' : 'Johnathon' ,\n",
        "'Cristiani' : 'India' ,\n",
        "'Stefan' : 'Eva' ,\n",
        "'Dogg' : 'Ralph' ,\n",
        "'Hiddink' : 'Yvonne' ,\n",
        "'Gandhi' : 'Warren' ,\n",
        "'Paul' : 'Kirsten' ,\n",
        "'Sinatra' : 'Miriam' ,\n",
        "'Dickson' : 'Kelvin' ,\n",
        "'Ania' : 'Lorena' ,\n",
        "'Eileen' : 'Staci' ,\n",
        "'White' : 'Anita' ,\n",
        "'Wang' : 'Rene' ,\n",
        "'Dinosaurs' : 'Cortney' ,\n",
        "'Bērziņš' : 'Orlando' ,\n",
        "'Sung' : 'Carissa' ,\n",
        "'Napoleon' : 'Jade' ,\n",
        "'Lee' : 'Camille' ,\n",
        "'Allen' : 'Leon' ,\n",
        "'Darwin' : 'Paige' ,\n",
        "'Brutus' : 'Marcos' ,\n",
        "'Bartow' : 'Elena' ,\n",
        "'Chapin' : 'Brianne' ,\n",
        "'Jeff' : 'Dorothy' ,\n",
        "'Speedy' : 'Marshall' ,\n",
        "'Albert' : 'Daryl' ,\n",
        "'Houdini' : 'Colby' ,\n",
        "'Susanna' : 'Terri' ,\n",
        "'Scharping' : 'Gabriela' ,\n",
        "'Dracula' : 'Brock' ,\n",
        "'Karen' : 'Gerardo' ,\n",
        "'Tomoyuki' : 'Jane' ,\n",
        "'Minton' : 'Nelson' ,\n",
        "'Jackson' : 'Tamika' ,\n",
        "'Chuck' : 'Alvin' ,\n",
        "'Emil' : 'Chasity' ,\n",
        "'Charlie' : 'Trent' ,\n",
        "'Margaret' : 'Jana' ,\n",
        "'Scorsese' : 'Enrique' ,\n",
        "'Shostakovich' : 'Tracey' ,\n",
        "'Bakula' : 'Antoinette' ,\n",
        "'Schaller' : 'Jami' ,\n",
        "'Simpson' : 'Earl' ,\n",
        "'Pizarro' : 'Gilbert' ,\n",
        "'Hendrix' : 'Damien' ,\n",
        "'Taro' : 'Janice' ,\n",
        "'Marzipan' : 'Christa' ,\n",
        "'Adolf' : 'Tessa' ,\n",
        "'Elba' : 'Kirk' ,\n",
        "'Teresa' : 'Yvette' ,\n",
        "'Marc' : 'Elijah' ,\n",
        "'Will' : 'Howard' ,\n",
        "'Tolstoy' : 'Elisa' ,\n",
        "'Brian' : 'Desmond' ,\n",
        "'Gabi' : 'Clarence' ,\n",
        "'Nicholas' : 'Alfred' ,\n",
        "'Milkman' : 'Darnell' ,\n",
        "'Nancy' : 'Breanna' ,\n",
        "'Dennis' : 'Kerry' ,\n",
        "'Helen' : 'Nickolas' ,\n",
        "'Manson' : 'Maureen' ,\n",
        "'Redgrave' : 'Karina' ,\n",
        "'Gogh' : 'Roderick' ,\n",
        "'Wolf' : 'Rochelle' ,\n",
        "'Bont' : 'Rhonda' ,\n",
        "'Collins' : 'Keisha' ,\n",
        "'Mabel' : 'Irene' ,\n",
        "'Montale' : 'Ethan' ,\n",
        "'Tiilikainen' : 'Alice',\n",
        "\n",
        "#countries\n",
        "'Turkey' : 'Afghanistan' ,\n",
        "'Mexico' : 'Albania' ,\n",
        "'Italy' : 'Algeria' ,\n",
        "'Libya' : 'Andorra' ,\n",
        "'Argentina' : 'Angola' ,\n",
        "'Indonesia' : 'Iceland' ,\n",
        "'Japan' : 'India' ,\n",
        "'Somalia' : 'Indonesia' ,\n",
        "'Israel' : 'Iran' ,\n",
        "'Greece' : 'Iraq' ,\n",
        "'Cambodia' : 'Ireland' ,\n",
        "'Morocco' : 'Romania' ,\n",
        "'Malaysia' : 'Russia' ,\n",
        "'Canada' : 'Rwanda' ,\n",
        "'Switzerland' : 'Jamaica' ,\n",
        "'Sweden' : 'Japan' ,\n",
        "'Eritrea' : 'Jordan' ,\n",
        "'India' : 'Kenya' ,\n",
        "'Mauritania' : 'Kiribati' ,\n",
        "'Lebanon' : 'Kosovo' ,\n",
        "'Germany' : 'Kuwait' ,\n",
        "'Greenland' : 'Kyrgyzstan' ,\n",
        "'Jordan' : 'Botswana' ,\n",
        "'Colombia' : 'Brazil' ,\n",
        "'Peru' : 'Brunei' ,\n",
        "'Latvia' : 'Bulgaria' ,\n",
        "'Albania' : 'Chad' ,\n",
        "'Austria' : 'Chile' ,\n",
        "'Kazakhstan' : 'China' ,\n",
        "'Lithuania' : 'Colombia' ,\n",
        "'Brazil' : 'Comoros' ,\n",
        "'Zambia' : 'Mauritius' ,\n",
        "'Netherlands' : 'Mexico' ,\n",
        "'Ukraine' : 'Micronesia' ,\n",
        "'Iceland' : 'Moldova' ,\n",
        "'canada' : 'Monaco' ,\n",
        "'Poland' : 'Mongolia' ,\n",
        "'Cuba' : 'Montenegro' ,\n",
        "'Norway' : 'Morocco' ,\n",
        "'Iraq' : 'Mozambique' ,\n",
        "'Romania' : 'Myanmar' ,\n",
        "'China' : 'Fiji' ,\n",
        "'Thailand' : 'Finland' ,\n",
        "'Ethiopia' : 'France' ,\n",
        "'Georgia' : 'Paraguay' ,\n",
        "'Algeria' : 'Peru' ,\n",
        "'Singapore' : 'Philippines' ,\n",
        "'Finland' : 'Poland' ,\n",
        "'Egypt' : 'Portugal' ,\n",
        "'Australia' : 'Vanuatu' ,\n",
        "'France' : 'Venezuela' ,\n",
        "'Spain' : 'Vietnam' ,\n",
        "'Ireland' : 'Pakistan' ,\n",
        "\n",
        "#states\n",
        "'Seoul' : 'Alaska' ,\n",
        "'Taiwan' : 'Alabama' ,\n",
        "'Nara' : 'Arkansas' ,\n",
        "'North' : 'Arizona' ,\n",
        "'England' : 'California' ,\n",
        "'Coventry' : 'Colorado' ,\n",
        "'Rome' : 'Connecticut' ,\n",
        "'Pisa' : 'Delaware' ,\n",
        "'Lisbon' : 'Florida' ,\n",
        "'Moscow' : 'Georgia' ,\n",
        "'Barcelona' : 'Guam' ,\n",
        "'Hamburg' : 'Hawaii' ,\n",
        "'Massachusetts' : 'Iowa' ,\n",
        "'Illinois' : 'Idaho' ,\n",
        "'California' : 'Illinois' ,\n",
        "'Ohio' : 'Indiana' ,\n",
        "'Texas' : 'Kansas' ,\n",
        "'Florida' : 'Kentucky' ,\n",
        "'Washington' : 'Louisiana' ,\n",
        "'Mississippi' : 'Massachusetts' ,\n",
        "'Georgia' : 'Maryland' ,\n",
        "'Missouri' : 'Maine' ,\n",
        "'Louisiana' : 'Michigan' ,\n",
        "'Indiana' : 'Minnesota' ,\n",
        "'Michigan' : 'Missouri' ,\n",
        "'South' : 'Mississippi' ,\n",
        "'Istanbul' : 'Montana' ,\n",
        "'Paris' : 'Nebraska' ,\n",
        "'Hawaii' : 'Nevada' ,\n",
        "'Alaska' : 'Ohio' ,\n",
        "'Auckland' : 'Oklahoma' ,\n",
        "'Saskatchewan' : 'Oregon' ,\n",
        "'Okinawa' : 'Pennsylvania' ,\n",
        "'Hiroshima' : 'Tennessee' ,\n",
        "'Salzburg' : 'Texas' ,\n",
        "'Alexandria' : 'Utah' ,\n",
        "'Edo' : 'Virginia' ,\n",
        "'Adamawa' : 'Vermont' ,\n",
        "'Western' : 'Washington' ,\n",
        "'Northwest' : 'Wisconsin' ,\n",
        "'Fukui' : 'Wyoming' ,\n",
        "'Nagasaki' : 'Alberta' ,\n",
        "'Chiapas' : 'Manitoba' ,\n",
        "'Chechnya' : 'Nunavut' ,\n",
        "'Portland' : 'Ontario' ,\n",
        "'Hanover' : 'Quebec' ,\n",
        "\n",
        "#cities\n",
        "'Tokyo' : 'Aberdeen' ,\n",
        "'Beijing' : 'Abilene' ,\n",
        "'Seoul' : 'Akron' ,\n",
        "'Kawasaki' : 'Albany' ,\n",
        "'Yokohama' : 'Albuquerque' ,\n",
        "'Nagoya' : 'Alexandria' ,\n",
        "'Kyoto' : 'Allentown' ,\n",
        "'Nara' : 'Amarillo' ,\n",
        "'Kobe' : 'Anaheim' ,\n",
        "'Darwin' : 'Anchorage' ,\n",
        "'Nantes' : 'Antioch' ,\n",
        "'London' : 'Appleton' ,\n",
        "'Coventry' : 'Arlington' ,\n",
        "'March' : 'Arvada' ,\n",
        "'Lincoln' : 'Asheville' ,\n",
        "'Fulham' : 'Athens' ,\n",
        "'Rome' : 'Atlanta' ,\n",
        "'Pisa' : 'Augusta' ,\n",
        "'Jerusalem' : 'Aurora' ,\n",
        "'Lisbon' : 'Austin' ,\n",
        "'Paul' : 'Bakersfield' ,\n",
        "'Athens' : 'Baltimore' ,\n",
        "'Volgograd' : 'Barnstable' ,\n",
        "'Moscow' : 'Beaumont' ,\n",
        "'Boston' : 'Bellevue' ,\n",
        "'Anna' : 'Berkeley' ,\n",
        "'Washington' : 'Bethlehem' ,\n",
        "'Barcelona' : 'Billings' ,\n",
        "'Berlin' : 'Birmingham' ,\n",
        "'Hamburg' : 'Bloomington' ,\n",
        "'Hanover' : 'Boise' ,\n",
        "'Stuttgart' : 'Boston' ,\n",
        "'Vinci' : 'Boulder' ,\n",
        "'Chicago' : 'Bradenton' ,\n",
        "'Portland' : 'Bremerton' ,\n",
        "'Alexandria' : 'Bridgeport' ,\n",
        "'Buffalo' : 'Brighton' ,\n",
        "'Clinton' : 'Brownsville' ,\n",
        "'Jackson' : 'Bryan' ,\n",
        "'Dallas' : 'Buffalo' ,\n",
        "'Edison' : 'Burbank' ,\n",
        "'Frederick' : 'Burlington' ,\n",
        "'Justin' : 'Cambridge' ,\n",
        "'Dickson' : 'Canton' ,\n",
        "'Spencer' : 'Carrollton' ,\n",
        "'Istanbul' : 'Cary' ,\n",
        "'Paris' : 'Champaign' ,\n",
        "'Nancy' : 'Chandler' ,\n",
        "'Vladivostok' : 'Charleston' ,\n",
        "'Dublin' : 'Charlotte' ,\n",
        "'Tbilisi' : 'Chattanooga' ,\n",
        "'Pskov' : 'Chesapeake' ,\n",
        "'Columbia' : 'Chicago' ,\n",
        "'Canadian' : 'Cincinnati' ,\n",
        "'California' : 'Clarksville' ,\n",
        "'Egypt' : 'Clearwater' ,\n",
        "'Pacific' : 'Cleveland' ,\n",
        "'Lebanon' : 'Columbia' ,\n",
        "'Vance' : 'Columbus' ,\n",
        "'Mexico' : 'Concord' ,\n",
        "'Holland' : 'Corona' ,\n",
        "'Cameron' : 'Dallas' ,\n",
        "'Hebron' : 'Danbury' ,\n",
        "'Tracy' : 'Davenport' ,\n",
        "'Liberty' : 'Dayton' ,\n",
        "'Patterson' : 'Deltona' ,\n",
        "'Hope' : 'Denton' ,\n",
        "'Beverly' : 'Denver' ,\n",
        "'Truckee' : 'Detroit' ,\n",
        "'Alice' : 'Downey' ,\n",
        "'Harvard' : 'Duluth' ,\n",
        "'Thomas' : 'Durham' ,\n",
        "'Scott' : 'Elizabeth' ,\n",
        "'Yale' : 'Elkhart' ,\n",
        "'Everest' : 'Erie' ,\n",
        "'Cuba' : 'Escondido' ,\n",
        "'Auckland' : 'Eugene' ,\n",
        "'Singapore' : 'Evansville' ,\n",
        "'Bali' : 'Fairfield' ,\n",
        "'Marian' : 'Fargo' ,\n",
        "'Kunming' : 'Fayetteville' ,\n",
        "'Calgary' : 'Fitchburg' ,\n",
        "'Scotland' : 'Flint' ,\n",
        "'Peru' : 'Fontana' ,\n",
        "'McDonald' : 'Frederick' ,\n",
        "'Indiana' : 'Fremont' ,\n",
        "'Apollo' : 'Fresno' ,\n",
        "'Hooper' : 'Fullerton' ,\n",
        "'Roy' : 'Gainesville' ,\n",
        "'Napoleon' : 'Garland' ,\n",
        "'Jack' : 'Gastonia' ,\n",
        "'Jordan' : 'Gilbert' ,\n",
        "'Charlemagne' : 'Glendale' ,\n",
        "'Johnson' : 'Grayslake' ,\n",
        "'Greenland' : 'GreenBay' ,\n",
        "'Rex' : 'Greensboro' ,\n",
        "'Brazil' : 'Greenville' ,\n",
        "'Mars' : 'Hagerstown' ,\n",
        "'Cairo' : 'Hampton' ,\n",
        "'Achille' : 'Harlingen' ,\n",
        "'Laura' : 'Harrisburg' ,\n",
        "'Spanish' : 'Hartford' ,\n",
        "'Florida' : 'Hayward' ,\n",
        "'White' : 'Hemet' ,\n",
        "'Roosevelt' : 'Henderson' ,\n",
        "'Osaka' : 'Hesperia' ,\n",
        "'Sapporo' : 'Hialeah' ,\n",
        "'Fuji' : 'Hickory' ,\n",
        "'Kanazawa' : 'Hollywood' ,\n",
        "'Shinjuku' : 'Honolulu' ,\n",
        "'God' : 'Houma' ,\n",
        "'Ford' : 'Houston' ,\n",
        "'Salzburg' : 'Howell' ,\n",
        "'Hangzhou' : 'Huntington' ,\n",
        "'Maastricht' : 'Huntington Beach' ,\n",
        "'Madonna' : 'Huntsville' ,\n",
        "'Jones' : 'Independence' ,\n",
        "'Pretoria' : 'Indianapolis' ,\n",
        "'Kinshasa' : 'Inglewood' ,\n",
        "'George' : 'Irvine' ,\n",
        "'Tama' : 'Irving' ,\n",
        "'America' : 'Jackson' ,\n",
        "'Hiroshima' : 'Jacksonville' ,\n",
        "'Bach' : 'Jefferson' ,\n",
        "'Cisco' : 'Joliet' ,\n",
        "'Okinawa' : 'Kailua' ,\n",
        "'Usa' : 'Kalamazoo' ,\n",
        "'Joseph' : 'Kaneohe' ,\n",
        "'Simpson' : 'Kennewick' ,\n",
        "'Ohio' : 'Kenosha' ,\n",
        "'Helen' : 'Killeen' ,\n",
        "'Lewis' : 'Kissimmee' ,\n",
        "'Poland' : 'Knoxville' ,\n",
        "'War' : 'Lacey' ,\n",
        "'Ikeda' : 'Lafayette' ,\n",
        "'Sakura' : 'Lakeland' ,\n",
        "'Hashimoto' : 'Lakewood' ,\n",
        "'Narita' : 'Lancaster' ,\n",
        "'Takeo' : 'Lansing' ,\n",
        "'Nagasaki' : 'Laredo' ,\n",
        "'Marie' : 'Layton' ,\n",
        "'Maria' : 'Leominster' ,\n",
        "'Mary' : 'Lewisville' ,\n",
        "'Lech' : 'Lexington' ,\n",
        "'Kelly' : 'Lincoln' ,\n",
        "'Ireland' : 'Lorain' ,\n",
        "'Hasselt' : 'Louisville' ,\n",
        "'Venus' : 'Lowell' ,\n",
        "'Ruth' : 'Lubbock' ,\n",
        "'Magdalena' : 'Macon' ,\n",
        "'Wagner' : 'Madison' ,\n",
        "'Van Horn' : 'Manchester' ,\n",
        "'Merlin' : 'Marina' ,\n",
        "'Elba' : 'Marysville' ,\n",
        "'Bush' : 'McAllen' ,\n",
        "'Smith' : 'McHenry' ,\n",
        "'Atlantic' : 'Medford' ,\n",
        "'Christmas' : 'Melbourne' ,\n",
        "'Elaine' : 'Memphis' ,\n",
        "'Grace' : 'Merced' ,\n",
        "'Norway' : 'Mesa' ,\n",
        "'Becker' : 'Mesquite' ,\n",
        "'Margaret' : 'Miami' ,\n",
        "'Lake' : 'Milwaukee' ,\n",
        "'Louisiana' : 'Minneapolis' ,\n",
        "'Kennedy' : 'Miramar' ,\n",
        "'Leonardo' : 'Mobile' ,\n",
        "'Tony' : 'Modesto' ,\n",
        "'Lopez' : 'Monroe' ,\n",
        "'Turkey' : 'Monterey' ,\n",
        "'Corsica' : 'Montgomery' ,\n",
        "'North' : 'Murfreesboro' ,\n",
        "'China' : 'Murrieta' ,\n",
        "'Italy' : 'Muskegon' ,\n",
        "'Bolivia' : 'Naperville' ,\n",
        "'Coleridge' : 'Naples' ,\n",
        "'Abrams' : 'Nashua' ,\n",
        "'Russia' : 'Nashville' ,\n",
        "'England' : 'Newark' ,\n",
        "'Palm' : 'Newburgh' ,\n",
        "'May' : 'Norfolk' ,\n",
        "'Emily' : 'Normal' ,\n",
        "'Swiss' : 'Norman' ,\n",
        "'Falkland' : 'Norwalk' ,\n",
        "'Shiro' : 'Norwich' ,\n",
        "'Damon' : 'Oakland' ,\n",
        "'Us' : 'Ocala' ,\n",
        "'Moncalvo' : 'Oceanside' ,\n",
        "'Requena' : 'Odessa' ,\n",
        "'Jesus' : 'Ogden' ,\n",
        "'Four' : 'Olathe' ,\n",
        "'Abuja' : 'Olympia' ,\n",
        "'Square' : 'Omaha' ,\n",
        "'Park' : 'Ontario' ,\n",
        "'Castro' : 'Orange' ,\n",
        "'Spain' : 'Orem' ,\n",
        "'Pedro' : 'Orlando' ,\n",
        "'Spock' : 'Oxnard' ,\n",
        "'Rosa' : 'Palmdale' ,\n",
        "'Wang' : 'Pasadena' ,\n",
        "'Charles' : 'Paterson' ,\n",
        "'Kuzey' : 'Pensacola' ,\n",
        "'Pizarro' : 'Peoria' ,\n",
        "'Jeff' : 'Philadelphia' ,\n",
        "'Trang' : 'Phoenix' ,\n",
        "'University' : 'Pittsburgh' ,\n",
        "'Tanaka' : 'Plano' ,\n",
        "'Krypton' : 'Pomona' ,\n",
        "'Schneider' : 'Portland' ,\n",
        "'Mark' : 'Portsmouth' ,\n",
        "'Tower' : 'Poughkeepsie' ,\n",
        "'Bill' : 'Providence' ,\n",
        "'Fatima' : 'Provo' ,\n",
        "'German' : 'Pueblo' ,\n",
        "'Lenz' : 'Racine' ,\n",
        "'Chiapas' : 'Raleigh' ,\n",
        "'Obama' : 'Reading' ,\n",
        "'Fukui' : 'Redding' ,\n",
        "'Nine' : 'Reno' ,\n",
        "'Mari' : 'Richland' ,\n",
        "'Gamble' : 'Richmond' ,\n",
        "'Kraft' : 'Riverside' ,\n",
        "'Speed' : 'Roanoke' ,\n",
        "'Aso' : 'Rochester' ,\n",
        "'Green' : 'Rockford' ,\n",
        "'Midnight' : 'Roseville' ,\n",
        "'Normandy' : 'Sacramento' ,\n",
        "'Colombia' : 'Saginaw' ,\n",
        "'Argentina' : 'Salem' ,\n",
        "'English' : 'Salinas' ,\n",
        "'Canada' : 'Sarasota' ,\n",
        "'Marks' : 'Savannah' ,\n",
        "'Pope' : 'Scottsdale' ,\n",
        "'Syria' : 'Scranton' ,\n",
        "'Morocco' : 'Seaside' ,\n",
        "'Brutus' : 'Seattle' ,\n",
        "'Finland' : 'Sebastian' ,\n",
        "'Michigan' : 'Shreveport' ,\n",
        "'Strawberry' : 'Spartanburg' ,\n",
        "'Luna' : 'Spokane' ,\n",
        "'Daniel' : 'Springdale' ,\n",
        "'Canoe' : 'Springfield' ,\n",
        "'Hood' : 'Stamford' ,\n",
        "'Patricia' : 'Stockton'\n",
        "              }\n",
        "with open('train.txt.raw') as main, open('name-changed.txt.raw', 'w') as done:\n",
        "     text = main.read()\n",
        "     done.write(re.sub(r'\\b\\w+\\b', lambda x: word_list.get(x.group(), x.group()), text))"
      ],
      "metadata": {
        "id": "_BnnZvTrsI9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Till now, names are changed in train.txt.raw file. Now we want to change names in DRS as well. In DRS, there are two types of names.**\n",
        "1. Inside DRS\n",
        "2. outside DRS as label to the DRS.\n",
        "**we have to consider both name conventions. And also have to focus on using exactly the same file that is used in above name-change approach.**"
      ],
      "metadata": {
        "id": "cyXY_1BGJBis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will take above used files and convert them into lower-case and also check # of lines and order of names."
      ],
      "metadata": {
        "id": "GwoODm3MLd3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=cap-case-single_names.txt.raw of=lower-case-single_names.txt.raw conv=lcase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FubzWnFWL9NF",
        "outputId": "e3a5855d-1964-49e5-fc45-193dc517166d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8+1 records in\n",
            "8+1 records out\n",
            "4496 bytes (4.5 kB, 4.4 KiB) copied, 0.000373977 s, 12.0 MB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=cap-case-replace_names.txt.raw of=lower-case-replace_names.txt.raw conv=lcase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQWqX1R5NKZ-",
        "outputId": "fe13feba-2993-445f-eeae-145de4e24652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8+1 records in\n",
            "8+1 records out\n",
            "4513 bytes (4.5 kB, 4.4 KiB) copied, 0.000264535 s, 17.1 MB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=/content/names/cap-case-unique_names.txt.raw of=/content/names/lower-case-unique_names.txt.raw conv=lcase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhWFGXmKHWAE",
        "outputId": "54ceb1f8-f03e-4c8a-d0d8-6468ab906507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8+1 records in\n",
            "8+1 records out\n",
            "4455 bytes (4.5 kB, 4.4 KiB) copied, 0.000322109 s, 13.8 MB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mXT_TDkL08T",
        "outputId": "847b0626-3773-441c-c0f0-a82accc7df09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names.txt  train.txt.raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dd if=names.txt of=lower-case-names.txt conv=lcase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-omB0LWAVm83",
        "outputId": "fac22051-536f-4c98-f4af-4dbc5d751849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52+1 records in\n",
            "52+1 records out\n",
            "26709 bytes (27 kB, 26 KiB) copied, 0.000344 s, 77.6 MB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-->DRS name-change code is mentioned below.**"
      ],
      "metadata": {
        "id": "93Hs2WW5J15p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i am reading original names of train.txt.raw dataset file.\n",
        "lines_1 = []\n",
        "with open(\"names.txt\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_1.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_2 = []\n",
        "with open(\"cap-case-replace_names.txt\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_2.append(line) #storing everything in memory!\n",
        "\n",
        "lines_3 = []\n",
        "with open(\"lower-case-names.txt\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_3.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "# Here i am reading replaceable names in the dataset.\n",
        "lines_4 = []\n",
        "with open(\"lower-case-replace_names.txt\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip() #or some other preprocessing\n",
        "        lines_4.append(line) #storing everything in memory!\n",
        "\n",
        "\n",
        "for x,y,z,w in zip(lines_1,lines_2,lines_3,lines_4): # <--- Loop through the list to check\n",
        "  print(\"'\"+x+\"'\",\":\",\"'\"+y+\"'\",\",\",\"'\"+z+\"'\",\":\",\"'\"+w+\"'\",\",\")"
      ],
      "metadata": {
        "id": "pJ7PC7lyJwQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the code below, i will copy above generated dictionary into {}. **"
      ],
      "metadata": {
        "id": "8GwyVH9LNyn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "word_list = {'David' : 'Michael' , 'david' : 'michael' ,\n",
        "'Lori' : 'Christopher' , 'lori' : 'christopher' ,\n",
        "'Bradtke' : 'Jessica' , 'bradtke' : 'jessica' ,\n",
        "'Brady' : 'Matthew' , 'brady' : 'matthew' ,\n",
        "'Monica' : 'Ashley' , 'monica' : 'ashley' ,\n",
        "'Keys' : 'Jennifer' , 'keys' : 'jennifer' ,\n",
        "'Koch' : 'Joshua' , 'koch' : 'joshua' ,\n",
        "'Kofi' : 'Amanda' , 'kofi' : 'amanda' ,\n",
        "'Ayako' : 'Daniel' , 'ayako' : 'daniel' ,\n",
        "'Sekkura' : 'David' , 'sekkura' : 'david' ,\n",
        "'Fatima' : 'James' , 'fatima' : 'james' ,\n",
        "'Cabot' : 'Robert' , 'cabot' : 'robert' ,\n",
        "'Damon' : 'John' , 'damon' : 'john' ,\n",
        "'Reno' : 'Joseph' , 'reno' : 'joseph' ,\n",
        "'Castro' : 'Andrew' , 'castro' : 'andrew' ,\n",
        "'Aurelius' : 'Ryan' , 'aurelius' : 'ryan' ,\n",
        "'Khalifa' : 'Brandon' , 'khalifa' : 'brandon' ,\n",
        "'Annie' : 'Jason' , 'annie' : 'jason' ,\n",
        "'Noble' : 'Justin' , 'noble' : 'justin' ,\n",
        "'Testing' : 'Sarah' , 'testing' : 'sarah' ,\n",
        "'Marika' : 'William' , 'marika' : 'william' ,\n",
        "'Warhol' : 'Jonathan' , 'warhol' : 'jonathan' ,\n",
        "'Britney' : 'Stephanie' , 'britney' : 'stephanie' ,\n",
        "'Ronald' : 'Brian' , 'ronald' : 'brian' ,\n",
        "'Ibrahim' : 'Nicole' , 'ibrahim' : 'nicole' ,\n",
        "'Watanabe' : 'Nicholas' , 'watanabe' : 'nicholas' ,\n",
        "'Edith' : 'Anthony' , 'edith' : 'anthony' ,\n",
        "'Clinton' : 'Heather' , 'clinton' : 'heather' ,\n",
        "'Guus' : 'Eric' , 'guus' : 'eric' ,\n",
        "'Hood' : 'Elizabeth' , 'hood' : 'elizabeth' ,\n",
        "'Yumi' : 'Adam' , 'yumi' : 'adam' ,\n",
        "'Stephen' : 'Megan' , 'stephen' : 'megan' ,\n",
        "'Sadako' : 'Melissa' , 'sadako' : 'melissa' ,\n",
        "'Sylvia' : 'Kevin' , 'sylvia' : 'kevin' ,\n",
        "'Berlioz' : 'Steven' , 'berlioz' : 'steven' ,\n",
        "'Pohl' : 'Thomas' , 'pohl' : 'thomas' ,\n",
        "'Sasaki' : 'Timothy' , 'sasaki' : 'timothy' ,\n",
        "'Gene' : 'Christina' , 'gene' : 'christina' ,\n",
        "'Melanie' : 'Kyle' , 'melanie' : 'kyle' ,\n",
        "'Raymond' : 'Rachel' , 'raymond' : 'rachel' ,\n",
        "'Elke' : 'Laura' , 'elke' : 'laura' ,\n",
        "'Michelangelo' : 'Lauren' , 'michelangelo' : 'lauren' ,\n",
        "'Jack' : 'Amber' , 'jack' : 'amber' ,\n",
        "'Yuriko' : 'Brittany' , 'yuriko' : 'brittany' ,\n",
        "'Bieber' : 'Danielle' , 'bieber' : 'danielle' ,\n",
        "'Qin' : 'Richard' , 'qin' : 'richard' ,\n",
        "'Mei' : 'Kimberly' , 'mei' : 'kimberly' ,\n",
        "'Irving' : 'Jeffrey' , 'irving' : 'jeffrey' ,\n",
        "'Chisini' : 'Amy' , 'chisini' : 'amy' ,\n",
        "'Sandra' : 'Crystal' , 'sandra' : 'crystal' ,\n",
        "'Judy' : 'Michelle' , 'judy' : 'michelle' ,\n",
        "'Zola' : 'Tiffany' , 'zola' : 'tiffany' ,\n",
        "'Reinsdorf' : 'Jeremy' , 'reinsdorf' : 'jeremy' ,\n",
        "'Cline' : 'Benjamin' , 'cline' : 'benjamin' ,\n",
        "'Kelly' : 'Mark' , 'kelly' : 'mark' ,\n",
        "'Deng' : 'Emily' , 'deng' : 'emily' ,\n",
        "'Mitchell' : 'Aaron' , 'mitchell' : 'aaron' ,\n",
        "'Marie' : 'Charles' , 'marie' : 'charles' ,\n",
        "'Marilyn' : 'Rebecca' , 'marilyn' : 'rebecca' ,\n",
        "'Babe' : 'Jacob' , 'babe' : 'jacob' ,\n",
        "'Montero' : 'Stephen' , 'montero' : 'stephen' ,\n",
        "'William' : 'Patrick' , 'william' : 'patrick' ,\n",
        "'Senna' : 'Sean' , 'senna' : 'sean' ,\n",
        "'Harrison' : 'Erin' , 'harrison' : 'erin' ,\n",
        "'Kamal' : 'Zachary' , 'kamal' : 'zachary' ,\n",
        "'Bin' : 'Jamie' , 'bin' : 'jamie' ,\n",
        "'Ali' : 'Kelly' , 'ali' : 'kelly' ,\n",
        "'Elvis' : 'Samantha' , 'elvis' : 'samantha' ,\n",
        "'Osamu' : 'Nathan' , 'osamu' : 'nathan' ,\n",
        "'John' : 'Sara' , 'john' : 'sara' ,\n",
        "'Salvador' : 'Dustin' , 'salvador' : 'dustin' ,\n",
        "'King' : 'Paul' , 'king' : 'paul' ,\n",
        "'Bérégovoy' : 'Angela' , 'bérégovoy' : 'angela' ,\n",
        "'Anderson' : 'Tyler' , 'anderson' : 'tyler' ,\n",
        "'Goethe' : 'Scott' , 'goethe' : 'scott' ,\n",
        "'Maria' : 'Katherine' , 'maria' : 'katherine' ,\n",
        "'Amadeus' : 'Andrea' , 'amadeus' : 'andrea' ,\n",
        "'Jackson' : 'Gregory' , 'jackson' : 'gregory' ,\n",
        "'Robin' : 'Erica' , 'robin' : 'erica' ,\n",
        "'Guillermo' : 'Mary' , 'guillermo' : 'mary' ,\n",
        "'Snoop' : 'Travis' , 'snoop' : 'travis' ,\n",
        "'Mike' : 'Lisa' , 'mike' : 'lisa' ,\n",
        "'Browne' : 'Kenneth' , 'browne' : 'kenneth' ,\n",
        "'Sue' : 'Bryan' , 'sue' : 'bryan' ,\n",
        "'Mandela' : 'Lindsey' , 'mandela' : 'lindsey' ,\n",
        "'Christoph' : 'Kristen' , 'christoph' : 'kristen' ,\n",
        "'Inachis' : 'Jose' , 'inachis' : 'jose' ,\n",
        "'Ortiz' : 'Alexander' , 'ortiz' : 'alexander' ,\n",
        "'Carla' : 'Jesse' , 'carla' : 'jesse' ,\n",
        "'Green' : 'Katie' , 'green' : 'katie' ,\n",
        "'Gregory' : 'Lindsay' , 'gregory' : 'lindsay' ,\n",
        "'Jane' : 'Shannon' , 'jane' : 'shannon' ,\n",
        "'Chris' : 'Vanessa' , 'chris' : 'vanessa' ,\n",
        "'Norman' : 'Courtney' , 'norman' : 'courtney' ,\n",
        "'Mohammad' : 'Christine' , 'mohammad' : 'christine' ,\n",
        "'Graham' : 'Alicia' , 'graham' : 'alicia' ,\n",
        "'Andy' : 'Cody' , 'andy' : 'cody' ,\n",
        "'Fischer' : 'Allison' , 'fischer' : 'allison' ,\n",
        "'Kalinske' : 'Bradley' , 'kalinske' : 'bradley' ,\n",
        "'Hariri' : 'Samuel' , 'hariri' : 'samuel' ,\n",
        "'Klein' : 'Shawn' , 'klein' : 'shawn' ,\n",
        "'Jim' : 'April' , 'jim' : 'april' ,\n",
        "'Jordan' : 'Derek' , 'jordan' : 'derek' ,\n",
        "'Spears' : 'Kathryn' , 'spears' : 'kathryn' ,\n",
        "'Reagan' : 'Kristin' , 'reagan' : 'kristin' ,\n",
        "'Vinci' : 'Chad' , 'vinci' : 'chad' ,\n",
        "'Kim' : 'Jenna' , 'kim' : 'jenna' ,\n",
        "'Ogura' : 'Tara' , 'ogura' : 'tara' ,\n",
        "'Hawking' : 'Maria' , 'hawking' : 'maria' ,\n",
        "'Lupita' : 'Krystal' , 'lupita' : 'krystal' ,\n",
        "'Elson' : 'Jared' , 'elson' : 'jared' ,\n",
        "'Sarah' : 'Anna' , 'sarah' : 'anna' ,\n",
        "'Gabriel' : 'Edward' , 'gabriel' : 'edward' ,\n",
        "'Iverson' : 'Julie' , 'iverson' : 'julie' ,\n",
        "'Tang' : 'Peter' , 'tang' : 'peter' ,\n",
        "'Charles' : 'Holly' , 'charles' : 'holly' ,\n",
        "'Dick' : 'Marcus' , 'dick' : 'marcus' ,\n",
        "'Kieslowski' : 'Kristina' , 'kieslowski' : 'kristina' ,\n",
        "'Mitt' : 'Natalie' , 'mitt' : 'natalie' ,\n",
        "'Yamamoto' : 'Jordan' , 'yamamoto' : 'jordan' ,\n",
        "'Leloir' : 'Victoria' , 'leloir' : 'victoria' ,\n",
        "'Keats' : 'Jacqueline' , 'keats' : 'jacqueline' ,\n",
        "'Chaplin' : 'Corey' , 'chaplin' : 'corey' ,\n",
        "'Turners' : 'Keith' , 'turners' : 'keith' ,\n",
        "'Bush' : 'Monica' , 'bush' : 'monica' ,\n",
        "'Robinson' : 'Juan' , 'robinson' : 'juan' ,\n",
        "'Seiji' : 'Donald' , 'seiji' : 'donald' ,\n",
        "'Dib' : 'Cassandra' , 'dib' : 'cassandra' ,\n",
        "'Lady' : 'Meghan' , 'lady' : 'meghan' ,\n",
        "'Wilson' : 'Joel' , 'wilson' : 'joel' ,\n",
        "'Zhao' : 'Shane' , 'zhao' : 'shane' ,\n",
        "'Maurice' : 'Phillip' , 'maurice' : 'phillip' ,\n",
        "'Van' : 'Patricia' , 'van' : 'patricia' ,\n",
        "'Eugenio' : 'Brett' , 'eugenio' : 'brett' ,\n",
        "'Greene' : 'Ronald' , 'greene' : 'ronald' ,\n",
        "'Gerulaitis' : 'Catherine' , 'gerulaitis' : 'catherine' ,\n",
        "'Brett' : 'George' , 'brett' : 'george' ,\n",
        "'Linux' : 'Antonio' , 'linux' : 'antonio' ,\n",
        "'Alice' : 'Cynthia' , 'alice' : 'cynthia' ,\n",
        "'Tina' : 'Stacy' , 'tina' : 'stacy' ,\n",
        "'Debierne' : 'Kathleen' , 'debierne' : 'kathleen' ,\n",
        "'Spencer' : 'Raymond' , 'spencer' : 'raymond' ,\n",
        "'Presley' : 'Carlos' , 'presley' : 'carlos' ,\n",
        "'Shiro' : 'Brandi' , 'shiro' : 'brandi' ,\n",
        "'Normand' : 'Douglas' , 'normand' : 'douglas' ,\n",
        "'Ikeda' : 'Nathaniel' , 'ikeda' : 'nathaniel' ,\n",
        "'Picasso' : 'Ian' , 'picasso' : 'ian' ,\n",
        "'Frank' : 'Craig' , 'frank' : 'craig' ,\n",
        "'Lewis' : 'Brandy' , 'lewis' : 'brandy' ,\n",
        "'Kennedy' : 'Alex' , 'kennedy' : 'alex' ,\n",
        "'Trygve' : 'Valerie' , 'trygve' : 'valerie' ,\n",
        "'John' : 'Veronica' , 'john' : 'veronica' ,\n",
        "'Ianiero' : 'Cory' , 'ianiero' : 'cory' ,\n",
        "'Jimi' : 'Whitney' , 'jimi' : 'whitney' ,\n",
        "'Kate' : 'Gary' , 'kate' : 'gary' ,\n",
        "'Gilbert' : 'Derrick' , 'gilbert' : 'derrick' ,\n",
        "'Dean' : 'Philip' , 'dean' : 'philip' ,\n",
        "'Agog' : 'Luis' , 'agog' : 'luis' ,\n",
        "'Dylan' : 'Diana' , 'dylan' : 'diana' ,\n",
        "'Hideki' : 'Chelsea' , 'hideki' : 'chelsea' ,\n",
        "'Salam' : 'Leslie' , 'salam' : 'leslie' ,\n",
        "'Quentin' : 'Caitlin' , 'quentin' : 'caitlin' ,\n",
        "'Presley' : 'Leah' , 'presley' : 'leah' ,\n",
        "'Dan' : 'Natasha' , 'dan' : 'natasha' ,\n",
        "'Jospin' : 'Erika' , 'jospin' : 'erika' ,\n",
        "'Milius' : 'Casey' , 'milius' : 'casey' ,\n",
        "'André' : 'Latoya' , 'andré' : 'latoya' ,\n",
        "'Von' : 'Erik' , 'von' : 'erik' ,\n",
        "'Machado' : 'Dana' , 'machado' : 'dana' ,\n",
        "'Ann' : 'Victor' , 'ann' : 'victor' ,\n",
        "'Johnson' : 'Brent' , 'johnson' : 'brent' ,\n",
        "'Kazuko' : 'Dominique' , 'kazuko' : 'dominique' ,\n",
        "'Gaulle' : 'Frank' , 'gaulle' : 'frank' ,\n",
        "'Blunt' : 'Brittney' , 'blunt' : 'brittney' ,\n",
        "'Tracy' : 'Evan' , 'tracy' : 'evan' ,\n",
        "'Jekyll' : 'Gabriel' , 'jekyll' : 'gabriel' ,\n",
        "'Steve' : 'Julia' , 'steve' : 'julia' ,\n",
        "'Heidenreich' : 'Candice' , 'heidenreich' : 'candice' ,\n",
        "'Harry' : 'Karen' , 'harry' : 'karen' ,\n",
        "'Marlowe' : 'Melanie' , 'marlowe' : 'melanie' ,\n",
        "'Rosset' : 'Adrian' , 'rosset' : 'adrian' ,\n",
        "'Argentinean' : 'Stacey' , 'argentinean' : 'stacey' ,\n",
        "'Lennon' : 'Margaret' , 'lennon' : 'margaret' ,\n",
        "'Louis' : 'Sheena' , 'louis' : 'sheena' ,\n",
        "'Yukio' : 'Wesley' , 'yukio' : 'wesley' ,\n",
        "'Rosario' : 'Vincent' , 'rosario' : 'vincent' ,\n",
        "'Vitas' : 'Alexandra' , 'vitas' : 'alexandra' ,\n",
        "'Vladislav' : 'Katrina' , 'vladislav' : 'katrina' ,\n",
        "'Politkovskaya' : 'Bethany' , 'politkovskaya' : 'bethany' ,\n",
        "'Yamaha' : 'Nichole' , 'yamaha' : 'nichole' ,\n",
        "'Piaf' : 'Larry' , 'piaf' : 'larry' ,\n",
        "'Hitler' : 'Jeffery' , 'hitler' : 'jeffery' ,\n",
        "'Laden' : 'Curtis' , 'laden' : 'curtis' ,\n",
        "'Marquez' : 'Carrie' , 'marquez' : 'carrie' ,\n",
        "'Woodrow' : 'Todd' , 'woodrow' : 'todd' ,\n",
        "'Nick' : 'Blake' , 'nick' : 'blake' ,\n",
        "'Papon' : 'Christian' , 'papon' : 'christian' ,\n",
        "'Favre' : 'Randy' , 'favre' : 'randy' ,\n",
        "'Robbins' : 'Dennis' , 'robbins' : 'dennis' ,\n",
        "'Garcia' : 'Alison' , 'garcia' : 'alison' ,\n",
        "'Woolf' : 'Trevor' , 'woolf' : 'trevor' ,\n",
        "'Lucy' : 'Seth' , 'lucy' : 'seth' ,\n",
        "'Henry' : 'Kara' , 'henry' : 'kara' ,\n",
        "'Marge' : 'Joanna' , 'marge' : 'joanna' ,\n",
        "'Wallace' : 'Rachael' , 'wallace' : 'rachael' ,\n",
        "'Yukichi' : 'Luke' , 'yukichi' : 'luke' ,\n",
        "'Listyev' : 'Felicia' , 'listyev' : 'felicia' ,\n",
        "'Bill' : 'Brooke' , 'bill' : 'brooke' ,\n",
        "'Linda' : 'Austin' , 'linda' : 'austin' ,\n",
        "'Anna' : 'Candace' , 'anna' : 'candace' ,\n",
        "'Vance' : 'Jasmine' , 'vance' : 'jasmine' ,\n",
        "'Conway' : 'Jesus' , 'conway' : 'jesus' ,\n",
        "'Keast' : 'Alan' , 'keast' : 'alan' ,\n",
        "'Raghav' : 'Susan' , 'raghav' : 'susan' ,\n",
        "'Andris' : 'Sandra' , 'andris' : 'sandra' ,\n",
        "'Cup' : 'Tracy' , 'cup' : 'tracy' ,\n",
        "'Sidney' : 'Kayla' , 'sidney' : 'kayla' ,\n",
        "'Joe' : 'Nancy' , 'joe' : 'nancy' ,\n",
        "'Catherine' : 'Tina' , 'catherine' : 'tina' ,\n",
        "'Tyler' : 'Krystle' , 'tyler' : 'krystle' ,\n",
        "'Versace' : 'Russell' , 'versace' : 'russell' ,\n",
        "'Tomba' : 'Jeremiah' , 'tomba' : 'jeremiah' ,\n",
        "'Putin' : 'Carl' , 'putin' : 'carl' ,\n",
        "'Majoli' : 'Miguel' , 'majoli' : 'miguel' ,\n",
        "'Hasselt' : 'Tony' , 'hasselt' : 'tony' ,\n",
        "'Jones' : 'Alexis' , 'jones' : 'alexis' ,\n",
        "'Mccartney' : 'Gina' , 'mccartney' : 'gina' ,\n",
        "'Fisher' : 'Jillian' , 'fisher' : 'jillian' ,\n",
        "'Saburo' : 'Pamela' , 'saburo' : 'pamela' ,\n",
        "'Maischberger' : 'Mitchell' , 'maischberger' : 'mitchell' ,\n",
        "'Sharpton' : 'Hannah' , 'sharpton' : 'hannah' ,\n",
        "'Koko' : 'Renee' , 'koko' : 'renee' ,\n",
        "'Gates' : 'Denise' , 'gates' : 'denise' ,\n",
        "'Simon' : 'Molly' , 'simon' : 'molly' ,\n",
        "'Schneider' : 'Jerry' , 'schneider' : 'jerry' ,\n",
        "'Peron' : 'Misty' , 'peron' : 'misty' ,\n",
        "'Ellen' : 'Mario' , 'ellen' : 'mario' ,\n",
        "'Alfredo' : 'Johnathan' , 'alfredo' : 'johnathan' ,\n",
        "'Einstein' : 'Jaclyn' , 'einstein' : 'jaclyn' ,\n",
        "'Mika' : 'Brenda' , 'mika' : 'brenda' ,\n",
        "'Hours' : 'Terry' , 'hours' : 'terry' ,\n",
        "'Yasser' : 'Lacey' , 'yasser' : 'lacey' ,\n",
        "'Washington' : 'Shaun' , 'washington' : 'shaun' ,\n",
        "'Hayes' : 'Devin' , 'hayes' : 'devin' ,\n",
        "'James' : 'Heidi' , 'james' : 'heidi' ,\n",
        "'Abraham' : 'Troy' , 'abraham' : 'troy' ,\n",
        "'Oakley' : 'Lucas' , 'oakley' : 'lucas' ,\n",
        "'Chapman' : 'Desiree' , 'chapman' : 'desiree' ,\n",
        "'George' : 'Jorge' , 'george' : 'jorge' ,\n",
        "'Luna' : 'Andre' , 'luna' : 'andre' ,\n",
        "'Piet' : 'Morgan' , 'piet' : 'morgan' ,\n",
        "'Simone' : 'Drew' , 'simone' : 'drew' ,\n",
        "'Rembrandt' : 'Sabrina' , 'rembrandt' : 'sabrina' ,\n",
        "'Gore' : 'Miranda' , 'gore' : 'miranda' ,\n",
        "'Mohamed' : 'Alyssa' , 'mohamed' : 'alyssa' ,\n",
        "'Jean' : 'Alisha' , 'jean' : 'alisha' ,\n",
        "'Paolo' : 'Teresa' , 'paolo' : 'teresa' ,\n",
        "'Bob' : 'Johnny' , 'bob' : 'johnny' ,\n",
        "'Fukuzawa' : 'Meagan' , 'fukuzawa' : 'meagan' ,\n",
        "'Pearl' : 'Allen' , 'pearl' : 'allen' ,\n",
        "'Bower' : 'Krista' , 'bower' : 'krista' ,\n",
        "'Miller' : 'Marc' , 'miller' : 'marc' ,\n",
        "'André' : 'Tabitha' , 'andré' : 'tabitha' ,\n",
        "'Louis' : 'Lance' , 'louis' : 'lance' ,\n",
        "'Anwar' : 'Ricardo' , 'anwar' : 'ricardo' ,\n",
        "'Obama' : 'Martin' , 'obama' : 'martin' ,\n",
        "'Susan' : 'Chase' , 'susan' : 'chase' ,\n",
        "'Samuel' : 'Theresa' , 'samuel' : 'theresa' ,\n",
        "'Liisa' : 'Melinda' , 'liisa' : 'melinda' ,\n",
        "'Pettibon' : 'Monique' , 'pettibon' : 'monique' ,\n",
        "'Natasha' : 'Tanya' , 'natasha' : 'tanya' ,\n",
        "'Hussein' : 'Linda' , 'hussein' : 'linda' ,\n",
        "'Milosevic' : 'Kristopher' , 'milosevic' : 'kristopher' ,\n",
        "'Snow' : 'Bobby' , 'snow' : 'bobby' ,\n",
        "'Anthony' : 'Caleb' , 'anthony' : 'caleb' ,\n",
        "'Koko' : 'Ashlee' , 'koko' : 'ashlee' ,\n",
        "'Hart' : 'Kelli' , 'hart' : 'kelli' ,\n",
        "'Roosevelt' : 'Henry' , 'roosevelt' : 'henry' ,\n",
        "'Noriega' : 'Garrett' , 'noriega' : 'garrett' ,\n",
        "'Arafat' : 'Mallory' , 'arafat' : 'mallory' ,\n",
        "'Frederick' : 'Jill' , 'frederick' : 'jill' ,\n",
        "'Madonna' : 'Jonathon' , 'madonna' : 'jonathon' ,\n",
        "'Sappho' : 'Kristy' , 'sappho' : 'kristy' ,\n",
        "'Monroe' : 'Anne' , 'monroe' : 'anne' ,\n",
        "'Oscar' : 'Francisco' , 'oscar' : 'francisco' ,\n",
        "'Hug' : 'Danny' , 'hug' : 'danny' ,\n",
        "'Sofu' : 'Robin' , 'sofu' : 'robin' ,\n",
        "'Jorge' : 'Lee' , 'jorge' : 'lee' ,\n",
        "'Babbage' : 'Tamara' , 'babbage' : 'tamara' ,\n",
        "'Pablo' : 'Manuel' , 'pablo' : 'manuel' ,\n",
        "'Micky' : 'Meredith' , 'micky' : 'meredith' ,\n",
        "'Hale' : 'Colleen' , 'hale' : 'colleen' ,\n",
        "'Nelson' : 'Lawrence' , 'nelson' : 'lawrence' ,\n",
        "'Abbas' : 'Christy' , 'abbas' : 'christy' ,\n",
        "'Edwin' : 'Ricky' , 'edwin' : 'ricky' ,\n",
        "'Rawlings' : 'Randall' , 'rawlings' : 'randall' ,\n",
        "'Rachel' : 'Marissa' , 'rachel' : 'marissa' ,\n",
        "'Noguchi' : 'Ross' , 'noguchi' : 'ross' ,\n",
        "'Steffi' : 'Mathew' , 'steffi' : 'mathew' ,\n",
        "'Lech' : 'Jimmy' , 'lech' : 'jimmy' ,\n",
        "'Betty' : 'Abigail' , 'betty' : 'abigail' ,\n",
        "'Luther' : 'Kendra' , 'luther' : 'kendra' ,\n",
        "'Costas' : 'Carolyn' , 'costas' : 'carolyn' ,\n",
        "'Mishima' : 'Billy' , 'mishima' : 'billy' ,\n",
        "'Harper' : 'Deanna' , 'harper' : 'deanna' ,\n",
        "'Himekusa' : 'Jenny' , 'himekusa' : 'jenny' ,\n",
        "'Mary' : 'Jon' , 'mary' : 'jon' ,\n",
        "'Ford' : 'Albert' , 'ford' : 'albert' ,\n",
        "'Bob' : 'Taylor' , 'bob' : 'taylor' ,\n",
        "'Kinnan' : 'Lori' , 'kinnan' : 'lori' ,\n",
        "'Bach' : 'Rebekah' , 'bach' : 'rebekah' ,\n",
        "'Hashimoto' : 'Cameron' , 'hashimoto' : 'cameron' ,\n",
        "'Edberg' : 'Ebony' , 'edberg' : 'ebony' ,\n",
        "'Chopin' : 'Wendy' , 'chopin' : 'wendy' ,\n",
        "'Metin' : 'Angel' , 'metin' : 'angel' ,\n",
        "'Joseph' : 'Micheal' , 'joseph' : 'micheal' ,\n",
        "'Becker' : 'Kristi' , 'becker' : 'kristi' ,\n",
        "'Scrooge' : 'Caroline' , 'scrooge' : 'caroline' ,\n",
        "'Dalton' : 'Colin' , 'dalton' : 'colin' ,\n",
        "'Saad' : 'Dawn' , 'saad' : 'dawn' ,\n",
        "'Aurore' : 'Kari' , 'aurore' : 'kari' ,\n",
        "'Julie' : 'Clayton' , 'julie' : 'clayton' ,\n",
        "'Alberto' : 'Arthur' , 'alberto' : 'arthur' ,\n",
        "'Sadat' : 'Roger' , 'sadat' : 'roger' ,\n",
        "'Patterson' : 'Roberto' , 'patterson' : 'roberto' ,\n",
        "'Nikos' : 'Priscilla' , 'nikos' : 'priscilla' ,\n",
        "'Ken' : 'Darren' , 'ken' : 'darren' ,\n",
        "'Tanaka' : 'Kelsey' , 'tanaka' : 'kelsey' ,\n",
        "'Robert' : 'Clinton' , 'robert' : 'clinton' ,\n",
        "'Hunter' : 'Walter' , 'hunter' : 'walter' ,\n",
        "'Brad' : 'Louis' , 'brad' : 'louis' ,\n",
        "'Punched' : 'Barbara' , 'punched' : 'barbara' ,\n",
        "'Marty' : 'Isaac' , 'marty' : 'isaac' ,\n",
        "'Bonaparte' : 'Cassie' , 'bonaparte' : 'cassie' ,\n",
        "'Tamaro' : 'Grant' , 'tamaro' : 'grant' ,\n",
        "'Kaplan' : 'Cristina' , 'kaplan' : 'cristina' ,\n",
        "'Charlemagne' : 'Tonya' , 'charlemagne' : 'tonya' ,\n",
        "'Rex' : 'Rodney' , 'rex' : 'rodney' ,\n",
        "'Kaurismäki' : 'Bridget' , 'kaurismäki' : 'bridget' ,\n",
        "'Annan' : 'Joe' , 'annan' : 'joe' ,\n",
        "'Muhammad' : 'Cindy' , 'muhammad' : 'cindy' ,\n",
        "'Riel' : 'Oscar' , 'riel' : 'oscar' ,\n",
        "'Antoinette' : 'Willie' , 'antoinette' : 'willie' ,\n",
        "'Tiên' : 'Maurice' , 'tiên' : 'maurice' ,\n",
        "'Jackie' : 'Jaime' , 'jackie' : 'jaime' ,\n",
        "'Mike' : 'Angelica' , 'mike' : 'angelica' ,\n",
        "'Weinberg' : 'Sharon' , 'weinberg' : 'sharon' ,\n",
        "'Goudie' : 'Julian' , 'goudie' : 'julian' ,\n",
        "'Pacino' : 'Jack' , 'pacino' : 'jack' ,\n",
        "'Matthaeus' : 'Jay' , 'matthaeus' : 'jay' ,\n",
        "'Meyer' : 'Calvin' , 'meyer' : 'calvin' ,\n",
        "'Heather' : 'Marie' , 'heather' : 'marie' ,\n",
        "'Lisa' : 'Hector' , 'lisa' : 'hector' ,\n",
        "'Reinhardt' : 'Kate' , 'reinhardt' : 'kate' ,\n",
        "'Anne' : 'Adrienne' , 'anne' : 'adrienne' ,\n",
        "'Dixon' : 'Tasha' , 'dixon' : 'tasha' ,\n",
        "'Rudolf' : 'Michele' , 'rudolf' : 'michele' ,\n",
        "'Klaus' : 'Ana' , 'klaus' : 'ana' ,\n",
        "'Patsy' : 'Stefanie' , 'patsy' : 'stefanie' ,\n",
        "'Bauer' : 'Cara' , 'bauer' : 'cara' ,\n",
        "'Evans' : 'Alejandro' , 'evans' : 'alejandro' ,\n",
        "'Kourkoulos' : 'Ruben' , 'kourkoulos' : 'ruben' ,\n",
        "'Burt' : 'Gerald' , 'burt' : 'gerald' ,\n",
        "'Nobel' : 'Audrey' , 'nobel' : 'audrey' ,\n",
        "'Dalí' : 'Kristine' , 'dalí' : 'kristine' ,\n",
        "'Scott' : 'Ann' , 'scott' : 'ann' ,\n",
        "'Caesar' : 'Shana' , 'caesar' : 'shana' ,\n",
        "'Marjorie' : 'Javier' , 'marjorie' : 'javier' ,\n",
        "'Hawk' : 'Katelyn' , 'hawk' : 'katelyn' ,\n",
        "'Leonardo' : 'Brianna' , 'leonardo' : 'brianna' ,\n",
        "'Andres' : 'Bruce' , 'andres' : 'bruce' ,\n",
        "'Aldrin' : 'Deborah' , 'aldrin' : 'deborah' ,\n",
        "'Maggie' : 'Claudia' , 'maggie' : 'claudia' ,\n",
        "'Luke' : 'Carla' , 'luke' : 'carla' ,\n",
        "'Cameron' : 'Wayne' , 'cameron' : 'wayne' ,\n",
        "'Carson' : 'Roy' , 'carson' : 'roy' ,\n",
        "'Nicholson' : 'Virginia' , 'nicholson' : 'virginia' ,\n",
        "'Adams' : 'Haley' , 'adams' : 'haley' ,\n",
        "'Mel' : 'Brendan' , 'mel' : 'brendan' ,\n",
        "'Max' : 'Janelle' , 'max' : 'janelle' ,\n",
        "'Spike' : 'Jacquelyn' , 'spike' : 'jacquelyn' ,\n",
        "'Brandon' : 'Beth' , 'brandon' : 'beth' ,\n",
        "'Ogawa' : 'Edwin' , 'ogawa' : 'edwin' ,\n",
        "'Raman' : 'Dylan' , 'raman' : 'dylan' ,\n",
        "'Jerry' : 'Dominic' , 'jerry' : 'dominic' ,\n",
        "'Chizhov' : 'Latasha' , 'chizhov' : 'latasha' ,\n",
        "'Emi' : 'Darrell' , 'emi' : 'darrell' ,\n",
        "'Walt' : 'Geoffrey' , 'walt' : 'geoffrey' ,\n",
        "'Dazai' : 'Savannah' , 'dazai' : 'savannah' ,\n",
        "'Ayrton' : 'Reginald' , 'ayrton' : 'reginald' ,\n",
        "'Akira' : 'Carly' , 'akira' : 'carly' ,\n",
        "'Quincy' : 'Fernando' , 'quincy' : 'fernando' ,\n",
        "'Band' : 'Ashleigh' , 'band' : 'ashleigh' ,\n",
        "'Antonioni' : 'Aimee' , 'antonioni' : 'aimee' ,\n",
        "'Laden' : 'Regina' , 'laden' : 'regina' ,\n",
        "'Lennon' : 'Mandy' , 'lennon' : 'mandy' ,\n",
        "'Tom' : 'Sergio' , 'tom' : 'sergio' ,\n",
        "'Huber' : 'Rafael' , 'huber' : 'rafael' ,\n",
        "'Laura' : 'Pedro' , 'laura' : 'pedro' ,\n",
        "'Lancaster' : 'Janet' , 'lancaster' : 'janet' ,\n",
        "'Markku' : 'Kaitlin' , 'markku' : 'kaitlin' ,\n",
        "'Lopez' : 'Frederick' , 'lopez' : 'frederick' ,\n",
        "'Lionel' : 'Cheryl' , 'lionel' : 'cheryl' ,\n",
        "'Crichton' : 'Autumn' , 'crichton' : 'autumn' ,\n",
        "'Meir' : 'Tyrone' , 'meir' : 'tyrone' ,\n",
        "'Williams' : 'Martha' , 'williams' : 'martha' ,\n",
        "'Blackhawks' : 'Omar' , 'blackhawks' : 'omar' ,\n",
        "'Shi' : 'Lydia' , 'shi' : 'lydia' ,\n",
        "'Abrams' : 'Jerome' , 'abrams' : 'jerome' ,\n",
        "'Gianni' : 'Theodore' , 'gianni' : 'theodore' ,\n",
        "'Barack' : 'Abby' , 'barack' : 'abby' ,\n",
        "'Michael' : 'Neil' , 'michael' : 'neil' ,\n",
        "'Golda' : 'Shawna' , 'golda' : 'shawna' ,\n",
        "'Akagawa' : 'Sierra' , 'akagawa' : 'sierra' ,\n",
        "'Beethoven' : 'Nina' , 'beethoven' : 'nina' ,\n",
        "'Sipowicz' : 'Tammy' , 'sipowicz' : 'tammy' ,\n",
        "'Donald' : 'Nikki' , 'donald' : 'nikki' ,\n",
        "'Peter' : 'Terrance' , 'peter' : 'terrance' ,\n",
        "'Camdessus' : 'Claire' , 'camdessus' : 'claire' ,\n",
        "'Chomsky' : 'Cole' , 'chomsky' : 'cole' ,\n",
        "'Sheldon' : 'Trisha' , 'sheldon' : 'trisha' ,\n",
        "'Roy' : 'Bonnie' , 'roy' : 'bonnie' ,\n",
        "'Ghiorso' : 'Diane' , 'ghiorso' : 'diane' ,\n",
        "'Burped' : 'Summer' , 'burped' : 'summer' ,\n",
        "'Sara' : 'Carmen' , 'sara' : 'carmen' ,\n",
        "'Twenty' : 'Mayra' , 'twenty' : 'mayra' ,\n",
        "'Gospel' : 'Jermaine' , 'gospel' : 'jermaine' ,\n",
        "'Coello' : 'Eddie' , 'coello' : 'eddie' ,\n",
        "'Vincent' : 'Micah' , 'vincent' : 'micah' ,\n",
        "'Constant' : 'Marvin' , 'constant' : 'marvin' ,\n",
        "'Spears' : 'Levi' , 'spears' : 'levi' ,\n",
        "'Yoko' : 'Emmanuel' , 'yoko' : 'emmanuel' ,\n",
        "'Paquiss' : 'Brad' , 'paquiss' : 'brad' ,\n",
        "'Nana' : 'Taryn' , 'nana' : 'taryn' ,\n",
        "'Ted' : 'Toni' , 'ted' : 'toni' ,\n",
        "'Finkelstein' : 'Jessie' , 'finkelstein' : 'jessie' ,\n",
        "'Jessie' : 'Evelyn' , 'jessie' : 'evelyn' ,\n",
        "'Moncalvo' : 'Darryl' , 'moncalvo' : 'darryl' ,\n",
        "'Mohn' : 'Ronnie' , 'mohn' : 'ronnie' ,\n",
        "'Zappa' : 'Joy' , 'zappa' : 'joy' ,\n",
        "'Mambro' : 'Adriana' , 'mambro' : 'adriana' ,\n",
        "'Austen' : 'Ruth' , 'austen' : 'ruth' ,\n",
        "'Schubert' : 'Mindy' , 'schubert' : 'mindy' ,\n",
        "'Barbie' : 'Spencer' , 'barbie' : 'spencer' ,\n",
        "'Cruise' : 'Noah' , 'cruise' : 'noah' ,\n",
        "'Gertrude' : 'Raul' , 'gertrude' : 'raul' ,\n",
        "'Leeson' : 'Suzanne' , 'leeson' : 'suzanne' ,\n",
        "'Pedro' : 'Sophia' , 'pedro' : 'sophia' ,\n",
        "'Sid' : 'Dale' , 'sid' : 'dale' ,\n",
        "'Mari' : 'Jodi' , 'mari' : 'jodi' ,\n",
        "'Nyong' : 'Christie' , 'nyong' : 'christie' ,\n",
        "'Michel' : 'Raquel' , 'michel' : 'raquel' ,\n",
        "'Trump' : 'Naomi' , 'trump' : 'naomi' ,\n",
        "'Mondrian' : 'Kellie' , 'mondrian' : 'kellie' ,\n",
        "'Liz' : 'Ernest' , 'liz' : 'ernest' ,\n",
        "'Edison' : 'Jake' , 'edison' : 'jake' ,\n",
        "'Hanako' : 'Grace' , 'hanako' : 'grace' ,\n",
        "'Osama' : 'Tristan' , 'osama' : 'tristan' ,\n",
        "'Ibarra' : 'Shanna' , 'ibarra' : 'shanna' ,\n",
        "'Henri' : 'Hilary' , 'henri' : 'hilary' ,\n",
        "'Stich' : 'Eduardo' , 'stich' : 'eduardo' ,\n",
        "'Cathy' : 'Ivan' , 'cathy' : 'ivan' ,\n",
        "'Daping' : 'Hillary' , 'daping' : 'hillary' ,\n",
        "'Hans' : 'Yolanda' , 'hans' : 'yolanda' ,\n",
        "'Akiko' : 'Alberto' , 'akiko' : 'alberto' ,\n",
        "'Martin' : 'Andres' , 'martin' : 'andres' ,\n",
        "'Pitt' : 'Olivia' , 'pitt' : 'olivia' ,\n",
        "'Patricia' : 'Armando' , 'patricia' : 'armando' ,\n",
        "'Seuss' : 'Paula' , 'seuss' : 'paula' ,\n",
        "'Antonia' : 'Amelia' , 'antonia' : 'amelia' ,\n",
        "'Squirrel' : 'Sheila' , 'squirrel' : 'sheila' ,\n",
        "'Thomas' : 'Rosa' , 'thomas' : 'rosa' ,\n",
        "'Cleopatra' : 'Robyn' , 'cleopatra' : 'robyn' ,\n",
        "'Andre' : 'Kurt' , 'andre' : 'kurt' ,\n",
        "'Signoret' : 'Dane' , 'signoret' : 'dane' ,\n",
        "'Anke' : 'Glenn' , 'anke' : 'glenn' ,\n",
        "'Erkin' : 'Nicolas' , 'erkin' : 'nicolas' ,\n",
        "'Karmazin' : 'Gloria' , 'karmazin' : 'gloria' ,\n",
        "'Ball' : 'Eugene' , 'ball' : 'eugene' ,\n",
        "'Lie' : 'Logan' , 'lie' : 'logan' ,\n",
        "'Colbeck' : 'Steve' , 'colbeck' : 'steve' ,\n",
        "'Mantle' : 'Ramon' , 'mantle' : 'ramon' ,\n",
        "'Warren' : 'Bryce' , 'warren' : 'bryce' ,\n",
        "'Molly' : 'Tommy' , 'molly' : 'tommy' ,\n",
        "'Ingalls' : 'Preston' , 'ingalls' : 'preston' ,\n",
        "'Rutherford' : 'Keri' , 'rutherford' : 'keri' ,\n",
        "'Lincoln' : 'Devon' , 'lincoln' : 'devon' ,\n",
        "'Tomlinson' : 'Alana' , 'tomlinson' : 'alana' ,\n",
        "'Antonio' : 'Marisa' , 'antonio' : 'marisa' ,\n",
        "'Noriko' : 'Melody' , 'noriko' : 'melody' ,\n",
        "'Johann' : 'Rose' , 'johann' : 'rose' ,\n",
        "'Lenz' : 'Barry' , 'lenz' : 'barry' ,\n",
        "'Dale' : 'Marco' , 'dale' : 'marco' ,\n",
        "'Geiger' : 'Karl' , 'geiger' : 'karl' ,\n",
        "'Barbara' : 'Daisy' , 'barbara' : 'daisy' ,\n",
        "'Swift' : 'Leonard' , 'swift' : 'leonard' ,\n",
        "'Tony' : 'Randi' , 'tony' : 'randi' ,\n",
        "'Elaine' : 'Maggie' , 'elaine' : 'maggie' ,\n",
        "'Doggy' : 'Charlotte' , 'doggy' : 'charlotte' ,\n",
        "'Eva' : 'Emma' , 'eva' : 'emma' ,\n",
        "'Allan' : 'Terrence' , 'allan' : 'terrence' ,\n",
        "'Vladimir' : 'Justine' , 'vladimir' : 'justine' ,\n",
        "'Lillien' : 'Britney' , 'lillien' : 'britney' ,\n",
        "'Shannon' : 'Lacy' , 'shannon' : 'lacy' ,\n",
        "'Hideyo' : 'Jeanette' , 'hideyo' : 'jeanette' ,\n",
        "'Samir' : 'Francis' , 'samir' : 'francis' ,\n",
        "'Ruth' : 'Tyson' , 'ruth' : 'tyson' ,\n",
        "'Sakura' : 'Elise' , 'sakura' : 'elise' ,\n",
        "'West' : 'Sylvia' , 'west' : 'sylvia' ,\n",
        "'Agnès' : 'Rachelle' , 'agnès' : 'rachelle' ,\n",
        "'Tyson' : 'Stanley' , 'tyson' : 'stanley' ,\n",
        "'Justin' : 'Debra' , 'justin' : 'debra' ,\n",
        "'Andrew' : 'Brady' , 'andrew' : 'brady' ,\n",
        "'Quinn' : 'Charity' , 'quinn' : 'charity' ,\n",
        "'Carl' : 'Hope' , 'carl' : 'hope' ,\n",
        "'Clinton' : 'Melvin' , 'clinton' : 'melvin' ,\n",
        "'Buzz' : 'Johanna' , 'buzz' : 'johanna' ,\n",
        "'Zhou' : 'Karla' , 'zhou' : 'karla' ,\n",
        "'Marian' : 'Jarrod' , 'marian' : 'jarrod' ,\n",
        "'Jill' : 'Charlene' , 'jill' : 'charlene' ,\n",
        "'Purnell' : 'Gabrielle' , 'purnell' : 'gabrielle' ,\n",
        "'Jan' : 'Cesar' , 'jan' : 'cesar' ,\n",
        "'Emily' : 'Clifford' , 'emily' : 'clifford' ,\n",
        "'Whitfield' : 'Byron' , 'whitfield' : 'byron' ,\n",
        "'Novello' : 'Terrell' , 'novello' : 'terrell' ,\n",
        "'Nirvana' : 'Sonia' , 'nirvana' : 'sonia' ,\n",
        "'Lynn' : 'Julio' , 'lynn' : 'julio' ,\n",
        "'Carrie' : 'Stacie' , 'carrie' : 'stacie' ,\n",
        "'Kumi' : 'Shelby' , 'kumi' : 'shelby' ,\n",
        "'Wolfgang' : 'Shelly' , 'wolfgang' : 'shelly' ,\n",
        "'Harding' : 'Edgar' , 'harding' : 'edgar' ,\n",
        "'Virginia' : 'Roxanne' , 'virginia' : 'roxanne' ,\n",
        "'Irving' : 'Dwayne' , 'irving' : 'dwayne' ,\n",
        "'Rosa' : 'Kaitlyn' , 'rosa' : 'kaitlyn' ,\n",
        "'Lin' : 'Kasey' , 'lin' : 'kasey' ,\n",
        "'Mahatma' : 'Jocelyn' , 'mahatma' : 'jocelyn' ,\n",
        "'Smith' : 'Alexandria' , 'smith' : 'alexandria' ,\n",
        "'Glashow' : 'Harold' , 'glashow' : 'harold' ,\n",
        "'Odette' : 'Esther' , 'odette' : 'esther' ,\n",
        "'Dickens' : 'Kerri' , 'dickens' : 'kerri' ,\n",
        "'Mark' : 'Ellen' , 'mark' : 'ellen' ,\n",
        "'Brown' : 'Abraham' , 'brown' : 'abraham' ,\n",
        "'Leo' : 'Cedric' , 'leo' : 'cedric' ,\n",
        "'Iva' : 'Carol' , 'iva' : 'carol' ,\n",
        "'Lida' : 'Katharine' , 'lida' : 'katharine' ,\n",
        "'Alfred' : 'Shauna' , 'alfred' : 'shauna' ,\n",
        "'Bukowski' : 'Frances' , 'bukowski' : 'frances' ,\n",
        "'Brontë' : 'Antoine' , 'brontë' : 'antoine' ,\n",
        "'Tarantino' : 'Tabatha' , 'tarantino' : 'tabatha' ,\n",
        "'Lidya' : 'Annie' , 'lidya' : 'annie' ,\n",
        "'Saddam' : 'Erick' , 'saddam' : 'erick' ,\n",
        "'Goodell' : 'Alissa' , 'goodell' : 'alissa' ,\n",
        "'Charlotte' : 'Sherry' , 'charlotte' : 'sherry' ,\n",
        "'Romney' : 'Chelsey' , 'romney' : 'chelsey' ,\n",
        "'Garfunkel' : 'Franklin' , 'garfunkel' : 'franklin' ,\n",
        "'Atahualpa' : 'Branden' , 'atahualpa' : 'branden' ,\n",
        "'Gottfried' : 'Helen' , 'gottfried' : 'helen' ,\n",
        "'Karim' : 'Traci' , 'karim' : 'traci' ,\n",
        "'Marley' : 'Lorenzo' , 'marley' : 'lorenzo' ,\n",
        "'Christian' : 'Dean' , 'christian' : 'dean' ,\n",
        "'Piao' : 'Sonya' , 'piao' : 'sonya' ,\n",
        "'Primus' : 'Briana' , 'primus' : 'briana' ,\n",
        "'Armstrong' : 'Angelina' , 'armstrong' : 'angelina' ,\n",
        "'Mozart' : 'Trista' , 'mozart' : 'trista' ,\n",
        "'Yamauchi' : 'Bianca' , 'yamauchi' : 'bianca' ,\n",
        "'Hillary' : 'Leticia' , 'hillary' : 'leticia' ,\n",
        "'Mona' : 'Tia' , 'mona' : 'tia' ,\n",
        "'Roger' : 'Kristie' , 'roger' : 'kristie' ,\n",
        "'Vanessa' : 'Stuart' , 'vanessa' : 'stuart' ,\n",
        "'Aaron' : 'Laurie' , 'aaron' : 'laurie' ,\n",
        "'Pierrot' : 'Harry' , 'pierrot' : 'harry' ,\n",
        "'Huang' : 'Leigh' , 'huang' : 'leigh' ,\n",
        "'Hooper' : 'Elisabeth' , 'hooper' : 'elisabeth' ,\n",
        "'Pikes' : 'Alfredo' , 'pikes' : 'alfredo' ,\n",
        "'Agassi' : 'Aubrey' , 'agassi' : 'aubrey' ,\n",
        "'Pierre' : 'Ray' , 'pierre' : 'ray' ,\n",
        "'Seles' : 'Arturo' , 'seles' : 'arturo' ,\n",
        "'Croatian' : 'Joey' , 'croatian' : 'joey' ,\n",
        "'Beavers' : 'Kelley' , 'beavers' : 'kelley' ,\n",
        "'Diana' : 'Max' , 'diana' : 'max' ,\n",
        "'Claxton' : 'Andy' , 'claxton' : 'andy' ,\n",
        "'Escobar' : 'Latisha' , 'escobar' : 'latisha' ,\n",
        "'Graf' : 'Johnathon' , 'graf' : 'johnathon' ,\n",
        "'Cristiani' : 'India' , 'cristiani' : 'india' ,\n",
        "'Stefan' : 'Eva' , 'stefan' : 'eva' ,\n",
        "'Dogg' : 'Ralph' , 'dogg' : 'ralph' ,\n",
        "'Hiddink' : 'Yvonne' , 'hiddink' : 'yvonne' ,\n",
        "'Gandhi' : 'Warren' , 'gandhi' : 'warren' ,\n",
        "'Paul' : 'Kirsten' , 'paul' : 'kirsten' ,\n",
        "'Sinatra' : 'Miriam' , 'sinatra' : 'miriam' ,\n",
        "'Dickson' : 'Kelvin' , 'dickson' : 'kelvin' ,\n",
        "'Ania' : 'Lorena' , 'ania' : 'lorena' ,\n",
        "'Eileen' : 'Staci' , 'eileen' : 'staci' ,\n",
        "'White' : 'Anita' , 'white' : 'anita' ,\n",
        "'Wang' : 'Rene' , 'wang' : 'rene' ,\n",
        "'Dinosaurs' : 'Cortney' , 'dinosaurs' : 'cortney' ,\n",
        "'Bērziņš' : 'Orlando' , 'bērziņš' : 'orlando' ,\n",
        "'Sung' : 'Carissa' , 'sung' : 'carissa' ,\n",
        "'Napoleon' : 'Jade' , 'napoleon' : 'jade' ,\n",
        "'Lee' : 'Camille' , 'lee' : 'camille' ,\n",
        "'Allen' : 'Leon' , 'allen' : 'leon' ,\n",
        "'Darwin' : 'Paige' , 'darwin' : 'paige' ,\n",
        "'Brutus' : 'Marcos' , 'brutus' : 'marcos' ,\n",
        "'Bartow' : 'Elena' , 'bartow' : 'elena' ,\n",
        "'Chapin' : 'Brianne' , 'chapin' : 'brianne' ,\n",
        "'Jeff' : 'Dorothy' , 'jeff' : 'dorothy' ,\n",
        "'Speedy' : 'Marshall' , 'speedy' : 'marshall' ,\n",
        "'Albert' : 'Daryl' , 'albert' : 'daryl' ,\n",
        "'Houdini' : 'Colby' , 'houdini' : 'colby' ,\n",
        "'Susanna' : 'Terri' , 'susanna' : 'terri' ,\n",
        "'Scharping' : 'Gabriela' , 'scharping' : 'gabriela' ,\n",
        "'Dracula' : 'Brock' , 'dracula' : 'brock' ,\n",
        "'Karen' : 'Gerardo' , 'karen' : 'gerardo' ,\n",
        "'Tomoyuki' : 'Jane' , 'tomoyuki' : 'jane' ,\n",
        "'Minton' : 'Nelson' , 'minton' : 'nelson' ,\n",
        "'Jackson' : 'Tamika' , 'jackson' : 'tamika' ,\n",
        "'Chuck' : 'Alvin' , 'chuck' : 'alvin' ,\n",
        "'Emil' : 'Chasity' , 'emil' : 'chasity' ,\n",
        "'Charlie' : 'Trent' , 'charlie' : 'trent' ,\n",
        "'Margaret' : 'Jana' , 'margaret' : 'jana' ,\n",
        "'Scorsese' : 'Enrique' , 'scorsese' : 'enrique' ,\n",
        "'Shostakovich' : 'Tracey' , 'shostakovich' : 'tracey' ,\n",
        "'Bakula' : 'Antoinette' , 'bakula' : 'antoinette' ,\n",
        "'Schaller' : 'Jami' , 'schaller' : 'jami' ,\n",
        "'Simpson' : 'Earl' , 'simpson' : 'earl' ,\n",
        "'Pizarro' : 'Gilbert' , 'pizarro' : 'gilbert' ,\n",
        "'Hendrix' : 'Damien' , 'hendrix' : 'damien' ,\n",
        "'Taro' : 'Janice' , 'taro' : 'janice' ,\n",
        "'Marzipan' : 'Christa' , 'marzipan' : 'christa' ,\n",
        "'Adolf' : 'Tessa' , 'adolf' : 'tessa' ,\n",
        "'Elba' : 'Kirk' , 'elba' : 'kirk' ,\n",
        "'Teresa' : 'Yvette' , 'teresa' : 'yvette' ,\n",
        "'Marc' : 'Elijah' , 'marc' : 'elijah' ,\n",
        "'Will' : 'Howard' , 'will' : 'howard' ,\n",
        "'Tolstoy' : 'Elisa' , 'tolstoy' : 'elisa' ,\n",
        "'Brian' : 'Desmond' , 'brian' : 'desmond' ,\n",
        "'Gabi' : 'Clarence' , 'gabi' : 'clarence' ,\n",
        "'Nicholas' : 'Alfred' , 'nicholas' : 'alfred' ,\n",
        "'Milkman' : 'Darnell' , 'milkman' : 'darnell' ,\n",
        "'Nancy' : 'Breanna' , 'nancy' : 'breanna' ,\n",
        "'Dennis' : 'Kerry' , 'dennis' : 'kerry' ,\n",
        "'Helen' : 'Nickolas' , 'helen' : 'nickolas' ,\n",
        "'Manson' : 'Maureen' , 'manson' : 'maureen' ,\n",
        "'Redgrave' : 'Karina' , 'redgrave' : 'karina' ,\n",
        "'Gogh' : 'Roderick' , 'gogh' : 'roderick' ,\n",
        "'Wolf' : 'Rochelle' , 'wolf' : 'rochelle' ,\n",
        "'Bont' : 'Rhonda' , 'bont' : 'rhonda' ,\n",
        "'Collins' : 'Keisha' , 'collins' : 'keisha' ,\n",
        "'Mabel' : 'Irene' , 'mabel' : 'irene' ,\n",
        "'Montale' : 'Ethan' , 'montale' : 'ethan' ,\n",
        "'Tiilikainen' : 'Alice' , 'tiilikainen' : 'alice' ,\n",
        "\n",
        "#countries\n",
        "'Turkey' : 'Afghanistan' , 'turkey' : 'afghanistan' ,\n",
        "'Mexico' : 'Albania' , 'mexico' : 'albania' ,\n",
        "'Italy' : 'Algeria' , 'italy' : 'algeria' ,\n",
        "'Libya' : 'Andorra' , 'libya' : 'andorra' ,\n",
        "'Argentina' : 'Angola' , 'argentina' : 'angola' ,\n",
        "'Indonesia' : 'Iceland' , 'indonesia' : 'iceland' ,\n",
        "'Japan' : 'India' , 'japan' : 'india' ,\n",
        "'Somalia' : 'Indonesia' , 'somalia' : 'indonesia' ,\n",
        "'Israel' : 'Iran' , 'israel' : 'iran' ,\n",
        "'Greece' : 'Iraq' , 'greece' : 'iraq' ,\n",
        "'Cambodia' : 'Ireland' , 'cambodia' : 'ireland' ,\n",
        "'Morocco' : 'Romania' , 'morocco' : 'romania' ,\n",
        "'Malaysia' : 'Russia' , 'malaysia' : 'russia' ,\n",
        "'Canada' : 'Rwanda' , 'hong kong' : 'rwanda' ,\n",
        "'Switzerland' : 'Jamaica' , 'canada' : 'jamaica' ,\n",
        "'Sweden' : 'Japan' , 'switzerland' : 'japan' ,\n",
        "'Eritrea' : 'Jordan' , 'sweden' : 'jordan' ,\n",
        "'India' : 'Kenya' , 'eritrea' : 'kenya' ,\n",
        "'Mauritania' : 'Kiribati' , 'india' : 'kiribati' ,\n",
        "'Lebanon' : 'Kosovo' , 'mauritania' : 'kosovo' ,\n",
        "'Germany' : 'Kuwait' , 'lebanon' : 'kuwait' ,\n",
        "'Greenland' : 'Kyrgyzstan' , 'germany' : 'kyrgyzstan' ,\n",
        "'Jordan' : 'Botswana' , 'greenland' : 'botswana' ,\n",
        "'Colombia' : 'Brazil' , 'jordan' : 'brazil' ,\n",
        "'Peru' : 'Brunei' , 'colombia' : 'brunei' ,\n",
        "'Latvia' : 'Bulgaria' , 'new zealand' : 'bulgaria' ,\n",
        "'Albania' : 'Chad' , 'peru' : 'chad' ,\n",
        "'Austria' : 'Chile' , 'latvia' : 'chile' ,\n",
        "'Kazakhstan' : 'China' , 'albania' : 'china' ,\n",
        "'Lithuania' : 'Colombia' , 'austria' : 'colombia' ,\n",
        "'Brazil' : 'Comoros' , 'kazakhstan' : 'comoros' ,\n",
        "'Zambia' : 'Mauritius' , 'lithuania' : 'mauritius' ,\n",
        "'Netherlands' : 'Mexico' , 'brazil' : 'mexico' ,\n",
        "'Ukraine' : 'Micronesia' , 'zambia' : 'micronesia' ,\n",
        "'Iceland' : 'Moldova' , 'netherlands' : 'moldova' ,\n",
        "'canada' : 'Monaco' , 'ukraine' : 'monaco' ,\n",
        "'Poland' : 'Mongolia' , 'iceland' : 'mongolia' ,\n",
        "'Cuba' : 'Montenegro' , 'canada' : 'montenegro' ,\n",
        "'Norway' : 'Morocco' , 'poland' : 'morocco' ,\n",
        "'Iraq' : 'Mozambique' , 'cuba' : 'mozambique' ,\n",
        "'Romania' : 'Myanmar' , 'norway' : 'myanmar' ,\n",
        "'China' : 'Fiji' , 'iraq' : 'fiji' ,\n",
        "'Thailand' : 'Finland' , 'romania' : 'finland' ,\n",
        "'Ethiopia' : 'France' , 'china' : 'france' ,\n",
        "'Georgia' : 'Paraguay' , 'thailand' : 'paraguay' ,\n",
        "'Algeria' : 'Peru' , 'united states' : 'peru' ,\n",
        "'Singapore' : 'Philippines' , 'ethiopia' : 'philippines' ,\n",
        "'Finland' : 'Poland' , 'georgia' : 'poland' ,\n",
        "'Egypt' : 'Portugal' , 'algeria' : 'portugal' ,\n",
        "'Australia' : 'Vanuatu' , 'singapore' : 'vanuatu' ,\n",
        "'France' : 'Venezuela' , 'finland' : 'venezuela' ,\n",
        "'Spain' : 'Vietnam' , 'egypt' : 'vietnam' ,\n",
        "'Ireland' : 'Pakistan' , 'australia' : 'pakistan' ,\n",
        "\n",
        "#states\n",
        "'Seoul' : 'Alaska' , 'seoul' : 'alaska' ,\n",
        "'Taiwan' : 'Alabama' , 'taiwan' : 'alabama' ,\n",
        "'Nara' : 'Arkansas' , 'nara' : 'arkansas' ,\n",
        "'North' : 'Arizona' , 'north' : 'arizona' ,\n",
        "'England' : 'California' , 'england' : 'california' ,\n",
        "'Coventry' : 'Colorado' , 'coventry' : 'colorado' ,\n",
        "'Rome' : 'Connecticut' , 'rome' : 'connecticut' ,\n",
        "'Pisa' : 'Delaware' , 'pisa' : 'delaware' ,\n",
        "'Lisbon' : 'Florida' , 'lisbon' : 'florida' ,\n",
        "'Moscow' : 'Georgia' , 'moscow' : 'georgia' ,\n",
        "'Barcelona' : 'Guam' , 'barcelona' : 'guam' ,\n",
        "'Hamburg' : 'Hawaii' , 'hamburg' : 'hawaii' ,\n",
        "'Massachusetts' : 'Iowa' , 'massachusetts' : 'iowa' ,\n",
        "'Illinois' : 'Idaho' , 'illinois' : 'idaho' ,\n",
        "'California' : 'Illinois' , 'california' : 'illinois' ,\n",
        "'Ohio' : 'Indiana' , 'ohio' : 'indiana' ,\n",
        "'Texas' : 'Kansas' , 'texas' : 'kansas' ,\n",
        "'Florida' : 'Kentucky' , 'florida' : 'kentucky' ,\n",
        "'Washington' : 'Louisiana' , 'washington' : 'louisiana' ,\n",
        "'Mississippi' : 'Massachusetts' , 'mississippi' : 'massachusetts' ,\n",
        "'Georgia' : 'Maryland' , 'georgia' : 'maryland' ,\n",
        "'Missouri' : 'Maine' , 'missouri' : 'maine' ,\n",
        "'Louisiana' : 'Michigan' , 'louisiana' : 'michigan' ,\n",
        "'Indiana' : 'Minnesota' , 'indiana' : 'minnesota' ,\n",
        "'Michigan' : 'Missouri' , 'michigan' : 'missouri' ,\n",
        "'South' : 'Mississippi' , 'south' : 'mississippi' ,\n",
        "'Istanbul' : 'Montana' , 'istanbul' : 'montana' ,\n",
        "'Paris' : 'Nebraska' , 'paris' : 'nebraska' ,\n",
        "'Hawaii' : 'Nevada' , 'hawaii' : 'nevada' ,\n",
        "'Alaska' : 'Ohio' , 'alaska' : 'ohio' ,\n",
        "'Auckland' : 'Oklahoma' , 'auckland' : 'oklahoma' ,\n",
        "'Saskatchewan' : 'Oregon' , 'saskatchewan' : 'oregon' ,\n",
        "'Okinawa' : 'Pennsylvania' , 'okinawa' : 'pennsylvania' ,\n",
        "'Hiroshima' : 'Tennessee' , 'hiroshima' : 'tennessee' ,\n",
        "'Salzburg' : 'Texas' , 'salzburg' : 'texas' ,\n",
        "'Alexandria' : 'Utah' , 'alexandria' : 'utah' ,\n",
        "'Edo' : 'Virginia' , 'edo' : 'virginia' ,\n",
        "'Adamawa' : 'Vermont' , 'adamawa' : 'vermont' ,\n",
        "'Western' : 'Washington' , 'western' : 'washington' ,\n",
        "'Northwest' : 'Wisconsin' , 'northwest' : 'wisconsin' ,\n",
        "'Fukui' : 'Wyoming' , 'fukui' : 'wyoming' ,\n",
        "'Nagasaki' : 'Alberta' , 'nagasaki' : 'alberta' ,\n",
        "'Chiapas' : 'Manitoba' , 'chiapas' : 'manitoba' ,\n",
        "'Chechnya' : 'Nunavut' , 'chechnya' : 'nunavut' ,\n",
        "'Portland' : 'Ontario' , 'portland' : 'ontario' ,\n",
        "'Hanover' : 'Quebec' , 'hanover' : 'quebec' ,\n",
        "\n",
        "#cities\n",
        "'Tokyo' : 'Aberdeen' , 'tokyo' : 'aberdeen' ,\n",
        "'Beijing' : 'Abilene' , 'beijing' : 'abilene' ,\n",
        "'Seoul' : 'Akron' , 'seoul' : 'akron' ,\n",
        "'Kawasaki' : 'Albany' , 'kawasaki' : 'albany' ,\n",
        "'Yokohama' : 'Albuquerque' , 'yokohama' : 'albuquerque' ,\n",
        "'Nagoya' : 'Alexandria' , 'nagoya' : 'alexandria' ,\n",
        "'Kyoto' : 'Allentown' , 'kyoto' : 'allentown' ,\n",
        "'Nara' : 'Amarillo' , 'nara' : 'amarillo' ,\n",
        "'Kobe' : 'Anaheim' , 'kobe' : 'anaheim' ,\n",
        "'Darwin' : 'Anchorage' , 'darwin' : 'anchorage' ,\n",
        "'Nantes' : 'Antioch' , 'nantes' : 'antioch' ,\n",
        "'London' : 'Appleton' , 'london' : 'appleton' ,\n",
        "'Coventry' : 'Arlington' , 'coventry' : 'arlington' ,\n",
        "'March' : 'Arvada' , 'march' : 'arvada' ,\n",
        "'Lincoln' : 'Asheville' , 'lincoln' : 'asheville' ,\n",
        "'Fulham' : 'Athens' , 'fulham' : 'athens' ,\n",
        "'Rome' : 'Atlanta' , 'rome' : 'atlanta' ,\n",
        "'Pisa' : 'Augusta' , 'pisa' : 'augusta' ,\n",
        "'Jerusalem' : 'Aurora' , 'jerusalem' : 'aurora' ,\n",
        "'Lisbon' : 'Austin' , 'lisbon' : 'austin' ,\n",
        "'Paul' : 'Bakersfield' , 'paul' : 'bakersfield' ,\n",
        "'Athens' : 'Baltimore' , 'athens' : 'baltimore' ,\n",
        "'Volgograd' : 'Barnstable' , 'volgograd' : 'barnstable' ,\n",
        "'Moscow' : 'Beaumont' , 'moscow' : 'beaumont' ,\n",
        "'Boston' : 'Bellevue' , 'boston' : 'bellevue' ,\n",
        "'Anna' : 'Berkeley' , 'anna' : 'berkeley' ,\n",
        "'Washington' : 'Bethlehem' , 'washington' : 'bethlehem' ,\n",
        "'Barcelona' : 'Billings' , 'barcelona' : 'billings' ,\n",
        "'Berlin' : 'Birmingham' , 'berlin' : 'birmingham' ,\n",
        "'Hamburg' : 'Bloomington' , 'hamburg' : 'bloomington' ,\n",
        "'Hanover' : 'Boise' , 'hanover' : 'boise' ,\n",
        "'Stuttgart' : 'Boston' , 'stuttgart' : 'boston' ,\n",
        "'Vinci' : 'Boulder' , 'vinci' : 'boulder' ,\n",
        "'Chicago' : 'Bradenton' , 'chicago' : 'bradenton' ,\n",
        "'Portland' : 'Bremerton' , 'portland' : 'bremerton' ,\n",
        "'Alexandria' : 'Bridgeport' , 'alexandria' : 'bridgeport' ,\n",
        "'Buffalo' : 'Brighton' , 'buffalo' : 'brighton' ,\n",
        "'Clinton' : 'Brownsville' , 'clinton' : 'brownsville' ,\n",
        "'Jackson' : 'Bryan' , 'jackson' : 'bryan' ,\n",
        "'Dallas' : 'Buffalo' , 'dallas' : 'buffalo' ,\n",
        "'Edison' : 'Burbank' , 'edison' : 'burbank' ,\n",
        "'Frederick' : 'Burlington' , 'frederick' : 'burlington' ,\n",
        "'Justin' : 'Cambridge' , 'justin' : 'cambridge' ,\n",
        "'Dickson' : 'Canton' , 'dickson' : 'canton' ,\n",
        "'Spencer' : 'Carrollton' , 'spencer' : 'carrollton' ,\n",
        "'Istanbul' : 'Cary' , 'istanbul' : 'cary' ,\n",
        "'Paris' : 'Champaign' , 'paris' : 'champaign' ,\n",
        "'Nancy' : 'Chandler' , 'nancy' : 'chandler' ,\n",
        "'Vladivostok' : 'Charleston' , 'vladivostok' : 'charleston' ,\n",
        "'Dublin' : 'Charlotte' , 'dublin' : 'charlotte' ,\n",
        "'Tbilisi' : 'Chattanooga' , 'tbilisi' : 'chattanooga' ,\n",
        "'Pskov' : 'Chesapeake' , 'pskov' : 'chesapeake' ,\n",
        "'Columbia' : 'Chicago' , 'columbia' : 'chicago' ,\n",
        "'Canadian' : 'Cincinnati' , 'canadian' : 'cincinnati' ,\n",
        "'California' : 'Clarksville' , 'california' : 'clarksville' ,\n",
        "'Egypt' : 'Clearwater' , 'egypt' : 'clearwater' ,\n",
        "'Pacific' : 'Cleveland' , 'pacific' : 'cleveland' ,\n",
        "'Lebanon' : 'Columbia' , 'lebanon' : 'columbia' ,\n",
        "'Vance' : 'Columbus' , 'vance' : 'columbus' ,\n",
        "'Mexico' : 'Concord' , 'mexico' : 'concord' ,\n",
        "'Holland' : 'Corona' , 'holland' : 'corona' ,\n",
        "'Cameron' : 'Dallas' , 'cameron' : 'dallas' ,\n",
        "'Hebron' : 'Danbury' , 'hebron' : 'danbury' ,\n",
        "'Tracy' : 'Davenport' , 'tracy' : 'davenport' ,\n",
        "'Liberty' : 'Dayton' , 'liberty' : 'dayton' ,\n",
        "'Patterson' : 'Deltona' , 'patterson' : 'deltona' ,\n",
        "'Hope' : 'Denton' , 'hope' : 'denton' ,\n",
        "'Beverly' : 'Denver' , 'beverly' : 'denver' ,\n",
        "'Truckee' : 'Detroit' , 'truckee' : 'detroit' ,\n",
        "'Alice' : 'Downey' , 'alice' : 'downey' ,\n",
        "'Harvard' : 'Duluth' , 'harvard' : 'duluth' ,\n",
        "'Thomas' : 'Durham' , 'thomas' : 'durham' ,\n",
        "'Scott' : 'Elizabeth' , 'scott' : 'elizabeth' ,\n",
        "'Yale' : 'Elkhart' , 'yale' : 'elkhart' ,\n",
        "'Everest' : 'Erie' , 'everest' : 'erie' ,\n",
        "'Cuba' : 'Escondido' , 'cuba' : 'escondido' ,\n",
        "'Auckland' : 'Eugene' , 'auckland' : 'eugene' ,\n",
        "'Singapore' : 'Evansville' , 'singapore' : 'evansville' ,\n",
        "'Bali' : 'Fairfield' , 'bali' : 'fairfield' ,\n",
        "'Marian' : 'Fargo' , 'marian' : 'fargo' ,\n",
        "'Kunming' : 'Fayetteville' , 'kunming' : 'fayetteville' ,\n",
        "'Calgary' : 'Fitchburg' , 'calgary' : 'fitchburg' ,\n",
        "'Scotland' : 'Flint' , 'scotland' : 'flint' ,\n",
        "'Peru' : 'Fontana' , 'peru' : 'fontana' ,\n",
        "'McDonald' : 'Frederick' , 'mcdonald' : 'frederick' ,\n",
        "'Indiana' : 'Fremont' , 'indiana' : 'fremont' ,\n",
        "'Apollo' : 'Fresno' , 'apollo' : 'fresno' ,\n",
        "'Hooper' : 'Fullerton' , 'hooper' : 'fullerton' ,\n",
        "'Roy' : 'Gainesville' , 'roy' : 'gainesville' ,\n",
        "'Napoleon' : 'Garland' , 'napoleon' : 'garland' ,\n",
        "'Jack' : 'Gastonia' , 'jack' : 'gastonia' ,\n",
        "'Jordan' : 'Gilbert' , 'jordan' : 'gilbert' ,\n",
        "'Charlemagne' : 'Glendale' , 'charlemagne' : 'glendale' ,\n",
        "'Johnson' : 'Grayslake' , 'johnson' : 'grayslake' ,\n",
        "'Greenland' : 'GreenBay' , 'greenland' : 'greenbay' ,\n",
        "'Rex' : 'Greensboro' , 'rex' : 'greensboro' ,\n",
        "'Brazil' : 'Greenville' , 'brazil' : 'greenville' ,\n",
        "'Mars' : 'Hagerstown' , 'mars' : 'hagerstown' ,\n",
        "'Cairo' : 'Hampton' , 'cairo' : 'hampton' ,\n",
        "'Achille' : 'Harlingen' , 'achille' : 'harlingen' ,\n",
        "'Laura' : 'Harrisburg' , 'laura' : 'harrisburg' ,\n",
        "'Spanish' : 'Hartford' , 'spanish' : 'hartford' ,\n",
        "'Florida' : 'Hayward' , 'florida' : 'hayward' ,\n",
        "'White' : 'Hemet' , 'white' : 'hemet' ,\n",
        "'Roosevelt' : 'Henderson' , 'roosevelt' : 'henderson' ,\n",
        "'Osaka' : 'Hesperia' , 'osaka' : 'hesperia' ,\n",
        "'Sapporo' : 'Hialeah' , 'sapporo' : 'hialeah' ,\n",
        "'Fuji' : 'Hickory' , 'fuji' : 'hickory' ,\n",
        "'Kanazawa' : 'Hollywood' , 'kanazawa' : 'hollywood' ,\n",
        "'Shinjuku' : 'Honolulu' , 'shinjuku' : 'honolulu' ,\n",
        "'God' : 'Houma' , 'god' : 'houma' ,\n",
        "'Ford' : 'Houston' , 'ford' : 'houston' ,\n",
        "'Salzburg' : 'Howell' , 'salzburg' : 'howell' ,\n",
        "'Hangzhou' : 'Huntington' , 'hangzhou' : 'huntington' ,\n",
        "'Maastricht' : 'Huntington Beach' , 'maastricht' : 'huntington beach' ,\n",
        "'Madonna' : 'Huntsville' , 'madonna' : 'huntsville' ,\n",
        "'Jones' : 'Independence' , 'jones' : 'independence' ,\n",
        "'Pretoria' : 'Indianapolis' , 'pretoria' : 'indianapolis' ,\n",
        "'Kinshasa' : 'Inglewood' , 'kinshasa' : 'inglewood' ,\n",
        "'George' : 'Irvine' , 'george' : 'irvine' ,\n",
        "'Tama' : 'Irving' , 'tama' : 'irving' ,\n",
        "'America' : 'Jackson' , 'america' : 'jackson' ,\n",
        "'Hiroshima' : 'Jacksonville' , 'hiroshima' : 'jacksonville' ,\n",
        "'Bach' : 'Jefferson' , 'bach' : 'jefferson' ,\n",
        "'Cisco' : 'Joliet' , 'cisco' : 'joliet' ,\n",
        "'Okinawa' : 'Kailua' , 'okinawa' : 'kailua' ,\n",
        "'Usa' : 'Kalamazoo' , 'usa' : 'kalamazoo' ,\n",
        "'Joseph' : 'Kaneohe' , 'joseph' : 'kaneohe' ,\n",
        "'Simpson' : 'Kennewick' , 'simpson' : 'kennewick' ,\n",
        "'Ohio' : 'Kenosha' , 'ohio' : 'kenosha' ,\n",
        "'Helen' : 'Killeen' , 'helen' : 'killeen' ,\n",
        "'Lewis' : 'Kissimmee' , 'lewis' : 'kissimmee' ,\n",
        "'Poland' : 'Knoxville' , 'poland' : 'knoxville' ,\n",
        "'War' : 'Lacey' , 'war' : 'lacey' ,\n",
        "'Ikeda' : 'Lafayette' , 'ikeda' : 'lafayette' ,\n",
        "'Sakura' : 'Lakeland' , 'sakura' : 'lakeland' ,\n",
        "'Hashimoto' : 'Lakewood' , 'hashimoto' : 'lakewood' ,\n",
        "'Narita' : 'Lancaster' , 'narita' : 'lancaster' ,\n",
        "'Takeo' : 'Lansing' , 'takeo' : 'lansing' ,\n",
        "'Nagasaki' : 'Laredo' , 'nagasaki' : 'laredo' ,\n",
        "'Marie' : 'Layton' , 'marie' : 'layton' ,\n",
        "'Maria' : 'Leominster' , 'maria' : 'leominster' ,\n",
        "'Mary' : 'Lewisville' , 'mary' : 'lewisville' ,\n",
        "'Lech' : 'Lexington' , 'lech' : 'lexington' ,\n",
        "'Kelly' : 'Lincoln' , 'kelly' : 'lincoln' ,\n",
        "'Ireland' : 'Lorain' , 'ireland' : 'lorain' ,\n",
        "'Hasselt' : 'Louisville' , 'hasselt' : 'louisville' ,\n",
        "'Venus' : 'Lowell' , 'venus' : 'lowell' ,\n",
        "'Ruth' : 'Lubbock' , 'ruth' : 'lubbock' ,\n",
        "'Magdalena' : 'Macon' , 'magdalena' : 'macon' ,\n",
        "'Wagner' : 'Madison' , 'wagner' : 'madison' ,\n",
        "'Van Horn' : 'Manchester' , 'van horn' : 'manchester' ,\n",
        "'Merlin' : 'Marina' , 'merlin' : 'marina' ,\n",
        "'Elba' : 'Marysville' , 'elba' : 'marysville' ,\n",
        "'Bush' : 'McAllen' , 'bush' : 'mcallen' ,\n",
        "'Smith' : 'McHenry' , 'smith' : 'mchenry' ,\n",
        "'Atlantic' : 'Medford' , 'atlantic' : 'medford' ,\n",
        "'Christmas' : 'Melbourne' , 'christmas' : 'melbourne' ,\n",
        "'Elaine' : 'Memphis' , 'elaine' : 'memphis' ,\n",
        "'Grace' : 'Merced' , 'grace' : 'merced' ,\n",
        "'Norway' : 'Mesa' , 'norway' : 'mesa' ,\n",
        "'Becker' : 'Mesquite' , 'becker' : 'mesquite' ,\n",
        "'Margaret' : 'Miami' , 'margaret' : 'miami' ,\n",
        "'Lake' : 'Milwaukee' , 'lake' : 'milwaukee' ,\n",
        "'Louisiana' : 'Minneapolis' , 'louisiana' : 'minneapolis' ,\n",
        "'Kennedy' : 'Miramar' , 'kennedy' : 'miramar' ,\n",
        "'Leonardo' : 'Mobile' , 'leonardo' : 'mobile' ,\n",
        "'Tony' : 'Modesto' , 'tony' : 'modesto' ,\n",
        "'Lopez' : 'Monroe' , 'lopez' : 'monroe' ,\n",
        "'Turkey' : 'Monterey' , 'turkey' : 'monterey' ,\n",
        "'Corsica' : 'Montgomery' , 'corsica' : 'montgomery' ,\n",
        "'North' : 'Murfreesboro' , 'north' : 'murfreesboro' ,\n",
        "'China' : 'Murrieta' , 'china' : 'murrieta' ,\n",
        "'Italy' : 'Muskegon' , 'italy' : 'muskegon' ,\n",
        "'Bolivia' : 'Naperville' , 'bolivia' : 'naperville' ,\n",
        "'Coleridge' : 'Naples' , 'coleridge' : 'naples' ,\n",
        "'Abrams' : 'Nashua' , 'abrams' : 'nashua' ,\n",
        "'Russia' : 'Nashville' , 'russia' : 'nashville' ,\n",
        "'England' : 'Newark' , 'england' : 'newark' ,\n",
        "'Palm' : 'Newburgh' , 'palm' : 'newburgh' ,\n",
        "'May' : 'Norfolk' , 'may' : 'norfolk' ,\n",
        "'Emily' : 'Normal' , 'emily' : 'normal' ,\n",
        "'Swiss' : 'Norman' , 'swiss' : 'norman' ,\n",
        "'Falkland' : 'Norwalk' , 'falkland' : 'norwalk' ,\n",
        "'Shiro' : 'Norwich' , 'shiro' : 'norwich' ,\n",
        "'Damon' : 'Oakland' , 'damon' : 'oakland' ,\n",
        "'Us' : 'Ocala' , 'us' : 'ocala' ,\n",
        "'Moncalvo' : 'Oceanside' , 'moncalvo' : 'oceanside' ,\n",
        "'Requena' : 'Odessa' , 'requena' : 'odessa' ,\n",
        "'Jesus' : 'Ogden' , 'jesus' : 'ogden' ,\n",
        "'Four' : 'Olathe' , 'four' : 'olathe' ,\n",
        "'Abuja' : 'Olympia' , 'abuja' : 'olympia' ,\n",
        "'Square' : 'Omaha' , 'square' : 'omaha' ,\n",
        "'Park' : 'Ontario' , 'park' : 'ontario' ,\n",
        "'Castro' : 'Orange' , 'castro' : 'orange' ,\n",
        "'Spain' : 'Orem' , 'spain' : 'orem' ,\n",
        "'Pedro' : 'Orlando' , 'pedro' : 'orlando' ,\n",
        "'Spock' : 'Oxnard' , 'spock' : 'oxnard' ,\n",
        "'Rosa' : 'Palmdale' , 'rosa' : 'palmdale' ,\n",
        "'Wang' : 'Pasadena' , 'wang' : 'pasadena' ,\n",
        "'Charles' : 'Paterson' , 'charles' : 'paterson' ,\n",
        "'Kuzey' : 'Pensacola' , 'kuzey' : 'pensacola' ,\n",
        "'Pizarro' : 'Peoria' , 'pizarro' : 'peoria' ,\n",
        "'Jeff' : 'Philadelphia' , 'jeff' : 'philadelphia' ,\n",
        "'Trang' : 'Phoenix' , 'trang' : 'phoenix' ,\n",
        "'University' : 'Pittsburgh' , 'university' : 'pittsburgh' ,\n",
        "'Tanaka' : 'Plano' , 'tanaka' : 'plano' ,\n",
        "'Krypton' : 'Pomona' , 'krypton' : 'pomona' ,\n",
        "'Schneider' : 'Portland' , 'schneider' : 'portland' ,\n",
        "'Mark' : 'Portsmouth' , 'mark' : 'portsmouth' ,\n",
        "'Tower' : 'Poughkeepsie' , 'tower' : 'poughkeepsie' ,\n",
        "'Bill' : 'Providence' , 'bill' : 'providence' ,\n",
        "'Fatima' : 'Provo' , 'fatima' : 'provo' ,\n",
        "'German' : 'Pueblo' , 'german' : 'pueblo' ,\n",
        "'Lenz' : 'Racine' , 'lenz' : 'racine' ,\n",
        "'Chiapas' : 'Raleigh' , 'chiapas' : 'raleigh' ,\n",
        "'Obama' : 'Reading' , 'obama' : 'reading' ,\n",
        "'Fukui' : 'Redding' , 'fukui' : 'redding' ,\n",
        "'Nine' : 'Reno' , 'nine' : 'reno' ,\n",
        "'Mari' : 'Richland' , 'mari' : 'richland' ,\n",
        "'Gamble' : 'Richmond' , 'gamble' : 'richmond' ,\n",
        "'Kraft' : 'Riverside' , 'kraft' : 'riverside' ,\n",
        "'Speed' : 'Roanoke' , 'speed' : 'roanoke' ,\n",
        "'Aso' : 'Rochester' , 'aso' : 'rochester' ,\n",
        "'Green' : 'Rockford' , 'green' : 'rockford' ,\n",
        "'Midnight' : 'Roseville' , 'midnight' : 'roseville' ,\n",
        "'Normandy' : 'Sacramento' , 'normandy' : 'sacramento' ,\n",
        "'Colombia' : 'Saginaw' , 'colombia' : 'saginaw' ,\n",
        "'Argentina' : 'Salem' , 'argentina' : 'salem' ,\n",
        "'English' : 'Salinas' , 'english' : 'salinas' ,\n",
        "'Canada' : 'Sarasota' , 'canada' : 'sarasota' ,\n",
        "'Marks' : 'Savannah' , 'marks' : 'savannah' ,\n",
        "'Pope' : 'Scottsdale' , 'pope' : 'scottsdale' ,\n",
        "'Syria' : 'Scranton' , 'syria' : 'scranton' ,\n",
        "'Morocco' : 'Seaside' , 'morocco' : 'seaside' ,\n",
        "'Brutus' : 'Seattle' , 'brutus' : 'seattle' ,\n",
        "'Finland' : 'Sebastian' , 'finland' : 'sebastian' ,\n",
        "'Michigan' : 'Shreveport' , 'michigan' : 'shreveport' ,\n",
        "'Strawberry' : 'Spartanburg' , 'strawberry' : 'spartanburg' ,\n",
        "'Luna' : 'Spokane' , 'luna' : 'spokane' ,\n",
        "'Daniel' : 'Springdale' , 'daniel' : 'springdale' ,\n",
        "'Canoe' : 'Springfield' , 'canoe' : 'springfield' ,\n",
        "'Hood' : 'Stamford' , 'hood' : 'stamford' ,\n",
        "'Patricia' : 'Stockton' , 'patricia' : 'stockton'\n",
        "              }\n",
        "with open('train.txt') as main, open('DRS-name-changed.txt', 'w') as done:\n",
        "     text = main.read()\n",
        "     done.write(re.sub(r'\\b\\w+\\b', lambda x: word_list.get(x.group(), x.group()), text))"
      ],
      "metadata": {
        "id": "Fy9H1v4cN6jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zH47GirnPtKI",
        "outputId": "ee854735-4fb0-4772-e8d5-fd17219d3c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "_YWd07zLPuCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**command to zip all the project files.**"
      ],
      "metadata": {
        "id": "0_O_xhZtQl7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/name_augmentation_files.zip /content/"
      ],
      "metadata": {
        "id": "B0c3fQkQPuxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**code below will split the big text file into small text files each having 20000 lines of text in it.**\n",
        "we did it because our parser was not supporting name, city, state, and country extraction from a very big file."
      ],
      "metadata": {
        "id": "imIpnF5rqgAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir data-chunks"
      ],
      "metadata": {
        "id": "9Io9jjnWrurj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_file = 'train.txt.raw'\n",
        "sorting = True\n",
        "hold_lines = []\n",
        "with open(my_file,'r') as text_file:\n",
        "    for row in text_file:\n",
        "        hold_lines.append(row)\n",
        "outer_count = 1\n",
        "line_count = 0\n",
        "while sorting:\n",
        "    count = 0\n",
        "    increment = (outer_count-1) * 20000\n",
        "    left = len(hold_lines) - increment\n",
        "    file_name = \"/content/data-chunks/train\" + str(outer_count * 20000) + \".txt.raw\"\n",
        "    hold_new_lines = []\n",
        "    if left < 20000:\n",
        "        while count < left:\n",
        "            hold_new_lines.append(hold_lines[line_count])\n",
        "            count += 1\n",
        "            line_count += 1\n",
        "        sorting = False\n",
        "    else:\n",
        "        while count < 20000:\n",
        "            hold_new_lines.append(hold_lines[line_count])\n",
        "            count += 1\n",
        "            line_count += 1\n",
        "    outer_count += 1\n",
        "    with open(file_name,'w') as next_file:\n",
        "        for row in hold_new_lines:\n",
        "            next_file.write(row)"
      ],
      "metadata": {
        "id": "ar92JOotoZ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGXG9gwOZCOA",
        "outputId": "e42886ea-c786-45a1-e511-bb6ad2564d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-01-24 15:28:04.126323: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.4.4                         \n",
            "Location         /usr/local/lib/python3.8/dist-packages/spacy\n",
            "Platform         Linux-5.10.147+-x86_64-with-glibc2.29\n",
            "Python version   3.8.10                        \n",
            "Pipelines        en_core_web_sm (3.4.1)        \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Working with PMB-5.0.0 (SBN) notation.**\n",
        "\n",
        "**--> Extracting names from sbn notation.**\n",
        "\n"
      ],
      "metadata": {
        "id": "hvdt0_cd3YIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define regular expression patterns to match male and female names\n",
        "male_name_pattern = r'male\\.n\\.02 Name \"(.*?)\"'\n",
        "female_name_pattern = r'female\\.n\\.02 Name \"(.*?)\"'\n",
        "\n",
        "# Open the SBN file for reading\n",
        "with open('gold.sbn', 'r') as sbn_file:\n",
        "    sbn_data = sbn_file.readlines()\n",
        "\n",
        "# Initialize lists and sets to store male and female names\n",
        "all_male_names = []\n",
        "unique_male_names = set()\n",
        "all_female_names = []\n",
        "unique_female_names = set()\n",
        "\n",
        "# Loop through each line in the SBN data and extract male and female names\n",
        "for line in sbn_data:\n",
        "    male_match = re.search(male_name_pattern, line)\n",
        "    female_match = re.search(female_name_pattern, line)\n",
        "\n",
        "    if male_match:\n",
        "        male_name = male_match.group(1)\n",
        "        all_male_names.append(male_name)\n",
        "        unique_male_names.add(male_name)\n",
        "\n",
        "    if female_match:\n",
        "        female_name = female_match.group(1)\n",
        "        all_female_names.append(female_name)\n",
        "        unique_female_names.add(female_name)\n",
        "\n",
        "# Specify the names of the output text files for all and unique male and female names\n",
        "all_male_output_file = 'all_male_names.txt'\n",
        "unique_male_output_file = 'unique_male_names.txt'\n",
        "all_female_output_file = 'all_female_names.txt'\n",
        "unique_female_output_file = 'unique_female_names.txt'\n",
        "\n",
        "# Write all male names to the male output file, one name per line\n",
        "with open(all_male_output_file, 'w') as all_male_output:\n",
        "    for name in all_male_names:\n",
        "        all_male_output.write(name + '\\n')\n",
        "\n",
        "# Write unique male names to the unique male output file, one name per line\n",
        "with open(unique_male_output_file, 'w') as unique_male_output:\n",
        "    for name in unique_male_names:\n",
        "        unique_male_output.write(name + '\\n')\n",
        "\n",
        "# Write all female names to the female output file, one name per line\n",
        "with open(all_female_output_file, 'w') as all_female_output:\n",
        "    for name in all_female_names:\n",
        "        all_female_output.write(name + '\\n')\n",
        "\n",
        "# Write unique female names to the unique female output file, one name per line\n",
        "with open(unique_female_output_file, 'w') as unique_female_output:\n",
        "    for name in unique_female_names:\n",
        "        unique_female_output.write(name + '\\n')\n",
        "\n",
        "print(f\"Extracted all male names saved to {all_male_output_file}\")\n",
        "print(f\"Extracted unique male names saved to {unique_male_output_file}\")\n",
        "print(f\"Extracted all female names saved to {all_female_output_file}\")\n",
        "print(f\"Extracted unique female names saved to {unique_female_output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jXiSkp1Aajw",
        "outputId": "61e8a485-938f-4e63-9721-32da3c96437f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all male names saved to all_male_names.txt\n",
            "Extracted unique male names saved to unique_male_names.txt\n",
            "Extracted all female names saved to all_female_names.txt\n",
            "Extracted unique female names saved to unique_female_names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking if there are some common names existing in both male and female names."
      ],
      "metadata": {
        "id": "pAdIVD516Po0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read names from male_names.txt and female_names.txt into lists\n",
        "with open('unique_male_names.txt', 'r') as male_file:\n",
        "    male_names = [line.strip() for line in male_file]\n",
        "\n",
        "with open('unique_female_names.txt', 'r') as female_file:\n",
        "    female_names = [line.strip() for line in female_file]\n",
        "\n",
        "# Convert the lists into sets for faster intersection check\n",
        "male_names_set = set(male_names)\n",
        "female_names_set = set(female_names)\n",
        "\n",
        "# Find common names\n",
        "common_names = male_names_set.intersection(female_names_set)\n",
        "\n",
        "# Check if there are common names and print them\n",
        "if common_names:\n",
        "    print(\"Common names found:\")\n",
        "    for name in common_names:\n",
        "        print(name)\n",
        "else:\n",
        "    print(\"No common names found.\")\n"
      ],
      "metadata": {
        "id": "X8So7ZoN6stS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "doing filteration of female names from male names."
      ],
      "metadata": {
        "id": "cOvfLRbwBxXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read unique female names into a set\n",
        "with open('unique_female_names.txt', 'r') as female_file:\n",
        "    female_names = {line.strip() for line in female_file}\n",
        "\n",
        "# Read unique male names into a list\n",
        "with open('unique_male_names.txt', 'r') as male_file:\n",
        "    male_names = [line.strip() for line in male_file]\n",
        "\n",
        "# Remove female names that are also in the male names set\n",
        "filtered_male_names = [name for name in male_names if name not in female_names]\n",
        "\n",
        "# Save the filtered male names into a separate text file\n",
        "with open('filtered_male_names.txt', 'w') as filtered_file:\n",
        "    for name in filtered_male_names:\n",
        "        filtered_file.write(name + '\\n')\n",
        "\n",
        "print(\"Filtered male names saved to 'filtered_male_names.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC-mo-r1B1P0",
        "outputId": "99ac1f9c-b82c-4499-aaa3-d74106cdda17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered male names saved to 'filtered_male_names.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting city names**"
      ],
      "metadata": {
        "id": "fP4ibdNZJfTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define regular expression patterns to match city names\n",
        "city_name_pattern_01 = r'city\\.n\\.01 Name \"(.*?)\"'\n",
        "city_name_pattern_03 = r'city\\.n\\.03 Name \"(.*?)\"'\n",
        "\n",
        "# Open the SBN file for reading\n",
        "with open('gold.sbn', 'r') as sbn_file:\n",
        "    sbn_data = sbn_file.readlines()\n",
        "\n",
        "# Initialize lists and sets to store city names\n",
        "all_city_names_01 = []\n",
        "unique_city_names_01 = set()\n",
        "all_city_names_03 = []\n",
        "unique_city_names_03 = set()\n",
        "\n",
        "# Loop through each line in the SBN data and extract city names\n",
        "for line in sbn_data:\n",
        "    city_match_01 = re.search(city_name_pattern_01, line)\n",
        "    city_match_03 = re.search(city_name_pattern_03, line)\n",
        "\n",
        "    if city_match_01:\n",
        "        city_name = city_match_01.group(1)\n",
        "        all_city_names_01.append(city_name)\n",
        "        unique_city_names_01.add(city_name)\n",
        "\n",
        "    if city_match_03:\n",
        "        city_name = city_match_03.group(1)\n",
        "        all_city_names_03.append(city_name)\n",
        "        unique_city_names_03.add(city_name)\n",
        "\n",
        "# Specify the names of the output text files for all and unique city names\n",
        "all_city_output_file_01 = 'all_city_names_01.txt'\n",
        "unique_city_output_file_01 = 'unique_city_names_01.txt'\n",
        "all_city_output_file_03 = 'all_city_names_03.txt'\n",
        "unique_city_output_file_03 = 'unique_city_names_03.txt'\n",
        "\n",
        "# Write all city names (n.01) to the output file, one name per line\n",
        "with open(all_city_output_file_01, 'w') as all_city_output_01:\n",
        "    for name in all_city_names_01:\n",
        "        all_city_output_01.write(name + '\\n')\n",
        "\n",
        "# Write unique city names (n.01) to the output file, one name per line\n",
        "with open(unique_city_output_file_01, 'w') as unique_city_output_01:\n",
        "    for name in unique_city_names_01:\n",
        "        unique_city_output_01.write(name + '\\n')\n",
        "\n",
        "# Write all city names (n.03) to the output file, one name per line\n",
        "with open(all_city_output_file_03, 'w') as all_city_output_03:\n",
        "    for name in all_city_names_03:\n",
        "        all_city_output_03.write(name + '\\n')\n",
        "\n",
        "# Write unique city names (n.03) to the output file, one name per line\n",
        "with open(unique_city_output_file_03, 'w') as unique_city_output_03:\n",
        "    for name in unique_city_names_03:\n",
        "        unique_city_output_03.write(name + '\\n')\n",
        "\n",
        "print(f\"Extracted all city names (n.01) saved to {all_city_output_file_01}\")\n",
        "print(f\"Extracted unique city names (n.01) saved to {unique_city_output_file_01}\")\n",
        "print(f\"Extracted all city names (n.03) saved to {all_city_output_file_03}\")\n",
        "print(f\"Extracted unique city names (n.03) saved to {unique_city_output_file_03}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_VivMrVJjvR",
        "outputId": "ab750c6f-1a20-44c2-8f8b-853c5dac4ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all city names (n.01) saved to all_city_names_01.txt\n",
            "Extracted unique city names (n.01) saved to unique_city_names_01.txt\n",
            "Extracted all city names (n.03) saved to all_city_names_03.txt\n",
            "Extracted unique city names (n.03) saved to unique_city_names_03.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Country name extraction.**"
      ],
      "metadata": {
        "id": "zwZkw9YbM2CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a regular expression pattern to match country names\n",
        "country_name_pattern = r'country\\.n\\.02 Name \"(.*?)\"'\n",
        "\n",
        "# Open the SBN file for reading\n",
        "with open('gold.sbn', 'r') as sbn_file:\n",
        "    sbn_data = sbn_file.readlines()\n",
        "\n",
        "# Initialize lists and a set to store country names\n",
        "all_country_names = []\n",
        "unique_country_names = set()\n",
        "\n",
        "# Loop through each line in the SBN data and extract country names\n",
        "for line in sbn_data:\n",
        "    country_match = re.search(country_name_pattern, line)\n",
        "\n",
        "    if country_match:\n",
        "        country_name = country_match.group(1)\n",
        "        all_country_names.append(country_name)\n",
        "        unique_country_names.add(country_name)\n",
        "\n",
        "# Specify the names of the output text files for all and unique country names\n",
        "all_country_output_file = 'all_country_names.txt'\n",
        "unique_country_output_file = 'unique_country_names.txt'\n",
        "\n",
        "# Write all country names to the output file, one name per line\n",
        "with open(all_country_output_file, 'w') as all_country_output:\n",
        "    for name in all_country_names:\n",
        "        all_country_output.write(name + '\\n')\n",
        "\n",
        "# Write unique country names to the output file, one name per line\n",
        "with open(unique_country_output_file, 'w') as unique_country_output:\n",
        "    for name in unique_country_names:\n",
        "        unique_country_output.write(name + '\\n')\n",
        "\n",
        "print(f\"Extracted all country names saved to {all_country_output_file}\")\n",
        "print(f\"Extracted unique country names saved to {unique_country_output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdCcftn-M5a1",
        "outputId": "12d2ab51-67ee-4b0d-a377-2b125235c7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all country names saved to all_country_names.txt\n",
            "Extracted unique country names saved to unique_country_names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Island Names**"
      ],
      "metadata": {
        "id": "FzBT-NSUNuzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a regular expression pattern to match country names\n",
        "country_name_pattern = r'island\\.n\\.01 Name \"(.*?)\"'\n",
        "\n",
        "# Open the SBN file for reading\n",
        "with open('gold.sbn', 'r') as sbn_file:\n",
        "    sbn_data = sbn_file.readlines()\n",
        "\n",
        "# Initialize lists and a set to store country names\n",
        "all_country_names = []\n",
        "unique_country_names = set()\n",
        "\n",
        "# Loop through each line in the SBN data and extract country names\n",
        "for line in sbn_data:\n",
        "    country_match = re.search(country_name_pattern, line)\n",
        "\n",
        "    if country_match:\n",
        "        country_name = country_match.group(1)\n",
        "        all_country_names.append(country_name)\n",
        "        unique_country_names.add(country_name)\n",
        "\n",
        "# Specify the names of the output text files for all and unique country names\n",
        "all_country_output_file = 'all_island_names.txt'\n",
        "unique_country_output_file = 'unique_island_names.txt'\n",
        "\n",
        "# Write all country names to the output file, one name per line\n",
        "with open(all_country_output_file, 'w') as all_country_output:\n",
        "    for name in all_country_names:\n",
        "        all_country_output.write(name + '\\n')\n",
        "\n",
        "# Write unique country names to the output file, one name per line\n",
        "with open(unique_country_output_file, 'w') as unique_country_output:\n",
        "    for name in unique_country_names:\n",
        "        unique_country_output.write(name + '\\n')\n",
        "\n",
        "print(f\"Extracted all island names saved to {all_country_output_file}\")\n",
        "print(f\"Extracted unique island names saved to {unique_country_output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGRFtm7YNy1k",
        "outputId": "ad492776-b8dc-4823-9917-8c084d945aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all island names saved to all_island_names.txt\n",
            "Extracted unique island names saved to unique_island_names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**State Name Extraction.**"
      ],
      "metadata": {
        "id": "X9cIaaACObXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define regular expression patterns to match state names\n",
        "state_name_pattern_01 = r'state\\.n\\.01 Name \"(.*?)\"'\n",
        "state_name_pattern_03 = r'state\\.n\\.03 Name \"(.*?)\"'\n",
        "state_name_pattern_04 = r'state\\.n\\.04 Name \"(.*?)\"'\n",
        "\n",
        "# Open the SBN file for reading\n",
        "with open('gold.sbn', 'r') as sbn_file:\n",
        "    sbn_data = sbn_file.readlines()\n",
        "\n",
        "# Initialize lists and sets to store state names\n",
        "all_state_names_01 = []\n",
        "unique_state_names_01 = set()\n",
        "all_state_names_03 = []\n",
        "unique_state_names_03 = set()\n",
        "all_state_names_04 = []\n",
        "unique_state_names_04 = set()\n",
        "\n",
        "# Loop through each line in the SBN data and extract state names\n",
        "for line in sbn_data:\n",
        "    state_match_01 = re.search(state_name_pattern_01, line)\n",
        "    state_match_03 = re.search(state_name_pattern_03, line)\n",
        "    state_match_04 = re.search(state_name_pattern_04, line)\n",
        "\n",
        "    if state_match_01:\n",
        "        state_name = state_match_01.group(1)\n",
        "        all_state_names_01.append(state_name)\n",
        "        unique_state_names_01.add(state_name)\n",
        "\n",
        "    if state_match_03:\n",
        "        state_name = state_match_03.group(1)\n",
        "        all_state_names_03.append(state_name)\n",
        "        unique_state_names_03.add(state_name)\n",
        "\n",
        "    if state_match_04:\n",
        "        state_name = state_match_04.group(1)\n",
        "        all_state_names_04.append(state_name)\n",
        "        unique_state_names_04.add(state_name)\n",
        "\n",
        "# Specify the names of the output text files for all and unique state names\n",
        "all_state_output_file_01 = 'all_state_names_01.txt'\n",
        "unique_state_output_file_01 = 'unique_state_names_01.txt'\n",
        "all_state_output_file_03 = 'all_state_names_03.txt'\n",
        "unique_state_output_file_03 = 'unique_state_names_03.txt'\n",
        "all_state_output_file_04 = 'all_state_names_04.txt'\n",
        "unique_state_output_file_04 = 'unique_state_names_04.txt'\n",
        "\n",
        "# Write all state names (n.01) to the output file, one name per line\n",
        "with open(all_state_output_file_01, 'w') as all_state_output_01:\n",
        "    for name in all_state_names_01:\n",
        "        all_state_output_01.write(name + '\\n')\n",
        "\n",
        "# Write unique state names (n.01) to the output file, one name per line\n",
        "with open(unique_state_output_file_01, 'w') as unique_state_output_01:\n",
        "    for name in unique_state_names_01:\n",
        "        unique_state_output_01.write(name + '\\n')\n",
        "\n",
        "# Write all state names (n.03) to the output file, one name per line\n",
        "with open(all_state_output_file_03, 'w') as all_state_output_03:\n",
        "    for name in all_state_names_03:\n",
        "        all_state_output_03.write(name + '\\n')\n",
        "\n",
        "# Write unique state names (n.03) to the output file, one name per line\n",
        "with open(unique_state_output_file_03, 'w') as unique_state_output_03:\n",
        "    for name in unique_state_names_03:\n",
        "        unique_state_output_03.write(name + '\\n')\n",
        "\n",
        "# Write all state names (n.04) to the output file, one name per line\n",
        "with open(all_state_output_file_04, 'w') as all_state_output_04:\n",
        "    for name in all_state_names_04:\n",
        "        all_state_output_04.write(name + '\\n')\n",
        "\n",
        "# Write unique state names (n.04) to the output file, one name per line\n",
        "with open(unique_state_output_file_04, 'w') as unique_state_output_04:\n",
        "    for name in unique_state_names_04:\n",
        "        unique_state_output_04.write(name + '\\n')\n",
        "\n",
        "print(f\"Extracted all state names (n.01) saved to {all_state_output_file_01}\")\n",
        "print(f\"Extracted unique state names (n.01) saved to {unique_state_output_file_01}\")\n",
        "print(f\"Extracted all state names (n.03) saved to {all_state_output_file_03}\")\n",
        "print(f\"Extracted unique state names (n.03) saved to {unique_state_output_file_03}\")\n",
        "print(f\"Extracted all state names (n.04) saved to {all_state_output_file_04}\")\n",
        "print(f\"Extracted unique state names (n.04) saved to {unique_state_output_file_04}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-URUts95OgQX",
        "outputId": "29d5ea24-256d-47ac-ad54-d8d3a0f90b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all state names (n.01) saved to all_state_names_01.txt\n",
            "Extracted unique state names (n.01) saved to unique_state_names_01.txt\n",
            "Extracted all state names (n.03) saved to all_state_names_03.txt\n",
            "Extracted unique state names (n.03) saved to unique_state_names_03.txt\n",
            "Extracted all state names (n.04) saved to all_state_names_04.txt\n",
            "Extracted unique state names (n.04) saved to unique_state_names_04.txt\n"
          ]
        }
      ]
    }
  ]
}